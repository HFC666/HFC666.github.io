[{"title":"变分贝叶斯推断","url":"/2022/07/10/VBI/","content":"\n## Variational Bayesian inference\n\n<p align=\"center\">\n    <img src=\"https://img0.baidu.com/it/u=2387178916,3720682298&fm=253&fmt=auto?w=1280&h=720\" style=\"zoom: 100%;\" />\n</p>\n\n> 参考文献\n>\n> 1. [徐亦达老师变分推断课件](https://github.com/roboticcam/machine-learning-notes/blob/master/files/variational.pdf)\n> 2. [A tutorial on variational Bayesian inference](https://link.springer.com/article/10.1007/s10462-011-9236-8)\n> 3. [白板推导指数族分布](https://www.bilibili.com/video/BV1QW411y7D3?spm_id_from=333.337.search-card.all.click&vd_source=6177c61c946280bb88c727585de76bc8)\n> 4. [白板推导变分推断](https://www.bilibili.com/video/BV1DW41167vr?spm_id_from=333.337.search-card.all.click&vd_source=6177c61c946280bb88c727585de76bc8)\n\n<!--more-->\n\n### Log-likelihood and Evidence Lower Bound(ELOB)\n\n下列表达式总是成立：\n$$\n\\ln(p(X)) = \\ln(p(X,Z)) - \\ln(P(Z\\mid X))\n$$\n所以下式也成立：\n$$\n\\ln(P(X)) = \\left[\\ln(p(X,Z))-\\ln(q(Z))\\right] - \\left[\\ln(p(Z\\mid X))-\\ln(q(Z))\\right]\n$$\n所以现在我们有\n$$\n\\ln(p(X)) = \\ln\\left(\\frac{p(X,Z)}{q(Z)}\\right) - \\ln\\left(\\frac{p(Z\\mid X)}{q(Z)}\\right)\n$$\n两边同时取期望：\n$$\n\\begin{aligned}\n\\ln (p(X)) &=\\int q(Z) \\ln \\left(\\frac{p(X, Z)}{q(Z)}\\right) \\mathrm{d} Z-\\int q(Z) \\ln \\left(\\frac{p(Z \\mid X)}{q(Z)}\\right) \\mathrm{d} Z \\\\\n&=\\underbrace{\\int q(Z) \\ln (p(X, Z)) \\mathrm{d} Z-\\int q(Z) \\ln (q(Z)) \\mathrm{d} Z}_{\\mathcal{L}(q)}+\\underbrace{\\left(-\\int q(Z) \\ln \\left(\\frac{p(Z \\mid X)}{q(Z)}\\right) \\mathrm{d} Z\\right)}_{\\mathbb{K} \\mathbb{L}(q \\| p)} \\\\\n&=\\mathcal{L}(q)+\\mathbb{K} \\mathbb{L}(q \\| p)\n\\end{aligned}\n$$\nKL散度一般用于度量两个概率分布函数之间的距离，其定义如下：\n$$\n\\mathbb{KL}[p(X)\\mid q(X)] = \\sum_{x\\in X}\\left[p(x)\\log\\frac{p(x)}{q(x)}\\right] = \\mathbb{E}_{x\\sim p(x)}\\left[\\log\\frac{p(x)}{q(x)}\\right]\n$$\n我们要做的就是找到与后验分布$p(Z\\mid X)$最接近的简单分布$p(Z)$。\n\n### Alternative Evidence Lower Bound(ELOB)\n\n我们看另一种推导方法：\n$$\n\\begin{aligned}\n\\ln (p(X)) &=\\log \\int_{Z} p(X, Z) \\mathrm{d} z \\\\\n&=\\log \\int_{Z} p(X, Z) \\frac{q(Z)}{q(Z)} \\mathrm{d} z \\\\\n&=\\log \\left(\\mathbb{E}_{q}\\left[\\frac{p(X, Z)}{q(Z)}\\right]\\right) \\\\\n& \\geq \\mathbb{E}_{q}\\left[\\log \\left(\\frac{p(X, Z)}{q(Z)}\\right)\\right] \\text { using Jensen's inequality } \\\\\n&=\\mathbb{E}_{q}[\\log (p(X, Z))]-\\mathbb{E}_{q}[\\log (q(Z))] \\\\\n& \\triangleq \\mathcal{L}(q)\n\\end{aligned}\n$$\n\n### Maximize Evidence Lower Bound(ELOB)\n\n我们给每个部分一个名字：\n$$\n\\begin{array}{ll}\n\\text {Evidence Lower Bound (ELOB):} & \\mathcal{L}(q)=\\int q(Z) \\ln (p(X, Z)) \\mathrm{d} Z-\\int q(Z) \\ln (q(Z)) \\mathrm{d} Z \\\\\n\\mathrm{KL} \\text { divergence: } & \\mathbb{K} \\mathbb{L}(q \\| p)=-\\int q(Z) \\ln \\left(\\frac{p(Z \\mid X)}{q(Z)}\\right) d Z\n\\end{array}\n$$\n\n+ 注意$p(X)$对于$q(Z)$的选择是固定的。我们想要去选择一个$q(Z)$函数最小化KL散度，因此$q(Z)$变得离$p(Z\\mid X)$越来越近。很容易验证，当$q(Z)=p(Z\\mid X)$时，KL散度为$0$。\n+ 我们知道$\\ln p(X) = \\mathcal{L}(q)+\\mathbb{KL}(q\\| p)$。最小化$\\mathbb{KL}(q\\| p)$等同于最大化$\\mathcal{L}(q)$。\n\n\n\n\n\n我们可以选择$q(Z)$使得\n$$\nq(Z) = \\prod_{i=1}^Mq_i(Z_i)\n$$\n其中$M$为$Z$的维度，也就是说$q(Z)$的各个维度是独立的，这被称为**平均场变分贝叶斯**。\n\n> 注意$q(Z)$对联合概率密度函数$p(Z\\mid X)$是一个很好地近似，但是边缘分布$q(Z_i)$对$p(Z_i\\mid x)$的近似不一定好。\n\n将其带入到$\\mathcal{L}(q)$中：\n$$\n\\begin{aligned}\n\\mathcal{L}(q) &=\\int q(Z) \\ln (p(X, Z)) \\mathrm{d} Z-\\int q(Z) \\ln (q(Z)) \\mathrm{d} Z \\\\\n&=\\underbrace{\\int \\prod_{i=1}^{M} q_{i}\\left(Z_{i}\\right) \\ln (p(X, Z)) \\mathrm{d} Z}_{\\text {part (1) }}-\\underbrace{\\int \\prod_{i=1}^{M} q_{i}\\left(Z_{i}\\right) \\sum_{i=1}^{M} \\ln \\left(q_{i}\\left(Z_{i}\\right)\\right) \\mathrm{d} Z}_{\\text {part (2) }}\n\\end{aligned}\n$$\n我们先看Part1，假设我们只对$Z_i$感兴趣，将其拿出来，变为：\n$$\n(\\operatorname{Part} 1)=\\int_{Z_{j}} q_{j}\\left(Z_{j}\\right)\\left(\\int_{Z_{i \\neq j}} \\ldots \\int \\prod_{i \\neq j}^{M} q_{i}\\left(Z_{i}\\right) \\ln (p(X, Z)) \\prod_{i \\neq j}^{M} d Z_{i}\\right) d Z_{j}\n$$\n或者将其写为更紧凑的形式：\n$$\n(\\operatorname{Part} 1)=\\int_{Z_{j}} q_{j}\\left(Z_{j}\\right)\\left(\\int_{Z_{i \\neq j}} \\cdots \\int \\ln (p(X, Z)) \\prod_{i \\neq j}^{M} q_{i}\\left(Z_{i}\\right) d Z_{i}\\right) d Z_{j}\n$$\n或者，为了让其更具有意义，可以将其放进一个期望函数里：\n$$\n(\\operatorname{Part} 1)=\\int_{Z_{j}} q_{j}\\left(Z_{j}\\right)\\left[\\mathbb{E}_{i \\neq j}[\\ln (p(X, Z))]\\right] d Z_{j}\n$$\n现在再看Part2：\n$$\n(\\text { Part 2) }=\\int \\prod_{i=1}^{M} q_{i}(Z_{i}) \\sum_{i=1}^{M} \\ln \\left(q_{i}(Z_{i}\\right)) d Z\n$$\n将其化简：\n$$\n\\begin{aligned}\n\\operatorname{(Part2)} &= \\int q(Z)\\sum_{i=1}^M\\ln(q_i(Z_i))dZ\\\\\n&=\\sum_{i=1}^M\\int_{Z}q(Z_1,\\cdots,Z_M)\\ln(q_i(Z_i))dZ\\\\\n&=\\sum_{i=1}^M\\int_{Z_i}q_i(Z_i)\\ln(q_i(Z_i))dZ_i\n\\end{aligned}\n$$\n\n\n假设现在我们只对$q_j(Z_j)$感兴趣，则其余部分可以看作常数，因此上式可以进一步写为：\n$$\n(\\text { Part } 2)=\\int_{Z_{j}} q_{j}\\left(Z_{j}\\right) \\ln \\left(q_{j}\\left(Z_{j}\\right)\\right) d Z_{j}+\\text { const}\n$$\n则$\\mathcal{L}(q)$变为：\n$$\n\\mathcal{L}(q)=\\operatorname{Part}(1)-\\operatorname{Part}(2)=\\int_{Z_{j}} q_{j}\\left(Z_{j}\\right) \\mathbb{E}_{i \\neq j}[\\ln (p(X, Z))] \\mathrm{d} Z_{j}-\\int_{Z_{j}} q_{j}\\left(Z_{j}\\right) \\ln \\left(q_{j}\\left(Z_{j}\\right)\\right) \\mathrm{d} Z_{j}+\\operatorname{const}\n$$\n我们定义：\n$$\n\\ln(\\tilde{p}_j(X,Z_j)) = \\mathbb{E}_{i\\neq j}[\\ln(p(X,Z))]\n$$\n或者定价的我们可以将ELOB写为：\n$$\n\\mathcal{L}(q_j) = \\int_{Z_j}q_j(Z_j)\\ln\\left[\\frac{\\tilde{p}_j(X,Z_j)}{q_j(Z_j)}\\right]+\\text{const}\n$$\n这与\n$$\n-\\mathbb{KL}\\left(\\exp(\\mathbb{E}_{i\\neq j}[\\ln(p(X,Z))])\\| q_i(Z_i)\\right)\n$$\n相等。\n\n**所以我们可以最大化ELOB，或者$\\mathcal{L}(q)$，通过最小化这个特殊的KL散度，也就是找到近似和最优$q^\\star_i(Z_i)$，使得**\n$$\n\\ln(q_i^\\star(Z_i)) = \\mathbb{E}_{i\\neq j}[\\ln(p(X,Z))]\n$$\n\n### Example\n\n令数据$\\mathcal{D}=\\{x_1,\\cdots,x_n\\}$，则\n$$\n\\begin{gathered}\np(\\mathcal{D} \\mid \\mu, \\tau)=\\prod_{i=1}^{n}\\left(\\frac{\\tau}{2 \\pi}\\right)^{\\frac{1}{2}} \\exp \\left(\\frac{-\\tau}{2}\\left(x_{i}-\\mu\\right)^{2}\\right) \\\\\n=\\left(\\frac{\\tau}{2 \\pi}\\right)^{\\frac{n}{2}} \\exp \\left(\\frac{-\\tau}{2} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right) \\\\\np(\\mu \\mid \\tau)=\\mathcal{N}\\left(\\mu_{0},\\left(\\lambda_{0} \\tau\\right)^{-1}\\right) \\propto \\exp \\left(\\frac{-\\lambda_{0} \\tau}{2}\\left(\\mu-\\mu_{0}\\right)^{2}\\right) \\\\\np(\\tau)=\\operatorname{Gamma}\\left(\\tau \\mid a_{0}, b_{0}\\right) \\propto \\tau^{a_{0}-1} \\exp ^{-b_{0} \\tau}\n\\end{gathered}\n$$\n并且\n$$\np(\\mathcal{D},\\mu,\\tau) = p(\\mathcal{D}\\mid \\mu,\\tau)p(\\mu\\mid \\tau)p(\\tau)\n$$\n则：\n$$\np(\\mu,\\tau\\mid d)\\propto p(\\mathcal{D}\\mid \\mu,\\tau)p(\\mu\\mid \\tau)p(\\tau)=\\mathcal{N}(\\mu_n,(\\lambda \\tau)^{-1})\\text{Gamma}(\\tau\\mid a_n,b_n)\n$$\n其中\n$$\n\\begin{aligned}\n\\mu_{n} &=\\frac{\\lambda_{0} \\mu_{0}+n \\bar{x}}{\\lambda_{0}+n} \\\\\n\\lambda_{n} &=\\lambda_{0}+n \\\\\na_{n} &=a_{0}+n / 2 \\\\\nb_{n} &=b_{0}+\\frac{1}{2} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}+\\frac{\\lambda_{0} n\\left(\\bar{x}-\\mu_{0}\\right)^{2}}{2\\left(\\lambda_{0}+n\\right)}\n\\end{aligned}\n$$\n可以看出是由解析解的，但是为了例子，我们再采用变分贝叶斯的方法，我们假设$q(\\mu,\\tau)$：\n$$\nq(\\mu,\\tau) = q_{\\mu}(\\mu)q_\\tau(\\tau)\n$$\n则：\n$$\n\\begin{aligned}\n\\ln \\left(q_{\\mu}^{*}(\\mu)\\right) &=\\mathbb{E}_{q_{\\tau}}[\\ln (p(\\mu, \\tau \\mid \\mathcal{D}))] \\\\\n&=\\mathbb{E}_{q_{\\tau} \\tau}[\\ln (p(\\mathcal{D} \\mid \\mu, \\tau))+\\ln p(\\mu \\mid \\tau)]+\\text { const. } \\quad \\text { remove terms do NOT contain } \\mu \\\\\n&=\\mathbb{E}_{q_{\\tau}}[\\underbrace{-\\frac{\\tau}{2} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\underbrace{\\frac{\\lambda_{0} \\tau}{2}\\left(\\mu-\\mu_{0}\\right)^{2}}_{\\ln p(\\mu \\mid \\gamma)}]}_{\\ln (p(\\mathcal{D} \\mid \\mu, \\tau))}+\\text { const. }\\\\\n&=-\\frac{\\mathbb{E}_{q_{\\tau}}[\\tau]}{2} \\underbrace{\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\lambda_{0}\\left(\\mu-\\mu_{0}\\right)^{2}\\right]}_{\\text {terms contain } \\mu \\text { but does not contain } \\tau}+\\text { const. }\n\\end{aligned}\n$$\n将关于$\\mu$的项展开：\n$$\n\\begin{aligned}\n& \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\lambda_{0}\\left(\\mu-\\mu_{0}\\right)^{2}=n \\mu^{2}-2 n \\mu \\bar{x}+\\lambda_{0} \\mu^{2}-2 \\lambda_{0} \\mu_{0} \\mu+\\text { const. } \\\\\n=&\\left(n+\\lambda_{0}\\right) \\mu^{2}-2 \\mu\\left(n \\bar{x}+\\lambda_{0} \\mu_{0}\\right)=\\left(n+\\lambda_{0}\\right)\\left(\\mu^{2}-\\frac{2 \\mu\\left(n \\bar{x}+\\lambda_{0} \\mu_{0}\\right)}{\\left(n+\\lambda_{0}\\right)}\\right) \\\\\n=&\\left(n+\\lambda_{0}\\right)\\left(\\mu-\\frac{\\left(n \\bar{x}+\\lambda_{0} \\mu_{0}\\right)}{\\left(n+\\lambda_{0}\\right)}\\right)^{2}+\\text { const. }\n\\end{aligned}\n$$\n因此我们有：\n$$\n\\begin{aligned}\n\\ln \\left(q_{\\mu}^{*}(\\mu)\\right) &=-\\frac{\\mathbb{E}_{q_{\\tau}}[\\tau]}{2}\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\lambda_{0}\\left(\\mu-\\mu_{0}\\right)^{2}\\right]+\\text { const. } \\\\\n&=-\\frac{\\mathbb{E}_{q_{\\tau}}[\\tau]\\left(n+\\lambda_{0}\\right)}{2}\\left(\\mu-\\frac{\\left(n \\bar{x}+\\lambda_{0} \\mu_{0}\\right)}{\\left(n+\\lambda_{0}\\right)}\\right)^{2}+\\text { const. } \\\\\n&=\\mathcal{N}\\left(\\frac{n \\bar{x}+\\lambda_{0} \\mu_{0}}{n+\\lambda_{0}}, \\mathbb{E}_{q_{\\tau}}[\\tau]\\left(n+\\lambda_{0}\\right)\\right)\n\\end{aligned}\n$$\n关于$\\tau$，我们有\n$$\n\\begin{aligned}\n\\ln \\left(q_{\\tau}^{*}(\\tau)\\right) &=\\mathbb{E}_{q_{\\mu}}[\\ln (p(\\mu, \\tau \\mid \\mathcal{D}))] \\\\\n&=\\mathbb{E}_{q_{\\mu}}[\\ln (p(\\mathcal{D} \\mid \\mu, \\tau))+\\ln p(\\mu \\mid \\tau)+\\ln p(\\tau)]+\\text { const. } \\\\\n&=\\mathbb{E}_{q_{\\mu}}[\\underbrace{\\frac{n}{2} \\ln (\\tau)-\\frac{\\tau}{2} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}}_{\\ln (p(\\mathcal{D} \\mid \\mu, \\tau))} \\underbrace{-\\frac{\\lambda_{0} \\tau}{2}\\left(\\mu-\\mu_{0}\\right)^{2}}_{\\ln p(\\mu \\mid \\gamma)} \\underbrace{+\\left(a_{0}-1\\right) \\ln (\\tau)-b_{0} \\tau}_{\\ln p(\\tau)}]+\\text { const. }\n\\end{aligned}\n$$\n将没有$\\mu$的项拿出积分：\n$$\n\\begin{aligned}\n&=\\frac{n}{2} \\ln (\\tau)+\\left(a_{0}-1\\right) \\ln (\\tau)-b_{0} \\tau-\\frac{\\tau}{2} \\mathbb{E}_{q_{\\mu}(\\mu)}\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\lambda_{0}\\left(\\mu-\\mu_{0}\\right)^{2}\\right]+\\text { const. } \\\\\n&=(\\underbrace{\\frac{n}{2}+a_{0}}_{a_{n}}-1) \\ln (\\tau)-\\tau(\\underbrace{b_{0}+\\frac{1}{2} \\mathbb{E}_{q_{\\mu}(\\mu)}\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\lambda_{0}\\left(\\mu-\\mu_{0}\\right)^{2}\\right]}_{b_{n}}+\\text { const. }\n\\end{aligned}\n$$\n重写为：\n$$\n\\begin{aligned}\nb_{n} &=b_{0}+\\frac{1}{2} \\mathbb{E}_{q_{\\mu}}\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}+\\lambda_{0}\\left(\\mu-\\mu_{0}\\right)^{2}\\right] \\\\\n&=b_{0}+\\frac{1}{2} \\mathbb{E}_{q_{\\mu}}\\left[-2 \\mu n \\bar{x}+n \\mu^{2}+\\lambda_{0} \\mu^{2}-2 \\lambda_{0} \\mu_{0} \\mu\\right]+\\sum_{i=1}^{n}\\left(x_{i}\\right)^{2}+\\lambda_{0} \\mu_{0}^{2} \\\\\n&=b_{0}+\\frac{1}{2}\\left[\\left(n+\\lambda_{0}\\right) \\mathbb{E}_{q_{\\mu}}\\left[\\mu^{2}\\right]-2\\left(n \\bar{x}+\\lambda_{0} \\mu_{0}\\right) \\mathbb{E}_{q_{\\mu}}[\\mu]+\\sum_{i=1}^{n}\\left(x_{i}\\right)^{2}+\\lambda_{0} \\mu_{0}^{2}\\right]\n\\end{aligned}\n$$\n因为$q_{\\mu}(\\mu)$事先定义好了我们可以计算$\\mathbb{E}_{q_\\mu}[\\mu]$和$\\mathbb{E}_{q_\\mu}[\\mu^2]$。\n\n### 随机梯度变分推断\n\n上面提到的基于平均场的变分推断实际上是坐标上升法，其存在一些问题：\n\n+ 假设太强，对复杂模型也许假设不好甚至不成立。\n+ 即使假设是成立的，但是因为其递推式包含很多积分，也可能无法计算。\n\n下面我们采用随机梯度上升的方法来求解变分推断问题：\n\n我们知道目标函数：\n$$\n\\hat{q} = \\arg\\min _q\\mathbb{KL}(q\\| p) = \\arg\\max_q\\mathcal{L}(q)\n$$\n其中$q$是$z$的函数，设其参数为$\\phi$，我们将其记为$q_{\\phi}(z)$，那么我们的目标函数变为：\n$$\n\\hat{q} = \\arg\\max_{\\phi}\\mathcal{L}(\\phi)\n$$\n其中\n$$\n\\mathcal{L}(\\phi) = \\mathbb{E}_{q_\\phi}[\\log P]\n$$\n因为是随机梯度下降，所以我们每次选取一个样本，假设选取的样本为$x_i$，那么目标函数变为：\n$$\n\\mathcal{L}(\\phi) = \\mathbb{E}_{q_\\phi}[\\log P(x_i,z) - \\log q_{\\phi}(z)]\n$$\n对其进行求导，得：\n$$\n\\begin{aligned}\n\\nabla_{\\phi} \\mathcal{L}(\\phi) &=\\nabla_{\\phi} \\mathbb{E}_{q_{\\phi}}\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] \\\\\n&=\\nabla_{\\phi} \\int q_{\\phi}\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] d z \\\\\n&=\\int \\nabla_{\\phi}\\left(q_{\\phi}\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right]\\right) d z \\\\\n&=\\underbrace{\\int \\nabla_{\\phi} q_{\\phi} \\cdot\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] d z}_{\\text{Part1}}+\\underbrace{\\int q_{\\phi} \\cdot \\nabla_{\\phi}\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] d z}_{\\text{Part2}}\n\\end{aligned}\n$$\n我们首先看Part2：\n$$\n\\begin{aligned}\n\\text { Part2 } &=\\int q_{\\phi} \\cdot \\nabla_{\\phi}\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] d z \\\\\n&=\\int q_{\\phi} \\cdot\\left(-\\nabla_{\\phi} \\log q_{\\phi}\\right) d z \\\\\n&=\\int q_{\\phi} \\cdot\\left(-\\frac{1}{q_{\\phi}} \\nabla_{\\phi} q_{\\phi}\\right) d z \\\\\n&=-\\int \\nabla_{\\phi} q_{\\phi} d z \\\\\n&=-\\nabla_{\\phi} \\int q_{\\phi} d z \\\\\n&=-\\nabla_{\\phi} 1 \\\\\n&=0\n\\end{aligned}\n$$\n所以\n$$\n\\nabla_\\phi\\mathcal{L}(\\phi) = \\int\\nabla_\\phi q_\\phi\\cdot[\\log P(x_i,z)-\\log q_\\phi]dz\n$$\n如果能写成期望的形式，我们就可以采用蒙特卡洛的方法对其进行采样，因此进行一个小的变换：$\\nabla_\\phi q_\\phi = \\nabla(\\log q_\\phi)q_\\phi$，得到\n$$\n\\begin{aligned}\n\\nabla_\\phi\\mathcal{L}(\\phi) &= \\int \\nabla_\\phi(\\log q_\\phi)\\cdot q_\\phi\\cdot[\\log P(x_i,z)-\\log q_\\phi]dz\\\\\n&= \\mathbb{E}_{q_\\phi}[\\nabla_\\phi(\\log q_\\phi)\\cdot (\\log P(x_i,z)-\\log q_\\phi)]\n\\end{aligned}\n$$\n这样就可以采用蒙特卡洛的方式进行采样后求解期望：\n\n从$q_{\\phi}(z)$中采样$z$，$z_l \\sim q_{\\phi}(z),l=1,2,\\cdots,L$，因此：\n$$\n\\nabla_\\phi\\mathcal{L}(\\phi)\\approx \\frac{1}{L}\\sum_{l=1}^L\\nabla_\\phi\\log q_{\\phi}(z_l)(\\log P(x_i,z_l)-\\log q_\\phi(z_l))\n$$\n但是存在一个问题，因为$q_{\\phi}(z)$为概率密度函数，所以其值位于$[0,1]$，在$[0,1]$内对数函数的变化非常大，这就导致其方差较大，导致此方法很可能无法使用。\n\n因此我们采用了重参数化技巧，假定$z = g_\\phi(\\epsilon,x_i),\\epsilon\\sim P(\\epsilon)$，其中$g_\\phi$为参数变换的函数，相当于$z$把随机性转移到了$\\epsilon$上，根据随机变量变换的性质：\n$$\n|q_\\phi(z)dz| = |P(\\epsilon)d\\epsilon|\n$$\n\n> 即：\n> $$\n> \\frac{q_\\phi(z)}{P(\\epsilon)} = \\left|\\frac{dz}{d\\epsilon}\\right|\n> $$\n\n将上述变换代入梯度，得：\n$$\n\\begin{aligned}\n\\nabla_{\\phi} \\mathcal{L}(\\phi) &=\\nabla_{\\phi} \\int\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] q_{\\phi} d z \\\\\n&=\\nabla_{\\phi} \\int\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right] \\cdot P(\\epsilon) d \\epsilon \\\\\n&=\\nabla_{\\phi} \\mathbb{E}_{P(\\epsilon)}\\left[\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right]\n\\end{aligned}\n$$\n因为$P(\\epsilon)$与$\\phi$的梯度无关，因此可以将其放在期望内部：\n$$\n\\begin{aligned}\n\\nabla_{\\phi} \\mathcal{L}(\\phi) &=E_{P(\\epsilon)}\\left[\\nabla_{\\phi}\\left(\\log P\\left(x_i, z\\right)-\\log q_{\\phi}\\right)\\right] \\\\\n&=E_{P(\\epsilon)}\\left[\\nabla_{z}\\left(\\log P\\left(x_i, z\\right)-\\log q_{\\phi}(z)\\right) \\nabla_{\\phi} z\\right] \\\\\n&=E_{P(\\epsilon)}\\left[\\nabla_{z}\\left(\\log P\\left(x_i, z\\right)-\\log q_{\\phi}(z)\\right) \\nabla_{\\phi} g_{\\phi}\\left(\\epsilon, x_i\\right)\\right]\n\\end{aligned}\n$$\n这样就可以再次采用蒙特卡洛的方法：\n$$\n\\begin{aligned}\n&\\epsilon_l \\sim P(\\epsilon), \\quad l=1,2, \\cdots, L \\\\\n&\\nabla_{\\phi} \\mathcal{L}(\\phi) \\approx \\frac{1}{L} \\sum_{l=1}^{L}\\left[\\nabla_{z}\\left(\\log P\\left(x_i, z\\right)-\\log q_{\\phi}(z)\\right) \\nabla_{\\phi} g_{\\phi}\\left(\\epsilon_l, x_i\\right)\\right]\n\\end{aligned}\n$$\n\n\n### Variational Bayes with message passing\n\n上述的手动推导的方式有些繁琐，但是现在的变分信息传递算法(variational message passing(VMP))可以自动对共轭指数分布族进行推导。对于非共轭指数网络，如果需要以牺牲精度为代价快速逼近，VMP 可能仍然有用。\n\n对于指数族分布，其形式为：\n$$\nP(x\\mid \\eta) = h(x)\\exp\\left(\\eta^T\\phi(x)-A(\\eta)\\right)\n$$\n其中$\\eta$为参数，$\\phi(x)$为充分统计量。\n\n关于指数族分布的标准理论证明了指数分布的充分统计量的性质为：\n$$\n\\langle \\phi(x)\\rangle = \\nabla_{\\eta}A(\\eta)\\mid_\\eta\n$$\n即充分统计量的期望为$A(\\eta)$函数对$\\eta$的导数。\n\n我们用$\\text{pa}(z_i)$表示$z_i$的父结点，$\\text{ch}(z_i)$表示其子结点，$\\text{cop}(z_i;\\text{ch})$表示与$x_i$共同子结点为$\\text{ch}$父结点的集合；$\\text{cop}(z_i)$表示与$z_i$有共同子结点的父结点。我们的更新公式为：\n$$\n\\ln q_i(z_i) = \\langle\\ln P(z_i,\\text{mb}(z_i)),D\\rangle_{q(\\text{mb}(z_i))}\n$$\n其中$\\langle\\rangle_{q(\\text{mb}(z_i))}$相当于对$q(\\text{mb}(z_i))$求期望，而$\\text{mb}$表示马尔可夫毯。\n\n> 马尔可夫毯：在随机变量的全集$U$中，对于给定的变量$\\mathrm{X}\\in \\mathrm{U}$和变量集$\\mathrm{MB}\\subset \\mathrm{U}$，若有：\n> $$\n> \\mathrm{X}\\perp \\{\\mathrm{U-MB-\\{X\\}}\\mid\\mathrm{MB}\\}\n> $$\n> 则称能满足上述条件的最小变量集$\\mathrm{MB}$为$\\mathrm{X}$的马尔可夫毯。\n\n则可以写为：\n$$\n=\\langle\\ln P(\\text{pa}(z_i))+\\ln P(\\text{cop}(z_i))+\\ln P(z_i\\mid\\text{pa}(z_i))+\\ln P(\\text{ch}(z_i)\\mid z_i,\\text{cop}(z_i))\\rangle_{q(\\text{mb}(z_i))}\n$$\n去除和$z_i$无关的常数项：\n$$\n=\\langle \\ln P(z_i\\mid \\text{pa}(z_i))\\rangle_{q(\\text{pa}(z_i))} +\\langle\\ln P(\\text{ch}(z_i)\\mid z_i,\\text{cop}(z_i))\\rangle_{q(\\text{ch}(z_i),\\text{cop}(z_i))}\n$$\n将子结点拆开得：\n$$\n=\\langle \\ln P(z_i\\mid \\text{pa}(z_i))\\rangle_{q(\\text{pa}(z_i))} +\\sum_{\\text{ch}\\in\\text{ch}(z_i)}\\langle\\ln P(\\text{ch}\\mid z_i,\\text{cop}(z_i))\\rangle_{q(\\text{ch},\\text{cop}(z_i))}\n$$\n我们将会将这两部分分开考虑\n\n#### Messages from parents\n\n共轭指数节点$z_i$由自然参数向量$\\phi_i$参数化。通过这些节点的定义：\n$$\n\\begin{aligned}\n\\langle\\ln P(z_i\\mid \\text{pa}(z_i))_{q(\\text{pa}(z_i))} &= \\langle \\phi_i\\mu(z_i) + f_i(z_i)+g_i(\\phi_i)\\rangle_{q(\\text{pa}(z_i))}\\\\\n&=\\langle\\phi_i\\rangle_{q(\\text{pa}(z_i))}\\mu_i(z_i)+f_i(z_i)+\\langle g(\\phi_i)\\rangle_{q(\\text{pa}(z_i))}\n\\end{aligned}\n$$\n由于$\\phi$和$g$是父节点充分统计量的多线性函数（通过构造），并且使用平均场假设，我们可以简单地采用它们的公式（定义为以父节点的单个值为条件）并将期望替换为充分统计，根据需要得到整个表达式的期望值。因此$z_i$的父结点只需要将它们的充分统计期望作为信息传递给$z_i$。\n\n#### Messages to parents\n\n指数族的一个关键性质是我们可以通过将其自然参数相加来得到相似分布的乘积：\n$$\n\\begin{aligned}\n&\\exp\\left[\\phi_1\\mu(z_i)+f(z_i)+g(\\phi_1)\\right]\\cdot\\exp\\left[\\phi_2\\mu(z_i)+f(z_i)+g(\\phi_2)\\right]\\\\\n&= \\exp\\left[(\\phi_1+\\phi_2)\\mu(z_i)+f(z_i)+g(\\phi_1+\\phi_2)\\right]\n\\end{aligned}\n$$\n第二个性质是关于共轭，$\\phi$和$g$在父结点的充分统计量中也是多线性的。因此我们总是可以通过找到函数$\\phi_{ij},f_j,g_{ij}$来重新组合公式是其像是一个父结点$z_j\\in\\text{pa}(z_i)$的函数：\n$$\n\\left\\langle\\ln P\\left(z_{i} \\mid \\text{pa}\\left(z_{i}\\right)\\right)\\right\\rangle_{q\\left(\\text{pa}\\left(z_{i}\\right)\\right)}=\\left\\langle\\phi_{i j} u_{j}\\left(z_{j}\\right)+f_{i j}\\left(z_{j}\\right)+g_{i j}\\left(\\phi_{i j}\\right)\\right\\rangle_{q\\left(\\text{pa}\\left(z_{i}\\right)\\right)}\n$$\n和以前一样，我们可以通过使用多线性属性来处理期望，以将所有期望推到充分统计量附近。因此，从父结点的角度来看，这是根据其子结点和共同父结点的充分统计期望来写的。因此，我们可以传递一个似然信息，包括：\n$$\n\\phi_{ij}\\left(\\langle\\mu(z_i)\\rangle,\\{\\langle\\mu(\\text{cop})\\rangle\\}_{\\text{cop}\\in\\text{cop}(z_j;z_i)}\\right)\n$$\n然后，父结点可以通过第一个属性将这些简单地添加到其先前的参数中。\n\n### Example\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/VBI1.jpg)\n\n则：\n$$\n\\ln P(\\mu\\mid m,\\beta) = \\begin{bmatrix}m\\beta&-\\beta/2\\end{bmatrix}\\cdot \\begin{bmatrix}\\mu\\\\\\mu^2\\end{bmatrix} - \\frac{1}{2}(-\\ln \\beta + \\beta m^2+\\ln2\\pi)\n$$\n其中$\\phi(x) = \\begin{bmatrix}\\mu\\\\\\mu^2\\end{bmatrix}, \\eta^T = \\begin{bmatrix}m\\beta&-\\beta/2\\end{bmatrix},A(\\eta) = \\frac{1}{2}(-\\ln \\beta + \\beta m^2+\\ln2\\pi)$。\n\n所以很容易得到充分统计量的期望为：\n$$\n\\left\\langle \\begin{bmatrix}\\mu\\\\\\mu^2\\end{bmatrix}\\right\\rangle = \\nabla A(\\eta) = \\begin{bmatrix}\\mu\\\\\\mu^2+\\beta^{-1}\\end{bmatrix}\n$$\n\n\n","tags":["贝叶斯","算法"],"categories":["文献阅读"]},{"title":"指数分布族","url":"/2022/07/10/EXP/","content":"\n## Exponential Family Distribution\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/EX1.png)\n\n> 课程地址：https://www.bilibili.com/video/BV1QW411y7D3?spm_id_from=333.337.search-card.all.click&vd_source=6177c61c946280bb88c727585de76bc8\n\n<!--more-->\n\n### 背景\n\n指数分布族是可以写为如下形式的分布：\n$$\nP(x\\mid \\eta) = h(x)\\exp\\left(\\eta^T\\phi(x)-A(\\eta)\\right)\n$$\n其中$\\eta$为参数向量，$x\\in \\mathbb{R}^p$，$A(\\eta)$为对数配分函数(log partition function)。\n\n下面我们解释一下**配分函数**，配分函数可以理解为**归一化因子**，例如我们在无向图模型中经常用到的：\n$$\nP(X\\mid \\theta) = \\frac{1}{Z}\\hat{P}(X\\mid \\theta)\n$$\n其中$\\hat{P}(X\\mid \\theta)$是我们构造出来的分布，但是概率分布必须满足和为$1$，所以我们在前面添加归一化因子使得：\n$$\nZ = \\int_x \\hat{P}(x\\mid \\theta)dx\n$$\n可以看出$Z$与$X$无关，那为什么$A(\\eta)$称为对数配分函数呢？这是因为：\n$$\n\\begin{aligned}\nP(x\\mid \\eta) &= h(x)\\exp\\left(\\eta^T\\phi(x)-A(\\eta)\\right)\\\\\n&= \\frac{1}{\\exp(A(\\eta))}h(x)\\exp(\\eta^T\\phi(x))\n\\end{aligned}\n$$\n所以$Z = \\exp(A(\\eta))\\Rightarrow A(\\eta)=\\ln Z$，所以其被称为对数配分函数。\n\n其中$\\phi(x)$为**充分统计量**。充分统计量指的是能够包含样本中所有信息的统计量。\n\n如对于数据$x_1,\\cdots,x_N$，我们假设其服从于高斯分布，那么其充分统计量就为：\n$$\n\\phi(x) = \\begin{bmatrix}\\sum_{i=1}^Nx_i\\\\\\sum_{i=1}^Nx_i^2\\end{bmatrix}\n$$\n因为有了这两个统计量我们就可以求出其**均值**和**方差**。\n\n在贝叶斯推断中我们常常遇到这样的问题：\n$$\nP(Z\\mid X) = \\frac{P(X\\mid Z)P(Z)}{\\int_ZP(X\\mid Z)P(Z)dZ}\n$$\n有时候积分很难算出，即使积分算出了，$P(Z\\mid X)$的形式可能很复杂，我们无法求解其期望和方差，这时候我们可以采用采样的方法(MCMC)或者通过变分推断来寻找接近$P(Z\\mid X)$的概率分布$Q(X)$。\n\n但是指数族分布可以采用共轭的性质。\n\n指数族分布与广义线性模型，广义线性模型的重要组成部分为：\n\n1. 线性组合，如$w^Tx$\n2. link function：为激活函数的逆函数\n3. 指数族分布：$y\\mid x\\sim$指数族分布\n\n概率图模型中非常重要的一组模型为无向图RBF，与指数族分布具有非常重要的关系。\n\n另外当分布为指数族分布时，变分推断可见极大地简化。\n\n### 高斯分布的指数族形式\n\n高斯分布的形式为：\n$$\n\\begin{aligned}\nP(x\\mid\\theta) &= \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right)\\quad \\theta = (\\mu,\\sigma^2)\\\\\n&=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}(x^2-2\\mu x+\\mu^2)\\right)\\\\\n&=\\exp\\left(\\log(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\right)\\exp\\left(-\\frac{1}{2\\sigma^2}\\begin{pmatrix}-2\\mu&1\\end{pmatrix}\\begin{pmatrix}x\\\\x^2\\end{pmatrix}-\\frac{\\mu^2}{2\\sigma^2}\\right)\\\\\n&=\\exp\\left(\\underbrace{\\begin{pmatrix}\\frac{\\mu}{\\sigma^2}&-\\frac{1}{2\\sigma^2}\\end{pmatrix}}_{\\eta^T}\\cdot\\underbrace{\\begin{pmatrix}x\\\\x^2\\end{pmatrix}}_{\\phi(x)}-\\underbrace{\\left(\\frac{\\mu^2}{2\\sigma^2}+\\frac{1}{2}\\log2\\pi\\sigma^2\\right)}_{A(\\eta)}\\right)\n\\end{aligned}\n$$\n其中我们令$\\eta_1=\\frac{\\mu}{\\sigma^2},\\eta_2=-\\frac{1}{2\\sigma^2}$。则$\\sigma^2=-\\frac{1}{2\\eta_2},\\mu=-\\frac{\\eta_1}{2\\eta_2}$。代入$A(\\eta)$，得：\n$$\nA(\\eta) = -\\frac{\\eta_1^2}{4\\eta_2}+\\frac{1}{2}\\log\\left(-\\frac{\\pi}{\\eta_2}\\right)\n$$\n\n### 对数配分函数与充分统计量的关系\n\n\n\n我们之前提到过：\n$$\n\\exp(A(\\eta)) = \\int_x h(x)\\exp(\\eta^T\\phi(x))dx\n$$\n两边同时对$\\eta$求导，得：\n$$\n\\begin{aligned}\n\\exp(A(\\eta))\\cdot A^\\prime(\\eta) &= \\frac{\\partial}{\\partial \\eta}(\\int h(x)\\exp(\\eta^T\\phi(x))dx)\\\\\n&= \\int_xh(x)\\exp(\\eta^T\\phi(x))\\phi(x)dx\n\\end{aligned}\n$$\n两边同除以$A^\\prime(\\eta)$，得\n$$\n\\begin{aligned}\nA^\\prime(\\eta) &= \\frac{\\int_xh(x)\\exp(\\eta^T\\phi(x))\\phi(x)dx}{\\exp(A(\\eta))}\\\\\n&=\\int_x \\underbrace{h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))}_{P(x\\mid\\eta)}\\phi(x)dx\\\\\n&= \\mathbb{E}_{P(x\\mid\\eta)}[\\phi(x)]\n\\end{aligned}\n$$\n所以$A^\\prime(\\eta) = \\mathbb{E}_{P(x\\mid \\eta)}[\\phi(x)]$。\n\n同样地，我们也可以研究一下二阶导，对式子\n$$\nA^\\prime(\\eta) =\\int_x \\underbrace{h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))}_{P(x\\mid\\eta)}\\phi(x)dx\n$$\n两边同时求导得：\n$$\n\\begin{aligned}\nA^{\\prime\\prime}(\\eta) &= \\int_x \\underbrace{h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))}_{P(x\\mid\\eta)}(\\phi(x)-A^{\\prime}(\\eta))\\phi(x)dx\\\\\n&= \\int_xP(x\\mid\\eta)(\\phi(x)-\\mathbb{E}_{P(x\\mid\\eta)}[\\phi(x)])\\phi(x)dx\\\\\n&= \\int_x P(x\\mid \\eta)\\phi(x)^2dx - \\mathbb{E}_{P(x\\mid\\eta)}[\\phi(x)])\\int_xP(x\\mid \\eta)\\phi(x)dx\\\\\n&= \\mathbb{E}_{P(x\\mid\\eta)}[\\phi(x)^2] - \\left(\\mathbb{E}_{P(x\\mid \\eta)}[\\phi(x)]\\right)^2\\\\\n&=\\operatorname{Var}[\\phi(x)]\n\\end{aligned}\n$$\n\n### 极大似然估计与充分统计量\n\n假设我们的数据为：$D=\\{x_1,x_2,\\cdots,x_N\\}$，所以我们有：\n$$\n\\begin{aligned}\n\\eta_{\\text{mle}} &= \\arg\\max\\log P(D\\mid \\eta)\\\\\n&=\\arg\\max \\log\\prod_{i=1}^N P(x_i\\mid \\eta)\\\\\n&=\\arg\\max \\sum_{i=1}^N\\log P(x_i\\mid \\eta)\\\\\n&=\\arg\\max\\sum_{i=1}^N\\log\\left[h(x_i)\\exp(\\eta^T\\phi(x_i)-A(\\eta))\\right]\\\\\n&= \\arg\\max\\sum_{i=1}^N\\left[\\log h(x_i)+\\eta^T\\phi(x_i)-A(\\eta)\\right]\\\\\n&= \\arg\\max\\sum_{i=1}^N(\\eta^T\\phi(x_i)-A(\\eta))\n\\end{aligned}\n$$\n我们对其求导，得：\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\eta}\\left(\\sum_{i=1}^N\\eta^T\\phi(x_i)-A(\\eta)\\right)&=\\sum_{i=1}^N\\frac{\\partial}{\\partial \\eta}(\\eta^T\\phi(x_i)-A(\\eta))\\\\\n&=\\sum_{i=1}^N\\phi(x_i)-A^{\\prime}(\\eta)\\\\\n&=\\sum_{i=1}^N\\phi(x_i)-NA^{\\prime}(\\eta)\n\\end{aligned}\n$$\n令导数等于$0$，得\n$$\nA^{\\prime}(\\eta_{\\text{mle}}) = \\frac{1}{N}\\sum_{i=1}^N\\phi(x_i)\n$$\n这样我们就可以求出$\\eta_{\\text{mle}}$，可以看出$\\eta_{\\text{mle}}$仅与$\\phi(x)$有关，即确定了$\\phi(x)$即确定了$\\eta_{\\text{mle}}$，即确定了分布，更加验证了$\\phi(x)$充分统计量的结论。\n\n### 最大熵角度\n\n假设一个事件发生的概率为$p$，其信息量为$-\\log p$。熵的概念就是信息量关于分布本身的期望：\n$$\n\\begin{aligned}\n\\mathbb{E}_{p(x)}[-\\log p] &= -\\int_x p(x)\\log p(x)dx\\\\\n&= -\\sum_x p(x)\\log p(x)\n\\end{aligned}\n$$\n最大熵的思想通俗来说就是等可能的，当我们对一个事件一无所知时，我们一般假设其是等可能的。下面看一个例子：\n\n我们用$H[P]$来表示熵：\n$$\nH[p] = -\\sum_x p(x)\\log p(x)\n$$\n我们假设$x$是离散的，$x$可以取值的个数为$K$，概率分别对应于$p_1,\\cdots,p_K$，并且$\\sum_{i=1}^K p_i=1$。所以其熵为：\n$$\nH[p] = -\\sum_{i=1}^K p_i\\log (p_i)\n$$\n我们令其最大，即变为了优化问题：\n$$\n\\begin{aligned}\n&\\min \\sum_{i=1}^K p_i\\log p_i\\\\\n&\\text{s.t. }\\sum_{i=1}^K p_i=1\n\\end{aligned}\n$$\n我们可以直接用拉格朗日乘子法进行求解，定义：\n$$\n\\mathcal{L}(p,\\lambda) = \\sum_{i=1}^K p_i\\log(p_i)+\\lambda(1-\\sum_{i=1}^Kp_i)\n$$\n对$p_i$求导，得：\n$$\n\\frac{\\partial \\mathcal{L}(p,\\lambda)}{\\partial p_i} = \\log(p_i)+p_i\\cdot\\frac{1}{p_i}-\\lambda\n$$\n所以：\n$$\np_i = \\exp(\\lambda-1)\n$$\n对于每个$p_i$都是如此，所以$p_1=p_2=\\cdots=p_K=\\frac{1}{K}$，所以其为等可能的。\n\n\n\n最大熵原理：在满足既定事实的前提下，具有最大熵的分布即为我们想要的分布。在机器学习中，我们的既定事实即为数据，假设我们的数据为$D=\\{x_1,\\cdots,x_N\\}$。\n\n在这里我们引入经验分布的概念，其是对已知样本的描述，其定义为：\n$$\n\\hat{p}(X=x) = \\frac{\\text{count}(x)}{N}\n$$\n因为分布$\\hat{p}$我们已经求出来了，所以对于$x$的任意函数$f(x)$向量，我们也能求其期望：\n$$\n\\mathbb{E}_{\\hat{p}}[f(x)] = \\Delta(\\text{已知})\n$$\n这个就是我们的**已知约束**。\n\n下面我们求满足上述约束的最大熵的分布，这就变成了优化问题：\n$$\n\\begin{aligned}\n&\\min \\sum_x p(x)\\log p(x)\\\\\n&\\text{s.t. } \\sum_x p(x)=1\\\\\n&\\quad\\quad \\mathbb{E}_{\\hat{p}} [f(x) ]= \\mathbb{E}_p[f(x)] = \\Delta\n\\end{aligned}\n$$\n定义拉格朗日乘子：\n$$\n\\mathcal{L}(p,\\lambda_0,\\lambda) = \\sum_x p(x)\\log p(x) + \\lambda_0(1-\\sum_x p(x))+\\lambda^T(\\Delta-\\mathbb{E}_p[f(x)])\n$$\n对$p(x)$求导得：\n$$\n\\frac{\\mathcal{L}}{\\partial p(x)} =(\\log p(x)+1)-\\lambda_0-\\lambda^T f(x)\n$$\n令其等于$0$，得\n$$\n\\log p(x) = \\lambda^T f(x) + \\lambda_0-1\n$$\n所以\n$$\np(x) = \\exp\\left(\\lambda^T f(x) - (1-\\lambda_0)\\right)\n$$\n为指数族分布。\n\n\n\n","tags":["概率论"],"categories":["课程笔记"]},{"title":"狄利克雷过程","url":"/2022/07/06/BNP/","content":"\n<p align=\"center\">\n    <img src=\"https://img2.baidu.com/it/u=2682475456,642314187&fm=253&fmt=auto&app=138&f=JPEG?w=799&h=500\" style=\"zoom: 100%;\" />\n</p>\n\n> 参看文献：\n>\n> 1. [徐亦达老师课程](https://www.bilibili.com/video/BV1Tp411R7Sf?spm_id_from=333.337.search-card.all.click&vd_source=6177c61c946280bb88c727585de76bc8)\n> 2. [狄利克雷过程文献](http://hil.t.u-tokyo.ac.jp/~kameoka/SAP/papers/Teh2010a.pdf)\n> 3. [A Tutorial on Bayesian Nonparametric Models](https://www.sciencedirect.com/science/article/abs/pii/S002224961100071X)\n\n<!--more-->\n\n## 狄利克雷过程\n\n### Introduction\n\n考虑下列问题，假设我们用高斯混合模型来做聚类。假设我们的数据为$x_1,x_2,\\cdots,x_N$，那我们的似然函数的对数为：\n$$\n\\sum_{i=1}^N\\log\\sum_{l=1}^K\\alpha_i\\mathcal{N}(\\mu_i,\\sigma_i^2)\n$$\n但是我们需要事先确定聚类的个数，但是在很多情况下聚类的个数并不是那么容易确定，我们需要从数据中学习到聚类的个数。一个方法是我们将聚类的数目$K$也作为一个参数，那么我们的参数$\\theta = (K,\\theta_1,\\sigma_1,\\cdots,\\theta_K,\\sigma_K)$。我们的优化问题变为：\n$$\n\\hat{\\theta} = \\arg\\max_{\\theta}\\sum_{i=1}^N\\log\\sum_{l=1}^K\\alpha_i\\mathcal{N}(\\mu_i,\\sigma_i^2)\n$$\n但是我们很容易发现当$K=N$，$\\mu_i$为数据的值，$\\sigma_i=0$的时候似然函数达到最大，即每一个数据都是一个类，这不是我们想要的。\n我们的一个方法是假设每个数据$x_i$都来自于参数为$\\theta_i$的一个分布，而$\\theta_i\\sim H(\\theta)$，其中分布$H(\\theta)$为连续分布，但是这样会参在新的问题：因为$H(\\theta)$为连续分布，所以$P(\\theta_i=\\theta_j)=0,i\\neq j$。所以这样每个数据来自的分布都不一样，又回到了之前提到的$K=N$的问题了。所以我们令$\\theta$来自一个离散分布$G(\\theta)$，而$G\\sim \\text{DP}(\\alpha,H)$，其中DP表示狄利克雷过程，而$H$为之前的连续分布，$\\alpha>0$为常数，其反映$G$的离散程度，越大表示离散程度越小，当$\\alpha\\rightarrow0$时，$G$离散程度最大，为一个点；当$\\alpha\\rightarrow \\infty$时，$G\\approx H$。\n\n> $H$也不一定是连续的，其被称为base measure。\n\n注意这里的$G$为一个random measure，我们每次从$\\text{DP}(\\alpha,H)$中采样得到的不是一个数值，而是一个分布。假设我们采集到的分布为：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/DP1.png)\n\n> 其中$G_1,G_2$为两次采样产生的分布，上面的棍子表示概率密度，其和为$1$。我们将其分为$a_1,a_2,\\cdots,a_d$等$d$个区域，其中每个区域的总概率密度符合狄利克雷分布，即\n> $$\n> (G(a_1),G(a_2),\\cdots,G(a_d))\\sim \\text{Dir}(\\alpha H(a_1),\\alpha H(a_2),\\cdots,\\alpha H(a_d))\n> $$\n> 这就是狄利克雷过程的定义。\n\n关于狄利克雷分布：\n$$\nP(x_1,\\cdots,x_i,\\cdots,x_K)\\sim \\text{Dir}(\\alpha_1,\\cdots,\\alpha_i,\\cdots,\\alpha_K)\n$$\n则\n$$\n\\begin{aligned}\n\\mathbb{E}[x_i]  &= \\frac{\\alpha_i}{\\sum_k \\alpha_k}\\\\\n\\text{Var}[x_i]&=\\frac{\\alpha_i(\\sum_k\\alpha_k-\\alpha_i)}{(\\sum_k\\alpha_k)^2(\\sum_{k}\\alpha_k+1)}\n\\end{aligned}\n$$\n将其带入到狄利克雷过程中，得：\n$$\n\\mathbb{E}[G[a_i]] = \\frac{\\alpha H(a_i)}{\\sum_k\\alpha H(a_k)} = H(a_i)\n$$\n\n$$\n\\text{var}[G[a_i]] = \\frac{\\alpha H(a_i)(\\alpha-\\alpha H(a_i))}{\\alpha^2(\\alpha+1)} = \\frac{H(a_i)(1-H(a_i))}{\\alpha+1}\n$$\n\n我们之前说过关于$\\alpha$的性质。现在我们来看一下，均值(期望)与$\\alpha$无关，当$\\alpha\\rightarrow \\infty$是，方差趋近于$0$，这说明不管我们怎么划分，在每个$a_i$处，$G(a_i)=H(a_i)$，说明$G(x)=H(x)$，即$G(x)$是连续的是最不离散的版本；如果$\\alpha=0$，则$\\text{Var}=H(a_i)(1-H(a_i))$，这正是伯努利分布的方差，因此在每个划分上我们都可以用一根棍来表示它们(包括不划分)，这是最离散的版本。\n\n### Construction\n\n那我们如何构建$G$呢？即如何从$H$中采样得到$G$呢？我们采用`stick-breaking construction`的方法来产生$G$。其构建方式为：\n\n1. 从$H$中采样得到$\\theta_1$，即$\\theta_1\\sim H$\n2. 采样$\\beta_1\\sim\\text{Beta}(1,\\alpha)$\n3. 权重$\\pi_1=\\beta_1$\n4. 采样$\\theta_2\\sim H$\n5. 采样$\\beta_2\\sim \\text{Beta}(1,\\alpha)$\n6. 权重$\\pi_2 = (1-\\pi)\\beta_2$\n   以此类推，这样权重$\\pi_2$相当于是从取完$\\pi_1$剩下的权重中取得。\n\n我们在看一下关于$\\alpha$得一些内容，当$\\alpha=0$时，$\\mathbb{E}(\\beta_i)=1,\\text{Var}(\\beta_i)=0$，所以一次就把权重全部采完，即只产生一个样本，对应于最离散的情况，而当$\\alpha=\\infty$时，$\\mathbb{E}(\\beta_i)=0$，相当于连续分布的情况。我们常将此采样方法写为$\\pi \\sim \\text{GEM}(\\alpha)$。\n\n### Property\n\n下面我们再回顾一下。对于狄利克雷过程，有如下性质：\n$$\nG\\sim \\text{DP}(\\alpha,H)\\Leftrightarrow (G(a_1),\\cdots,G(a_n))\\sim \\text{DIR}(\\alpha H(a_1),\\cdots,\\alpha H(a_n)),\\quad \\text{for any partitions }a_1,\\cdots,a_n\n$$\n总结之前讲过的，我们有：\n$$\nG\\sim \\text{DP}(\\alpha,H)\n$$\n\n$$\n\\theta_1,\\cdots,\\theta_N\\sim G\n$$\n\n$$\nX_i\\sim F(\\theta_i)\n$$\n\n其图模型为：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/DP2.png)\n\n下面我们研究一下$G$的后验分布$P(G\\mid \\theta_1,\\cdots,\\theta_N)$：\n$$\nP(G\\mid \\theta_1,\\cdots,\\theta_N)\\propto P(\\theta_1,\\cdots,\\theta_N\\mid G)P(G)\n$$\n在研究之前我们先看一个关于狄利克雷分布和多项式分布的例子：\n假设\n$$\n\\begin{aligned}\np_1,\\cdots,p_N&\\sim\\text{DIR}(\\alpha_1,\\cdots,\\alpha_N)\\\\\nn_1,\\cdots,n_N&\\sim\\text{Mult}(p_1,\\cdots,p_N)\n\\end{aligned}\n$$\n那么\n$$\n\\begin{aligned}\nP(p_1,\\cdots,p_N\\mid n_1,\\cdots,n_N)&\\propto\\left(\\frac{\\Gamma(\\sum_{i=1}^N\\alpha_i)}{\\prod_{i=1}^N\\Gamma(\\alpha_i)}\\prod P_i^{\\alpha_i-1}\\right)\\left(\\frac{(\\sum_{i=1}^Nn_i)!}{n_1!\\cdots n_N!}\\prod_{i=1}^NP_i^{n_i}\\right)\\\\&\\propto \\prod_{i=1}^NP_i^{\\alpha_i+n_i-1}\\\\ &= \\text{DIR}(\\alpha_1+n_1,\\cdots,\\alpha_N+n_N)\n\\end{aligned}\n$$\n\n### Posterior\n\n有了前面的指示，下面我们来看一下后验分布：\n对于任何划分\n$$\n\\begin{aligned}\nP(G(a_1),\\cdots,G(a_K)\\mid \\theta_1,\\cdots,\\theta_K)&\\propto P(\\theta_1,\\cdots,\\theta_K\\mid G(a_1),\\cdots,G(a_K))P(G)\\\\\n&=\\text{Mult}(n_1,\\cdots,n_K)\\text{DIR}(\\alpha H(a_1),\\cdots,\\alpha H(a_K))\\\\\n&= \\text{Dir}(n_1+\\alpha H(a_1),\\cdots,n_K+\\alpha H(a_K))\\\\\n&= \\text{DP}\\left(\\alpha+n,\\frac{\\alpha H+\\sum_{i=1}^K\\delta_{\\theta_i}}{\\alpha+n}\\right)\n\\end{aligned}\n$$\n其中$n=\\sum_{i=1}^K n_i，G=\\sum_{i=1}^\\infty\\pi_i\\delta_{\\theta_i}$。最后一步是怎么来的呢？\n所以我们得到的后验分布为：\n$$\nP(G(a_1),\\cdots,G(a_K))\\sim \\text{Dir}(n_1+\\alpha H(a_1),\\cdots,n_K+\\alpha H(a_K))\n$$\n根据之前讲过的狄利克雷过程的性质，狄利克雷过程的第一个参数是对应的狄利克雷分布的测度和，而第二个参数为归一化后的一个概率分布，理解为狄利克雷分布的参数除以归一化系数。所以第一个参数为：$\\sum_{i=1}^K n_i+\\alpha H(a_i) = \\alpha+n$，而第二个参数为$\\frac{\\alpha H+\\sum_{i=1}^K\\delta_{\\theta_i}}{\\alpha+n}$，其中$\\alpha+n$为归一化参数，而分子$\\sum_{i=1}^N\\delta_{\\theta_i}(a_j)$实际上就是表示$n_j$。\n我们再看一下得到的分布：\n$$\n\\frac{\\alpha H+\\sum_{i=1}^N\\delta_{\\theta_i}}{\\alpha+n} = \\frac{\\alpha}{\\alpha+n}H+\\frac{\\sum_{i=1}^N\\delta_{\\theta_i}}{\\alpha+n}\n$$\n为一个连续的分布加上一个离散的分布，这被称为`spike and slab`。\n\n### Predictive distribution\n\n什么是预测分布呢？预测分布为：\n$$\n\\begin{aligned}\nP(X_i\\mid X_{-i}) &= \\int_w P(X_i,w\\mid X_{-i})dw\\\\\n&= \\int_w P(X_i\\mid w,X_{-i})P(w\\mid X_{-i})dw\\\\\n&= \\int_wP(X_i\\mid w)P(w\\mid X_{-i})dw\n\\end{aligned}\n$$\n其中$X_{-i}$表示去除第$i$项后的$X$。\n对于狄利克雷过程，我们想要求得的为：\n$$\nP(\\theta_i\\mid \\theta_{-i}) = \\int_G P(\\theta_i\\mid G)P(G\\mid \\theta_{-i})dG\n$$\n由此可以看出，我们的预测分布可以看作是后验分布$\\theta_i$在后验分布$P(G\\mid \\theta_{-i})$下的期望，根据狄利克雷分布的性质，其期望为\n$$\n\\frac{\\alpha}{\\alpha+n}H+\\frac{\\sum_{i=1}^N\\delta_{\\theta_i}}{\\alpha+n}\n$$\n所以其预测分布等于后验分布。\n\n$\\theta_1,\\theta_2,\\cdots$预测分布的序列被称为`Blackwell-MacQueen urn scheme`。这个名字来源于一个隐喻。特别地，在$\\Theta$中的每一个值都是唯一的颜色，并且抽样$\\theta\\sim G$来给球上色。另外我们有一个盒子来装之前看过的球。起初在盒子里没有球，我们从$H$中取颜色，$\\theta_1\\sim H$，给球上色并将其放在盒子里。在之后的步骤中，如在$n+1$步中，我们要么以$\\frac{\\alpha}{\\alpha+n}$抽取一个新颜色($\\theta_{n+1}\\sim H$)，给球染色并将其放到盒子中，或者以概率$\\frac{n}{\\alpha+n}$从盒子中取出一个球，将新球涂成它的颜色(从经验分布中抽样)并放到盒子里。\n\n`Blackwell-MacQueen urn scheme`可以被用来证明DP的存在。我们可以在序列$\\theta_1,\\theta_2,\\cdots$上构建分布，通过迭代地在给定$\\theta_1,\\cdots,\\theta_{i-1}$的条件下采样$\\theta_i$。对于$n\\ge1$令\n$$\nP(\\theta_1,\\cdots,\\theta_n) = \\prod_{i=1}^nP(\\theta_i\\mid \\theta_1,\\cdots,\\theta_{i-1})\n$$\n可以得到这个随机序列是无限可交换的。也就是说，对于每一个$n$，生成$\\theta_1,\\cdots,\\theta_n$的概率等于以任何顺序采样得到它们的概率。\n\n下面我们来证明一下，令$I_k$表示第$k$类的索引，$N_k$表示第$k$类的样本数，那么在第$k$类的样本的上述关于$\\theta$的概率为：\n$$\n\\frac{\\alpha\\cdot1\\cdot2\\cdots(N_k-1)}{(I_{k,1}-1+\\alpha)(I_{k,2}-1+\\alpha)\\cdots(I_{k,N_k)}-1+\\alpha)}\n$$\n第一项是因为我们第一次到新的类$k$，所以概率为$\\frac{\\alpha}{I_{k,1}-1+\\alpha}$，第二项是因为$k$已经出现了，所以概率为$\\frac{1}{(I_{k,2}-1+\\alpha)}$，以此类推。对于所有的类：\n$$\np(\\theta_{1:N}) = \\prod_{k=1}^K\\frac{\\alpha(N_k-1)!}{(I_{k,1}-1+\\alpha)(I_{k,2}-1+\\alpha)\\cdots(I_{k,N_k}-1+\\alpha)}\n$$\n注意所有$I_k$的并为所有的索引，我们将索引合并，得：\n$$\np(\\theta_{1:N}) = \\frac{\\alpha^K\\prod_{k=1}^K(N_k-1)!}{\\prod_{i=1}^N(i-1+\\alpha)}\n$$\n所以很明显看出来是无限可交换的。\n\n\n\n现在`de Finetti's theorem`说明对于任何无限可交换序列$\\theta_1,\\theta_2,\\cdots$存在一个随机分布$G$使得序列可以被分解为独立同分布地从下列采样：\n$$\nP(\\theta_1,\\cdots,\\theta_n) = \\int\\prod_{i=1}^n G(\\theta_i)dP(G)\n$$\n在我们的设置中，随机分布$P(G)$的先验正是狄利克雷过程$\\text{DP}(\\alpha,H)$，因此DP存在。\n\n### Clustering, Partitions and the Chinese Restaurant Process\n\nDP的离散性质也暗示了聚类的特性。现在我们假设$H$是光滑的，因此所有的重复值都由于DP的离散性质而不是$H$自身。因此采样得到的值有重复的，令$\\theta_1^\\star,\\cdots,\\theta_m^\\star$为$\\theta_1,\\cdots,\\theta_n$去除重复值后的结果并且$n_k$为$\\theta_k^\\star$重复的次数。预测分布可以被等价地写为：\n$$\n\\theta_{n+1}\\mid \\theta_1,\\cdots,\\theta_n\\sim \\frac{1}{\\alpha+n}\\left(\\alpha H+\\sum_{k=1}^m n_k\\delta_{\\theta_k^\\star}\\right)\n$$\n\n\n我们可以通过查看由聚类引起的划分来进一步研究DP的聚类属性。$\\theta_1,\\cdots,\\theta_n$去除重复值后将对集合$[n]=\\{1,\\cdots,n\\}$分区引进了聚类使得在每一个类$k$中，$\\theta_i$取相同的值$\\theta_k^\\star$。\n\n分区的分布被称为中国餐馆过程(CRP)。在这个情境下我们有一个中国餐馆，里面有无穷多个桌子，每个桌子可以坐无穷多个人。第一个人进入餐馆坐在第一个位置，第二个人可以坐在第一个人的位置或者坐在新的位置。一般地，第$n+1$个人要么以正比于$n_k$的概率坐在已经有人的位置$k$，或者以正比于$\\alpha$的概率坐在新的位置。\n\n我们也可以估计聚类数目的期望。假设共有$n$个观测，对于$i\\ge1$，观测$\\theta_i$以$\\frac{\\alpha}{\\alpha+i-1}$的概率取新的值，所以聚类数$m$的期望为：\n$$\n\\mathbb{E}[m\\mid n] = \\sum_{i=1}^n\\frac{\\alpha}{\\alpha+i-1}\\in \\mathcal{O}(\\alpha \\log n)\n$$\n\n\n因为$\\theta$为离散值，具有相同$\\theta$值得数据表示属于同一类，我们可以用$Z$来表示属于哪一类。即计算$P(Z_i\\mid Z_{-i})$。有多少类只与参数$\\alpha$有关，而$\\theta$的位置(值)则与$H$有关。\n\n\n\n我们下面计算：\n$$\nP(Z_i=m\\mid Z_{-i}) = \\frac{P(Z_i=m,Z_{-i})}{P(Z_{-i})}\n$$\n我们如何将其与狄利克雷过程结合起来呢？将其与狄利克雷过程结合起来很难，因为狄利克雷过程有无限多的项，我们可以假设其外$K$项，然后再将$K$取无穷。我们用如下方法：\n$$\n\\begin{aligned}\nP(Z_i=m\\mid Z_{-i}) &= \\frac{P(Z_i=m,Z_{-i})}{P(Z_{-i})}\\\\\n&=\\frac{\\int_{P_1,\\cdots,P_K}P(Z_i=m,Z_{-i}\\mid P_1,\\cdots,P_K)\\text{DIR}(\\alpha/K,\\cdots,\\alpha/K)dP}{\\int_{P_1,\\cdots,P_K}P(Z_{-i}\\mid P_1,\\cdots,P_K)\\text{DIR}(\\alpha/K,\\cdots,\\alpha/K)dP}\n\\end{aligned}\n$$\n关于积分的计算就用到我们之前的多项式分布和狄利克雷分布共轭的知识了：\n$$\n\\begin{aligned}\n&\\int_{p_1,\\cdots,p_K}P(n_1,\\cdots,n_K\\mid p_1,\\cdots,p_K)P(p_1,\\cdots,p_K\\mid \\alpha_1,\\cdots,\\alpha_K)dP\\\\\n&=\\frac{n!}{n_1!\\cdots n_K!}\\frac{\\Gamma(\\sum\\alpha_i)}{\\prod\\Gamma(\\alpha_i)}\\int_{p_1,\\cdots,p_K}\\prod_{i=1}^K p_i^{n_i+\\alpha_i-1}dp\\\\\n&=\\frac{n!}{n_1!\\cdots n_K!}\\frac{\\Gamma(\\sum\\alpha_i)}{\\prod\\Gamma(\\alpha_i)}\\frac{\\prod\\Gamma(\\alpha_i+n_i)}{\\Gamma(\\sum\\alpha_i+n)}\n\\end{aligned}\n$$\n我们将其应用到分子和分母上，首先定义符号：$n_{l,-i}$表示去除第$i$个数据后属于第$l$类的个数。我们知道第二项：\n$$\n\\frac{\\Gamma(\\sum\\alpha_i)}{\\prod\\Gamma(\\alpha_i)}\n$$\n只与先验有关，所以分子分母都一样。\n\n我们先看第一项，因为在我们的情景下，即便类数相等，每个类的个数相等，但是相同个体不属于同一个类，这两种划分方法得到的第一项的值是相同的，但是在我们的情境下是不同的，所以第一项不应该存在。\n\n第三项代入为：\n$$\n\\frac{\\Gamma(\\alpha/K+n_{m,-i}+1)\\prod_{l\\neq i} \\Gamma(\\alpha/K+n_{l,-i})}{\\Gamma(\\alpha+n)}\\cdot \\frac{\\Gamma(\\alpha+n-1)}{\\prod\\Gamma(\\sum_l \\alpha/K+n_{l,-i})}\n$$\n伽马函数具有如下性质：\n$$\n\\Gamma(x) = (x-1)\\Gamma(x-1)\n$$\n上式化简得到：\n$$\n\\frac{n_{m,-i}+\\frac{\\alpha}{K}}{n+\\alpha-1}\n$$\n\n\n当$K\\rightarrow \\infty$为\n$$\n\\frac{n_{m,-i}}{n+\\alpha-1}\n$$\n对$m$进行求和得到：\n$$\n\\sum_m\\frac{n_{m,-i}}{n+\\alpha-1} = \\frac{n-1}{n+\\alpha-1}\\neq1\n$$\n这与概率密度的定义不同，所以有$\\frac{\\alpha}{n+\\alpha-1}$的概率属于新的一个类，这就是**中国餐馆过程**。\n\n### Dirichlet Process Mixture Models\n\n狄利克雷混合模型可以写为：\n$$\n\\begin{aligned}\n&\\pi \\mid \\alpha \\sim \\operatorname{GEM}(\\alpha)\\\\\n&\\theta_{k}^{*} \\mid H \\sim H\\\\\n&z_{i} \\mid \\pi \\sim \\operatorname{Mult}(\\pi)\\\\\n&x_{i} \\mid z_{i},\\left\\{\\theta_{k}^{*}\\right\\} \\sim F\\left(\\theta_{z_{i}}^{*}\\right)\n\\end{aligned}\n$$\n狄利克雷混合模型为无限混合模型，指的是具有无限可数个类的混合模型。与事先确定了类的有限混合模型不同，狄利克雷混合模型会根据数据确定聚类的数目。\n\n> 狄利克雷过程为无参贝叶斯方法的一种，为什么是无参？我们理解是狄利克雷过程是分布的先验，而狄利克雷过程采样得到的分布为我们产生数据的分布，在有参数的模型中此分布有参数(感觉像废话)，而狄利克雷过程产生的分布无法用参数表示故为无参数模型。我们将分布作为概率的一部分，并且存在自己的先验分布，也可以让我们通过数据来自动调节分布的复杂度。","tags":["贝叶斯","算法"],"categories":["文献阅读"]},{"title":"书籍Thinking Julia后几章阅读笔记","url":"/2022/07/03/thinkjulia2/","content":"\n<p align=\"center\">\n    <img src=\"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fi0.hdslb.com%2Fbfs%2Farticle%2F0641bd5a05ae260e3167b7a6b6f389143abb0416.jpg&refer=http%3A%2F%2Fi0.hdslb.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1659401858&t=1004217d7de1a7d354b99be904052734\" style=\"zoom: 100%;\" />\n</p>\n\n> 书籍网址：https://benlauwens.github.io/ThinkJulia.jl/latest/book.html\n\n<!--more-->\n\n## Dictionaries\n\n### A Dictionary Is a Mapping\n\n~~~julia\njulia> eng2sp = Dict()\nDict{Any, Any}()\n~~~\n\n我们可以使用方括号为字典添加数据：\n\n~~~julia\njulia> eng2sp[\"one\"] = \"uno\"\n\"uno\"\njulia> eng2sp\nDict{Any, Any} with 1 entry:\n  \"one\" => \"uno\"\n~~~\n\n上述输出的格式也可以作为输入的格式：\n\n~~~julia\njulia> eng2sp = Dict(\"one\"=>\"uno\", \"two\"=>\"dos\",\"three\"=>\"tres\")\nDict{String, String} with 3 entries: …\njulia> eng2sp\nDict{String, String} with 3 entries:\n  \"two\"   => \"dos\"\n  \"one\"   => \"uno\"\n  \"three\" => \"tres\"\n~~~\n\n可以看出字典输出的顺序与我们输入的顺序不同，在`Julia`中，字典的输出顺序是不可预测的。\n\n查看长度：\n\n~~~julia\njulia> length(eng2sp)\n3\n~~~\n\n`keys`函数返回字典的键：\n\n~~~julia\njulia> ks = keys(eng2sp);\njulia> print(ks)\n[\"two\", \"one\", \"three\"]\n~~~\n\n也可以用 `∈` 符号查看某个字符串是否在keys里：\n\n~~~julia\njulia> \"one\" ∈ ks\ntrue\n~~~\n\n使用`values`函数获取字典的值：\n\n~~~julia\njulia> vs = values(eng2sp);\n\njulia> \"uno\" ∈ vs\ntrue\n~~~\n\n字典有`get`函数，给定key获取其值，如果key不存在，则返回默认值：\n\n~~~julia\njulia> get(eng2sp, \"one\",1)    \n\"uno\"                          \n                               \njulia> get(eng2sp, \"four\",1)   \n1                              \n~~~\n\n### Reverse Lookup\n\n我们可以根据值找键：\n\n~~~julia\njulia> findall(isequal(\"uno\"), eng2sp) \n1-element Vector{String}:              \n \"one\"                                 \n~~~\n\n### Global Variables\n\n全局变量是位于`Main`中的变量，我们一般将其用为`flag`来表示真假，如：\n\n~~~julia\nverbose = true\n\nfunction example1()\n    if verbose\n        println(\"Running example1\")\n    end\nend\n~~~\n\n但是如果你\n\n~~~julia\nbeen_called = false\n\nfunction example2()\n    been_called = true         # WRONG\nend\n~~~\n\n你会发现`been_called`的值没有改变，这是因为函数中的`been_called`是局部变量，与函数外的变量无关系。\n\n要在函数内部重新分配全局变量，必须在使用它之前声明该变量为全局变量：\n\n~~~julia\nbeen_called = false\n\nfunction example2()\n    global been_called\n    been_called = true\nend\n~~~\n\n如果一个全局变量引用了一个可变值，您可以修改该值，而不需要声明变量为全局变量：\n\n~~~julia\nknown = Dict(0=>0, 1=>1)\n\nfunction example4()\n    known[2] = 1\nend\n~~~\n\n因此，您可以添加、删除和替换全局数组或字典的元素，但如果您想重新分配变量，您必须声明它是全局的：\n\n~~~julia\nknown = Dict(0=>0, 1=>1)\n\nfunction example5()\n    global known\n    known = Dict()\nend\n~~~\n\n## Tuples\n\n### Tuples Are Immutable\n\n元组是不可变的，其元素可以是不同的类型：\n\n~~~julia\njulia> t = 'a', 'b', 'c', 'd', 'e'\n('a', 'b', 'c', 'd', 'e')\n~~~\n\n创建只有一个元素的数组，后面必须加`,`：\n\n~~~julia\njulia> t1 = ('a',)\n('a',)\njulia> typeof(t1)\nTuple{Char}\n~~~\n\n如果提供了多个参数，则结果是一个具有给定参数的元组\n\n~~~julia\njulia> t3 = tuple(1, 'a', pi)\n(1, 'a', π = 3.1415926535897...)\n~~~\n\n可以使用数字对元组进行索引：\n\n~~~julia\njulia> t = ('a', 'b', 'c', 'd', 'e');\n\njulia> t[1]\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\njulia> t[2:4]\n('b', 'c', 'd')\n~~~\n\n但是如果你尝试改变元组的值则会报错：\n\n~~~julia\njulia> t[1] = 'A'\nERROR: MethodError: no method matching setindex!(::NTuple{5,Char}, ::Char, ::Int64)\n~~~\n\n元组逐元素比较大小：\n\n~~~julia\njulia> (0, 1, 2) < (0, 3, 4)\ntrue\njulia> (0, 1, 2000000) < (0, 3, 4)\ntrue\n~~~\n\n### Tuple Assignment\n\n交换`a,b`的值我们可以：\n\n~~~julia\na, b = b, a\n~~~\n\n左侧的值的数量要少于右边值的数量：\n\n~~~julia\njulia> (a, b) = (1, 2, 3)\n(1, 2, 3)\njulia> a  \n1         \n          \njulia> b  \n2         \njulia> a, b, c = 1, 2\nERROR: BoundsError: attempt to access (1, 2)\n  at index [3]\n~~~\n\n### Tuples as Return Values\n\n元组也可以作为返回值，如内置函数`diverm`返回整除和余数：\n\n~~~julia\njulia> q, r = divrem(7, 3);\n\njulia> @show q r;\nq = 2\nr = 1\n~~~\n\n### Variable-length Argument Tuples\n\n函数可以接受可变数量的参数。末尾带有`...`的参数将参数聚集成元组：\n\n~~~julia\nfunction printall(args...)\n    println(args)\nend\n\njulia> printall(1, 2.0, '3')\n(1, 2.0, '3')\n~~~\n\n同样的元组后加`...`可以将元组分解作为多个参数传入：\n\n~~~julia\njulia> t = (7, 3);\n\njulia> divrem(t)\nERROR: MethodError: no method matching divrem(::Tuple{Int64,Int64})\njulia> divrem(t...)\n(2, 1)\n~~~\n\n### Arrays and Tuples\n\n内建函数`zip`可以将两个或多个序列转换为元组的集合，每个元组包含每个序列的一个元素。\n\n~~~julia\njulia> s = \"abc\";\n\njulia> t = [1,2,3];\n\njulia> zip(s,t)\nzip(\"abc\", [1, 2, 3])\n~~~\n\n返回一个`zip`对象，`zip`对象是一种迭代器，它是对序列进行迭代的任何对象。迭代器在某些方面类似于数组，但与数组不同的是，不能使用索引从迭代器中选择元素。我们可以使用`for`循环对其进行遍历：\n\n~~~julia\njulia> for pair in zip(s,t)\n       println(pair)\n       end\n('a', 1)\n('b', 2)\n('c', 3)\n~~~\n\n如果你想用数组的方法来操纵`zip`对象，可以将其转换为数组：\n\n~~~julia\njulia> collect(zip(s,t))\n3-element Vector{Tuple{Char, Int64}}:\n ('a', 1)\n ('b', 2)\n ('c', 3)\n~~~\n\n如果序列长度不一样，那么用长度较小的序列：\n\n~~~julia\njulia> collect(zip(\"Anne\", \"Elk\"))\n3-element Array{Tuple{Char,Char},1}:\n ('A', 'E')\n ('n', 'l')\n ('n', 'k')\n~~~\n\n你可以在`for`循环中使用元组赋值来遍历元组数组：\n\n~~~julia\njulia> t = [('a', 1), ('b', 2), ('c', 3)];\n\njulia> for (letter, number) in t\n           println(number, \" \", letter)\n       end\n1 a\n2 b\n3 c\n~~~\n\n使用`enumerate`来获得索引和元素：\n\n~~~julia\njulia> for (index, element) in enumerate(\"abc\")\n           println(index, \" \", element)\n       end\n1 a\n2 b\n3 c\n~~~\n\n### Dictionaries and Tuples\n\n我们可以使用元组来初始化字典：\n\n~~~julia\njulia> t = [('a', 1), ('c', 3), ('b', 2)];\n\njulia> d = Dict(t)\nDict{Char,Int64} with 3 entries:\n  'a' => 1\n  'c' => 3\n  'b' => 2\n~~~\n\n将`zip`和`Dict`结合起来创建字典很简洁：\n\n~~~julia\njulia> d = Dict(zip(\"abc\", 1:3))\nDict{Char,Int64} with 3 entries:\n  'a' => 1\n  'c' => 3\n  'b' => 2\n~~~\n\n## Files\n\n### Reading and Writing\n\n使用`w`模式对文件进行写，如果文件存在则清空以前的内容，不存在则重新创建一个。\n\n~~~julia\njulia> fout = open(\"output.txt\", \"w\")\nIOStream(<file output.txt>)\n~~~\n\n写入\n\n~~~julia\njulia> line1 = \"This here's the wattle,\\n\"\n\"This here's the wattle,\\n\"\n\njulia> write(fout, line1)\n24\n~~~\n\n返回的为写入的字符串长度。\n\n当写入完毕后，要关闭文件：\n\n~~~julia\njulia> close(fout)\n~~~\n\n### Filenames and Paths\n\n`pwd`获取当前路径，`abspath`获取文件所处绝对路径，`ispath`判断是否为路径，`isdir`判断是否为文件夹，`readdir`读取路径下所有文件和路径。\n\n### Catching Exceptions\n\n~~~julia\ntry\n    fin = open(\"bad_file.txt\")\ncatch exc\n    println(\"Something went wrong: $exc\")\nfinally\n    println(\"finally\")\nend\n~~~\n\n### Serialization\n\n函数`serialize`和`deserialize`可以将任何类型的对象转为字节数组。\n\n~~~julia\njulia> using Serialization\n\njulia> io = IOBuffer()\nIOBuffer(data=UInt8[...], readable=true, writable=true, seekable=true, append=false, size=0, maxsize=Inf, ptr=1, mark=-1)\n\njulia> t = [1,2,3];\n\njulia> serialize(io, t)\n24\n\njulia> print(take!(io))\nUInt8[0x37, 0x4a, 0x4c, 0x0f, 0x04, 0x00, 0x00, 0x00, 0x15, 0x00, 0x08, 0xe2, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]\n~~~\n\n输出的类型不利于我们阅读，我们可以将其转换为原来的格式：\n\n~~~julia\njulia> io = IOBuffer();\n\njulia> t1 = [1, 2, 3];\n\njulia> serialize(io, t1)\n24\n\njulia> s = take!(io)\n36-element Vector{UInt8}: …\n\njulia> t2 = deserialize(IOBuffer(s));\n\njulia> print(t2)\n[1, 2, 3]\n~~~\n\n尽管新的对象和原对象的值相同，但是它们不是同一个对象：\n\n~~~julia\njulia> t1 == t2          \ntrue                     \n                         \njulia> t1 === t2         \nfalse                    \n~~~\n\n### Modules\n\n如果你有一个文件`wc.jl`，内容为：\n\n~~~julia\nfunction linecount(filename)\n    count = 0\n    for line in eachline(filename)\n        count += 1\n    end\n    count\nend\n\nprint(linecount(\"wc.jl\"))\n~~~\n\n如果你运行此段代码，它读取自己并输出$9$。\n\n~~~julia\njulia> include(\"wc.jl\")\n9\n~~~\n\n`Julia`引入了一些模块(module)来创建单独的变量工作区，即新的全局作用域。`import`允许控制来自其他模块的哪些名称是可见的，`export`确定哪些名称是公共的，即可以在模块外不加模块名称前缀来使用。\n\n~~~julia\nmodule LineCount\n    export linecount\n\n    function linecount(filename)\n        count = 0\n        for line in eachline(filename)\n            count += 1\n        end\n        count\n    end\nend\n~~~\n\n将上述文件保存为`LineCount.jl`，之后运行`push!(LOAD_PATH, \".\")`，将当前目录添加到工作路径，`.`表示当前路径。之后\n\n~~~julia\njulia> using LineCount\n\njulia> linecount(\"wc.jl\")\n11\n~~~\n\n## Structs and Objects\n\n### Composite Types\n\n我们可以通过`struct`来定义复合类型，如定义`Point`类型：\n\n~~~julia\nstruct Point\n    x\n    y\nend\njulia> p = Point(3.0, 4.0)\nPoint(3.0, 4.0)\n~~~\n\n返回值是对`Point`对象的引用，我们将其赋值给`p`。\n\n### Structs are Immutable\n\n你可以使用`.`符号来获取字段的值：\n\n~~~julia\njulia> x = p.x\n3.0\njulia> p.y\n4.0\n~~~\n\n`struct`在默认情况下是不可变的，构造之后字段的值不可改变：\n\n~~~julia\njulia> p.y = 1.0\nERROR: setfield! immutable struct of type Point cannot be changed\n~~~\n\n### Mutable Structs\n\n我们可以使用`mutate`关键字使`struct`可变：\n\n~~~julia\nmutable struct MPoint\n    x\n    y\nend\n\njulia> blank = MPoint(0.0, 0.0)\nMPoint(0.0, 0.0)\njulia> blank.x = 3.0\n3.0\njulia> blank.y = 4.0\n4.0\n~~~\n\n### Rectangles\n\n我们可以创建一个矩形对象，字段为一个端点的坐标和宽度和长度：\n\n~~~julia\n\"\"\"\nRepresents a rectangle.\n\nfields: width, height, corner.\n\"\"\"\nstruct Rectangle\n    width\n    height\n    corner\nend\n\njulia> origin = MPoint(0.0, 0.0)\nMPoint(0.0, 0.0)\njulia> box = Rectangle(100.0, 200.0, origin)\nRectangle(100.0, 200.0, MPoint(0.0, 0.0))\n~~~\n\n\n\n### Instances as Arguments\n\n实例可以作为参数：\n\n~~~julia\nfunction printpoint(p)\n    println(\"($(p.x), $(p.y))\")\nend\n~~~\n\n当把一个实例传入到函数中去，函数会改变实例的字段值：\n\n~~~julia\nfunction movepoint!(p, dx, dy)\n    p.x += dx\n    p.y += dy\n    nothing\nend\n\njulia> origin = MPoint(0.0, 0.0)\nMPoint(0.0, 0.0)\njulia> movepoint!(origin, 1.0, 2.0)\n\njulia> origin\nMPoint(1.0, 2.0)\n~~~\n\n但是，你可以修改不可变对象的可变属性的值，如：\n\n~~~julia\nfunction moverectangle!(rect, dx, dy)\n  movepoint!(rect.corner, dx, dy)\nend\n\njulia> box\nRectangle(100.0, 200.0, MPoint(0.0, 0.0))\njulia> moverectangle!(box, 1.0, 2.0)\n\njulia> box\nRectangle(100.0, 200.0, MPoint(1.0, 2.0))\n~~~\n\n### Instances as Return Values\n\n~~~julia\nfunction findcenter(rect)\n    Point(rect.corner.x + rect.width / 2, rect.corner.y + rect.height / 2)\nend\n~~~\n\n### Copying\n\n`Julia`内建函数`deepcopy`可以复制任何对象：\n\n~~~julia\njulia> p1 = MPoint(3.0, 4.0)\nMPoint(3.0, 4.0)\njulia> p2 = deepcopy(p1)\nMPoint(3.0, 4.0)\njulia> p1 ≡ p2\nfalse\njulia> p1 == p2\nfalse\n~~~\n\n`≡`的结果我们应该能接受，因为是不同的对象，但是`==`的结果我们可能无法接受，因为两个对象的值是相同的，这是因为在`Julia`中可变复合类型`mutate`，`Julia`不知道什么是等价的。\n\n而在不可变复合类型中相反：\n\n~~~julia\njulia> p1 = Point(1,2)\nPoint(1, 2)\n\njulia> p2 = deepcopy(p1)\nPoint(1, 2)\n\njulia> p1==p2\ntrue\n\njulia> p1===p2\ntrue\n~~~\n\n因为我们不会改变`p1`，所以复制也就没意义。\n\n### Debugging\n\n判断`p`是否为`Point`类型：\n\n~~~julia\njulia> p isa Point\ntrue\n~~~\n\n查看`Point`类型的字段：\n\n~~~julia\njulia> fieldnames(Point)\n(:x, :y)\n~~~\n\n或者使用：\n\n~~~julia\njulia> isdefined(p, :x)\ntrue\njulia> isdefined(p, :z)\nfalse\n~~~\n\n## Structs and Functions\n\n### Time\n\n我们构建时间类：\n\n~~~julia\n\"\"\"\nRepresents the time of day.\n\nfields: hour, minute, second\n\"\"\"\nstruct MyTime\n    hour\n    minute\n    second\nend\n~~~\n\n~~~julia\njulia> time = MyTime(11, 59, 30)\nMyTime(11, 59, 30)\n~~~\n\n### Pure Functions\n\n下面是两个时间相加的简单原型：\n\n~~~julia\nfunction addtime(t1, t2)\n    MyTime(t1.hour + t2.hour, t1.minute + t2.minute, t1.second + t2.second)\nend\n~~~\n\n上面函数被称为纯函数，因为它并没有改变传入的两个对象的值。\n\n~~~julia\njulia> start = MyTime(9, 45, 0);\n\njulia> duration = MyTime(1, 35, 0);\n\njulia> done = addtime(start, duration);\n\njulia> printtime(done)\n10:80:00\n~~~\n\n出现了$80$分钟，这与我们的常识不同，我们需要添加新的规则\n\n~~~julia\nfunction addtime(t1, t2)\n    second = t1.second + t2.second\n    minute = t1.minute + t2.minute\n    hour = t1.hour + t2.hour\n    if second >= 60\n        second -= 60\n        minute += 1\n    end\n    if minute >= 60\n        minute -= 60\n        hour += 1\n    end\n    MyTime(hour, minute, second)\nend\n~~~\n\n### Modifiers\n\n~~~julia\nfunction increment!(time, seconds)\n    time.second += seconds\n    if time.second >= 60\n        time.second -= 60\n        time.minute += 1\n    end\n    if time.minute >= 60\n        time.minute -= 60\n        time.hour += 1\n    end\nend\n~~~\n\n上面定义的函数会改变传入的参数值，我们称其为`Modifiers`。\n\n##  Multiple Dispatch\n\n在`Julia`中，你可以写在不同类型上运行的代码，这被称为泛型编程。\n\n### Type Declarations\n\n运算符`::`将类型注释附加到表达式和变量：\n\n~~~julia\njulia> (1 + 2) :: Float64\nERROR: TypeError: in typeassert, expected Float64, got Int64\njulia> (1 + 2) :: Int64\n3\n~~~\n\n这帮助确认你的程序按照你期望的方式进行。\n\n`::`运算符也可以添加到赋值语句的左边，作为声明的一部分：\n\n~~~julia\njulia> function returnfloat()\n           x::Float64 = 100\n           x\n       end\nreturnfloat (generic function with 1 method)\njulia> x = returnfloat()\n100.0\njulia> typeof(x)\nFloat64\n~~~\n\n也可以作为函数定义的一部分：\n\n~~~julia\nfunction sinc(x)::Float64\n    if x == 0\n        return 1\n    end\n    sin(x)/(x)\nend\n~~~\n\n### Methods\n\n方法是具有特定特征的函数：\n\n~~~julia\nusing Printf\n\nstruct MyTime\n    hour :: Int64\n    minute :: Int64\n    second :: Int64\nend\n\nfunction printtime(time::MyTime)\n    @printf(\"%02d:%02d:%02d\", time.hour, time.minute, time.second)\nend\n~~~\n\n上面的函数定义了输入的数据类型，为方法。\n\n### Constructors\n\n构造是用来创建对象的一类特殊的函数。`MyTime`的默认构造函数方法有以下特征：\n\n~~~julia\nMyTime(hour, minute, second) # 默认构造函数\nMyTime(hour::Int64, minute::Int64, second::Int64)\n~~~\n\n我们也可以添加自己的外部构建方法：\n\n~~~julia\nfunction MyTime(time::MyTime)\n    MyTime(time.hour, time.minute, time.second)\nend\n~~~\n\n我们也可以构建内部构造函数：\n\n~~~julia\nstruct MyTime\n    hour :: Int64\n    minute :: Int64\n    second :: Int64\n    function MyTime(hour::Int64=0, minute::Int64=0, second::Int64=0)\n        @assert(0 ≤ minute < 60, \"Minute is not between 0 and 60.\")\n        @assert(0 ≤ second < 60, \"Second is not between 0 and 60.\")\n        new(hour, minute, second)\n    end\nend\n~~~\n\n现在结构`MyTime`有$4$个内部构造方法：\n\n~~~julia\nMyTime()\nMyTime(hour::Int64)\nMyTime(hour::Int64, minute::Int64)\nMyTime(hour::Int64, minute::Int64, second::Int64)\n~~~\n\n> 内部构造函数会覆盖默认构造函数。\n\n内部构造函数总是定义在结构的内部，且能使用一个特殊函数`new`来创建最新定义的类型的对象。\n\n另一种不使用`new`函数的参数的方法为：\n\n~~~julia\nmutable struct MyTime\n    hour :: Int\n    minute :: Int\n    second :: Int\n    function MyTime(hour::Int64=0, minute::Int64=0, second::Int64=0)\n        @assert(0 ≤ minute < 60, \"Minute is between 0 and 60.\")\n        @assert(0 ≤ second < 60, \"Second is between 0 and 60.\")\n        time = new()\n        time.hour = hour\n        time.minute = minute\n        time.second = second\n        time\n    end\nend\n~~~\n\n但是这样数据结构必须是可变的。\n\n### `show`\n\n`show`函数是一个特殊的函数，返回对象的字符串表示。\n\n~~~julia\nusing Printf\n\nfunction Base.show(io::IO, time::MyTime)\n    @printf(io, \"%02d:%02d:%02d\", time.hour, time.minute, time.second)\nend\n~~~\n\n在这里前缀`Base`是需要的因为我们创建了`Base.show`函数的新方法。\n\n~~~julia\njulia> time = MyTime(9, 45)\n09:45:00\n~~~\n\n### Operator Overloading\n\n通过定义符号方法，你可以定义在定义的类型上的符号的行为。例如：\n\n~~~julia\nimport Base.+\n\nfunction +(t1::MyTime, t2::MyTime)\n    seconds = timetoint(t1) + timetoint(t2)\n    inttotime(seconds)\nend\n\njulia> start = MyTime(9, 45)\n09:45:00\njulia> duration = MyTime(1, 35, 0)\n01:35:00\njulia> start + duration\n11:20:00\n~~~\n\n### Multiple Dispatch\n\n在上面我们定义了两个`MyTime`类型相加，但是你可能也想整数和`Mytime`类型相加：\n\n~~~julia\nfunction +(time::MyTime, seconds::Int64)\n    increment(time, seconds)\nend\n\njulia> start = MyTime(9, 45)\n09:45:00\njulia> start + 1337\n10:07:17\n~~~\n\n相加是可交换的，因此我们定义\n\n~~~julia\nfunction +(seconds::Int64, time::MyTime)\n  time + seconds\nend\n\njulia> 1337 + start\n10:07:17\n~~~\n\n当一个函数被调用时决定使用哪个方法的决定被称为分派。\n\n### Generic Programming\n\n多分派在必要时很有用，但(幸运的是)并不总是必要的。通常，您可以通过编写对不同类型的参数正确工作的函数来避免这种情况。\n\n如下面的函数不仅可以对字符串使用，也可以对其他序列类型的数据使用：\n\n~~~julia\nfunction histogram(s)\n    d = Dict()\n    for c in s\n        if c ∉ keys(d)\n            d[c] = 1\n        else\n            d[c] += 1\n        end\n    end\n    d\nend\n\njulia> t = (\"spam\", \"egg\", \"spam\", \"spam\", \"bacon\", \"spam\")\n(\"spam\", \"egg\", \"spam\", \"spam\", \"bacon\", \"spam\")\njulia> histogram(t)\nDict{Any,Any} with 3 entries:\n  \"bacon\" => 1\n  \"spam\"  => 4\n  \"egg\"   => 1\n~~~\n\n使用多种类型的函数称为多态函数。多态可以促进代码重用。\n\n## Subtyping\n\n### Cards\n\n假设我们有一副扑克牌，我们想比较其大小，根据花色和数字，先定义卡牌类：\n\n~~~julia\nstruct Card\n    suit :: Int64\n    rank :: Int64\n    function Card(suit::Int64, rank::Int64)\n        @assert(1 ≤ suit ≤ 4, \"suit is not between 1 and 4\")\n        @assert(1 ≤ rank ≤ 13, \"rank is not between 1 and 13\")\n        new(suit, rank)\n    end\nend\n~~~\n\n### Global Variables\n\n定义对应的全局变量来一一对应花色和数组：\n\n~~~julia\nconst suit_names = [\"♣\", \"♦\", \"♥\", \"♠\"]\nconst rank_names = [\"A\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"J\", \"Q\", \"K\"]\n\n\nfunction Base.show(io::IO, card::Card)\n    print(io, rank_names[card.rank], suit_names[card.suit])\nend\n\njulia> Card(3, 11)\nJ♥\n~~~\n\n### Comparing Cards\n\n~~~julia\nimport Base.<\n\nfunction <(c1::Card, c2::Card)\n    (c1.suit, c1.rank) < (c2.suit, c2.rank)\nend\n~~~\n\n### Decks\n\n~~~julia\nstruct Deck\n    cards :: Array{Card, 1}\nend\n\nfunction Deck()\n    deck = Deck(Card[])\n    for suit in 1:4\n        for rank in 1:13\n            push!(deck.cards, Card(suit, rank))\n        end\n    end\n    deck\nend\n\nfunction Base.show(io::IO, deck::Deck)\n    for card in deck.cards\n        print(io, card, \" \")\n    end\n    println()\nend\n\njulia> Deck()\nA♣ 2♣ 3♣ 4♣ 5♣ 6♣ 7♣ 8♣ 9♣ 10♣ J♣ Q♣ K♣ A♦ 2♦ 3♦ 4♦ 5♦ 6♦ 7♦ 8♦ 9♦ 10♦ J♦ Q♦ K♦ A♥ 2♥ 3♥ 4♥ 5♥ 6♥ 7♥ 8♥ 9♥ 10♥ J♥ Q♥ K♥ A♠ 2♠ 3♠ 4♠ 5♠ 6♠ 7♠ 8♠ 9♠ 10♠ J♠ Q♠ K♠\n~~~\n\n### Add, Remove, Shuffle and Sort\n\n~~~julia\nfunction Base.pop!(deck::Deck)\n    pop!(deck.cards)\nend\n\nfunction Base.push!(deck::Deck, card::Card)\n    push!(deck.cards, card)\n    deck\nend\n\nusing Random\n\nfunction Random.shuffle!(deck::Deck)\n    shuffle!(deck.cards)\n    deck\nend\n~~~\n\n\n\n### Abstract Types and Subtyping\n\n现在我们想要定义手(hand)的类型，其与Decks类型大致相同，因此我们先定义抽象类型：\n\n~~~julia\nabstract type CardSet end\n~~~\n\n在类型后可以使用`<:`来指定其为谁的子类型，如果没有则为`Any`的子类型。\n\n我们可以指定`Deck`为`CardSet`的子类\n\n~~~julia\nstruct Deck <: CardSet\n    cards :: Array{Card, 1}\nend\n\nfunction Deck()\n    deck = Deck(Card[])\n    for suit in 1:4\n        for rank in 1:13\n            push!(deck.cards, Card(suit, rank))\n        end\n    end\n    deck\nend\n~~~\n\n~~~julia\nstruct Hand <: CardSet\n    cards :: Array{Card, 1}\n    label :: String\nend\n\nfunction Hand(label::String=\"\")\n    Hand(Card[], label)\nend\n~~~\n\n\n\n~~~julia\njulia> deck = Deck();\n\njulia> deck isa CardSet\ntrue\n~~~\n\n### Abstract Types and Functions\n\n我们现在可以给抽象类型定义函数：\n\n~~~julia\nfunction Base.show(io::IO, cs::CardSet)\n    for card in cs.cards\n        print(io, card, \" \")\n    end\nend\n\nfunction Base.pop!(cs::CardSet)\n    pop!(cs.cards)\nend\n\nfunction Base.push!(cs::CardSet, card::Card)\n    push!(cs.cards, card)\n    nothing\nend\n~~~\n\n\n\n~~~julia\njulia> deck = Deck()\nA♣ 2♣ 3♣ 4♣ 5♣ 6♣ 7♣ 8♣ 9♣ 10♣ J♣ Q♣ K♣ A♦ 2♦ 3♦ 4♦ 5♦ 6♦ 7♦ 8♦ 9♦ 10♦ J♦ Q♦ K♦ A♥ 2♥ 3♥ 4♥ 5♥ 6♥ 7♥ 8♥ 9♥ 10♥ J♥ Q♥ K♥ A♠ 2♠ 3♠ 4♠ 5♠ 6♠ 7♠ 8♠ 9♠ 10♠ J♠ Q♠ K♠\njulia> shuffle!(deck)\nJ♦ 10♣ 8♠ 9♥ 5♠ 7♣ 6♦ A♠ J♣ 7♠ 5♦ 10♥ 3♦ 9♦ 9♣ 4♣ 8♦ 8♥ 5♣ A♥ K♥ K♦ K♠ 4♦ A♦ Q♥ 6♠ 2♦ 6♥ 2♣ 10♠ 3♥ 2♥ J♥ Q♣ 5♥ 2♠ 9♠ 10♦ Q♠ 3♠ 8♣ K♣ 7♥ 3♣ J♠ 4♥ 6♣ 7♦ 4♠ A♣ Q♦\njulia> card = pop!(deck)\nQ♦\njulia> push!(hand, card)\n~~~\n\n## The Goodies: Syntax\n\n### Named Tuples\n\n~~~julia\njulia> x = (a=1, b=1+1)\n(a = 1, b = 2)\njulia> x.a\n1\n~~~\n\n### Functions\n\n可以以紧凑形式定义函数：\n\n~~~julia\njulia> f(x,y) = x + y\nf (generic function with 1 method)\n~~~\n\n#### Anonymous Functions\n\n我们可以定义没有名字的函数：\n\n~~~julia\njulia> x -> x^2 + 2x - 1\n#1 (generic function with 1 method)\njulia> function (x)\n           x^2 + 2x - 1\n       end\n#3 (generic function with 1 method)\n~~~\n\n匿名函数通常是其他函数的参数：\n\n~~~julia\njulia> using Plots\n\njulia> plot(x -> x^2 + 2x - 1, 0, 10, xlabel=\"x\", ylabel=\"y\")\n~~~\n\n#### Keyword Arguments\n\n函数参数可以命名：\n\n~~~julia\njulia> function myplot(x, y; style=\"solid\", width=1, color=\"black\")\n           ###\n       end\nmyplot (generic function with 1 method)\njulia> myplot(0:10, 0:10, style=\"dotted\", color=\"blue\")\n~~~\n\n关键字参数用`;`隔开，但调用的时候可以使用`,`。\n\n#### Closures\n\n`closure`是允许函数获取在函数范围之外的变量的方法：\n\n~~~julia\njulia> foo(x) = ()->x\nfoo (generic function with 1 method)\n\njulia> bar = foo(1)\n#1 (generic function with 1 method)\n\njulia> bar()\n1\n~~~\n\n### Blocks\n\n块是一种将许多语句分组的方法。\n\n~~~julia\n🐢 = Turtle()\n@svg begin\n    forward(🐢, 100)\n    turn(🐢, -90)\n    forward(🐢, 100)\nend\n~~~\n\n#### `let` Blocks\n\n~~~julia\njulia> x, y, z = -1, -1, -1;\n\njulia> let x = 1, z\n           @show x y z;\n       end\nx = 1\ny = -1\nERROR: UndefVarError: z not defined\njulia> @show x y z;\nx = -1\ny = -1\nz = -1\n~~~\n\n在第一个`let`中，`@show`打印局部变量`x,z`，打印全局变量`y`，全局变量`x,y,z`并未受影响。\n\n#### `do` Blocks\n\n~~~julia\njulia> data = \"This here's the wattle,\\nthe emblem of our land.\\n\"\n\"This here's the wattle,\\nthe emblem of our land.\\n\"\njulia> open(\"output.txt\", \"w\") do fout\n           write(fout, data)\n       end\n48\n~~~\n\n这里`fout`为文件流，我们不再需要手动关闭`fout`。\n\n这在函数上等价于\n\n~~~julia\njulia> f = fout -> begin\n           write(fout, data)\n       end\n#3 (generic function with 1 method)\njulia> open(f, \"output.txt\", \"w\")\n48\n~~~\n\n匿名函数常被用为`open`的参数：\n\n~~~julia\nfunction open(f::Function, args...)\n    io = open(args...)\n    try\n        f(io)\n    finally\n        close(io)\n    end\nend\n~~~\n\ndo块可以从它的封闭作用域捕获变量。例如，上面`open…do`例子中的变量`data`是从外部作用域捕获的。\n\n### Control Flow\n\n#### Ternary Operator\n\n~~~julia\njulia> a = 150\n150\njulia> a % 2 == 0 ? println(\"even\") : println(\"odd\")\neven\n~~~\n\n#### Short-Circuit Evaluation\n\n`&&`和`||`是短路运算符，当前一个表达式的值可以确定结果是另一个就不需要计算了。\n\n#### Tasks (aka Coroutines)\n\n任务是一种能够传递协同控制而不返回的控制结构。在Julia中，任务可以作为第一个参数为`Channel`对象的函数来实现。通道用于将值从函数传递给被调用方。\n\n~~~julia\nfunction fib(c::Channel)\n    a = 0\n    b = 1\n    put!(c, a)\n    while true\n        put!(c, b)\n        (a, b) = (b, a+b)\n    end\nend\n~~~\n\n`take!`可以从通道中取值：\n\n~~~julia\njulia> fib_gen = Channel(fib);\n\njulia> take!(fib_gen)\n0\njulia> take!(fib_gen)\n1\njulia> take!(fib_gen)\n1\njulia> take!(fib_gen)\n2\njulia> take!(fib_gen)\n3\n~~~\n\n通道也可以作为迭代对象\n\n~~~julia\njulia> for val in Channel(fib)\n           print(val, \" \")\n           val > 20 && break\n       end\n0 1 1 2 3 5 8 13 21\n~~~\n\n### Types\n\n#### Primitive Types\n\n在`Julia`中，你可以定义自己的原始类型，标准原始类型也用同样的方法定义：\n\n~~~julia\nprimitive type Float64 <: AbstractFloat 64 end\nprimitive type Bool <: Integer 8 end\nprimitive type Char <: AbstractChar 32 end\nprimitive type Int64 <: Signed 64 end\n~~~\n\n创建`Byte`原始类型和其构造函数：\n\n~~~julia\njulia> primitive type Byte 8 end\n\njulia> Byte(val::UInt8) = reinterpret(Byte, val)\nByte\njulia> b = Byte(0x01)\nByte(0x01)\n~~~\n\n`reinterpret`函数用于存储一个8位的无符号整数的位到字节中。\n\n#### Parametric Types\n\n`Julia`的类型是参数的，说明其类型可以带参数。\n\n~~~julia\nstruct Point{T<:Real}\n    x::T\n    y::T\nend\n~~~\n\n#### Type Unions\n\n~~~julia\njulia> IntOrString = Union{Int64, String}\nUnion{Int64, String}\njulia> 150 :: IntOrString\n150\njulia> \"Julia\" :: IntOrString\n\"Julia\"\n~~~\n\n\n\n类型联合在大多数计算机语言中是对类型进行推理的内部构造。然而，`Julia`向用户公开了该特性，因为当类型联合只有少量类型时，可以生成有效的代码。这个特性为`Julia`程序员控制调度提供了极大的灵活性。\n\n### Methods\n\n#### Parametric Methods\n\n方法定义也可以含有参数的类型参数：\n\n~~~julia\njulia> isintpoint(p::Point{T}) where {T} = (T === Int64)\nisintpoint (generic function with 1 method)\njulia> p = Point(1, 2)\nPoint{Int64}(1, 2)\njulia> isintpoint(p)\ntrue\n~~~\n\n#### Function-like Objects\n\n`Julia`中的任何对象都可以被调用，这种可以被调用的对象被称为`functors`：\n\n~~~julia\nstruct Polynomial{R}\n    coeff::Vector{R}\nend\n\nfunction (p::Polynomial)(x)\n    val = p.coeff[end]\n    for coeff in p.coeff[end-1:-1:1]\n        val = val * x + coeff\n    end\n    val\nend\n~~~\n\n去计算多项式，我们简单调用它：\n\n~~~julia\njulia> p = Polynomial([1,10,100])\nPolynomial{Int64}([1, 10, 100])\njulia> p(3)\n931\n~~~\n\n### Constructors\n\n参数类型可以显式或隐式构造\n\n~~~julia\njulia> Point(1,2)         # implicit T\nPoint{Int64}(1, 2)\njulia> Point{Int64}(1, 2) # explicit T\nPoint{Int64}(1, 2)\njulia> Point(1,2.5)       # implicit T\nERROR: MethodError: no method matching Point(::Int64, ::Float64)\n~~~\n\n为每个`T`生成默认的内部和外部构造函数：\n\n~~~julia\nstruct Point{T<:Real}\n    x::T\n    y::T\n    Point{T}(x,y) where {T<:Real} = new(x,y)\nend\n\nPoint(x::T, y::T) where {T<:Real} = Point{T}(x,y);\n~~~\n\n并且每一个`x`和`y`的类型都相同。\n\n当类型不同时可以：\n\n~~~julia\nPoint(x::Real, y::Real) = Point(promote(x,y)...);\n~~~\n\n### Conversion and Promotion\n\n#### Conversion\n\n数据可以从一个类型转为另一个类型：\n\n~~~julia\njulia> x = 12\n12\njulia> typeof(x)\nInt64\njulia> convert(UInt8, x)\n0x0c\njulia> typeof(ans)\nUInt8\n~~~\n\n我们可以增加自己的`convert`方法：\n\n~~~julia\njulia> Base.convert(::Type{Point{T}}, x::Array{T, 1}) where {T<:Real} = Point(x...)\n\njulia> convert(Point{Int64}, [1, 2])\nPoint{Int64}(1, 2)\n~~~\n\n#### Promotion\n\n`Promotion`是将混合类型的值转换为单一公共类型：\n\n~~~julia\njulia> promote(1, 2.5, 3)\n(1.0, 2.5, 3.0)\n~~~\n\n### Metaprogramming\n\n`Julia`代码可以表示为语言本身的数据结构。这允许程序转换和生成自己的代码。\n\n#### Expressions\n\n每一个`Julia`程序开始都为一个字符串：\n\n~~~julia\njulia> prog = \"1 + 2\"\n\"1 + 2\"\n~~~\n\n下一步是将每个字符串解析为一个名为表达式的对象，表达式由`Julia`类型`Expr`表示：\n\n~~~julia\njulia> ex = Meta.parse(prog)\n:(1 + 2)\njulia> typeof(ex)\nExpr\njulia> dump(ex)\nExpr\n  head: Symbol call\n  args: Array{Any}((3,))\n    1: Symbol +\n    2: Int64 1\n    3: Int64 2\n~~~\n\n`dump`函数显示带有注释的`expr`对象。\n\n表达式可以由`:()`或`quote`块构造：\n\n~~~julia\njulia> ex = quote\n           1 + 2\n       end;\n~~~\n\n#### `eval`\n\n可以用`eval`函数计算表达式的值：\n\n~~~julia\njulia> eval(ex)\n3\n~~~\n\n#### Macros\n\n宏可以包括程序中生成的代码。宏将`Expr`对象的元组直接映射到编译后的表达式：\n\n~~~julia\nmacro containervariable(container, element)\n    return esc(:($(Symbol(container,element)) = $container[$element]))\nend\n~~~\n\n#### Generated Functions\n\n宏`@generated`根据参数的类型为方法创建专门的代码：\n\n~~~julia\n@generated function square(x)\n    println(x)\n    :(x * x)\nend\n\njulia> x = square(2); # note: output is from println() statement in the body\nInt64\njulia> x              # now we print x\n4\njulia> y = square(\"spam\");\nString\njulia> y\n\"spamspam\"\n~~~\n\n### Missing Values\n\n缺失的值可以通过`missing`对象表示，该对象是`Missing`类型的单例实例：\n\n~~~julia\njulia> a = [1, missing]\n2-element Array{Union{Missing, Int64},1}:\n 1\n  missing\n\njulia> sum(a)\nmissing\n\njulia> sum(skipmissing([1, missing]))\n1\n~~~\n\n## The Goodies: Base and Standard Library\n\n### Measuring Performance\n\n可以使用宏`@time`来比较程序运行的快慢。\n\n### Collections and Data Structures\n\nJulia提供了另一种内置类型，称为set，它的行为类似于没有值的字典键的集合。集合提供了计算常见集合操作的函数和运算符。\n\n~~~julia\nfunction subtract(d1, d2)\n    res = Dict()\n    for key in keys(d1)\n        if key ∉ keys(d2)\n            res[key] = nothing\n        end\n    end\n    res\nend\n~~~\n\n~~~julia\nfunction subtract(d1, d2)\n    setdiff(d1, d2)\nend\n~~~\n\n~~~julia\nfunction hasduplicates(t)\n    d = Dict()\n    for x in t\n        if x ∈ d\n            return true\n        end\n        d[x] = nothing\n    end\n    false\nend\n~~~\n\n~~~julia\nfunction hasduplicates(t)\n    length(Set(t)) < length(t)\nend\n~~~\n\n~~~julia\nfunction usesonly(word, available)\n    for letter in word\n        if letter ∉ available\n            return false\n        end\n    end\n    true\nend\n~~~\n\n~~~julia\nfunction usesonly(word, available)\n    Set(word) ⊆ Set(available)\nend\n~~~\n\n### Interfaces\n\n`Julia`指定了一些非正式的接口来定义行为，例如，具有特定目标的方法。当您为某个类型扩展这样的方法时，可以使用该类型的对象来构建这些行为。\n\n例如斐波那契：\n\n~~~julia\nstruct Fibonacci{T<:Real} end\nFibonacci(d::DataType) = d<:Real ? Fibonacci{d}() : error(\"No Real type!\")\n\nBase.iterate(::Fibonacci{T}) where {T<:Real} = (zero(T), (one(T), one(T)))\nBase.iterate(::Fibonacci{T}, state::Tuple{T, T}) where {T<:Real} = (state[1], (state[2], state[1] + state[2]))\n~~~\n\n首先定义了结构和构造方法，之后定义了初始循环，返回值第一个为$0$，之后一个元组为`state`用于下面的下一次循环。\n\n~~~julia\njulia> for e in Fibonacci(Int64)\n           e > 100 && break\n           print(e, \" \")\n       end\n0 1 1 2 3 5 8 13 21 34 55 89\n~~~\n\n","tags":["Julia","编程"],"categories":["书籍阅读"]},{"title":"书籍Thinking Julia前十章阅读笔记","url":"/2022/07/01/thinkjulia/","content":"\n<p align=\"center\">\n    <img src=\"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimglf6.lf127.net%2Fimg%2FanBSb2NqdEc5dTlseXpNTWxpY0RWQ2NwUlAyVmFEa2lFSVo0TVM4WXNwSndDMUdvN3crMS9nPT0.jpg%3FimageView%26thumbnail%3D2160x0%26quality%3D90%26interlace%3D1%26type%3Djpg&refer=http%3A%2F%2Fimglf6.lf127.net&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1659263087&t=d2faeee051aa3c102a86e173d74306ad\" style=\"zoom: 100%;\" />\n</p>\n\n> 书籍网址：https://benlauwens.github.io/ThinkJulia.jl/latest/book.html\n\n<!--more-->\n\n## The Way of the program\n\n### What is a Program?\n\n一个程序应该包括以下几部分：\n\n+ 输入：从键盘、文件、网络或者其他设备中获取数据\n+ 输出：将数据展示在屏幕上、或将其存储在文件中、将其发送到网络上等等\n+ 数学：执行基本的数学运算，如加法乘法等\n+ 条件执行：查看特定的条件并且运行适当的代码\n+ 重复：重复地做一些动作，通常有一些变化\n\n### The First Program\n\n~~~julia\njulia> println(\"Hello, World!\")\nHello, World!\n~~~\n\n### Arithmetic Operators\n\n符号`+`，`-`，`*`，`/`，`^`分别表示加法、减法、乘法、除法、幂运算。\n\n~~~julia\njulia> 40 + 2         \n42                    \n                      \njulia> 43 - 1         \n42                    \n                      \njulia> 6 * 7          \n42                    \n                      \njulia> 84 / 2         \n42.0                  \n                      \njulia> 6 ^ 2 + 6      \n42                    \n~~~\n\n> 注意在除法中我们得到是$42.0$而不是$42$，后面我们会解释原因。\n\n### Values and Types\n\n我们可以使用`typeof`函数来获取类型。\n\n~~~julia\njulia> typeof(2)\nInt64\n\njulia> typeof(42.0)\nFloat64\n\njulia> typeof(\"Hello, World!\")\nString\n~~~\n\n## Variables, Expressions and Statements\n\n### Assignment Statements\n\n使用`=`对变量进行赋值。\n\n~~~julia\njulia> n = 17\n17\n~~~\n\n### Variable Names\n\n命名可以采用字母、数字和`_`，但是数字不能在开头，也不能使用关键字。\n\n下面为`Julia`的关键字：\n\n~~~julia\nabstract type    baremodule   begin      break       catch\nconst            continue     do         else        elseif\nend              export       finally    for         function\nglobal           if           import     importall   in\nlet              local        macro      module      mutable struct\nprimitive type   quote        return     try         using\nstruct           where        while\n~~~\n\n### Expressions and Statements\n\n表达式是值（values）、变量（variables）和符号（operators）的组合。\n\n~~~julia\njulia> 42\n42\n\njulia> n\n17\n\njulia> n + 25\n42\n~~~\n\n语句是具有效果的代码单位，例如创建变量或显示值。\n\n~~~julia\njulia> n = 17\n17\n\njulia> println(n)\n17\n~~~\n\n### Operator Precedence\n\n括号优先级最高，其次是幂，之后是乘除法、加减法优先级最低。\n\n### String Operations\n\n`*`表示字符串拼接，`^`表示字符串重复。\n\n~~~julia\njulia> first_str = \"throat\"\n\"throat\"\n\njulia> second_str = \"warbler\"\n\"warbler\"\n\njulia> first_str * second_str\n\"throatwarbler\"\n\njulia> \"Spam\"^3\n\"SpamSpamSpam\"\n~~~\n\n### Comments\n\n注释用`#`。\n\n### Debugging\n\n`Julia`中存在三种错误。\n\n+ 语法错误(Syntax error)：语法指的是程序的结构和关于该结构的规则。如括号少一边。\n+ 运行时错误(Runtime error)：指的是程序运行时出错，也被称为异常。\n+ 语义错误(Semantic error)：这种错误程序会运行，但是得到的结果不是我们想要的。\n\n## Functions\n\n### Function Calls\n\n我们之前已经看到一个函数调用的例子：\n\n~~~julia\njulia> println(\"Hello, World!\")\nHello, World!\n~~~\n\n`Println()`是函数的名字，括号里面是函数的参数。\n\n`Julia`提供一些类型转换的函数：\n\n`parse`函数将字符串类型转为任何数字(number)类型\n\n~~~julia\njulia> parse(Int64, \"32\")\n32\n\njulia> parse(Float64, \"3.14159\")\n3.14159\n\njulia> parse(Int64, \"Hello\")\nERROR: ArgumentError: invalid base 10 digit 'H' in \"Hello\"\n~~~\n\n`trunc`可以将字符串截断为整数：\n\n~~~julia\njulia> trunc(Int64, 3.9999)\n3\n\njulia> trunc(Int64, -2.3)\n-2\n~~~\n\n`float`将整数转为浮点数：\n\n~~~julia\njulia> float(24)\n24.0\n~~~\n\n`string`将参数转换为字符串：\n\n~~~julia\njulia> string(32)\n\"32\"\n\njulia> string(32.2)\n\"32.2\"\n~~~\n\n### Adding New Functions\n\n我们使用`function`定义函数，以`end`结束。\n\n~~~julia\nfunction printlyrics()\n    println(\"I'm a lumberjack, and I'm okay.\")\n    println(\"I sleep all night and I work all day.\")\nend\n~~~\n\n我们也可以在函数中调用函数：\n\n~~~julia\nfunction repeatlyrics()\n    printlyrics()\n    printlyrics()\nend\n~~~\n\n>  函数在运行前必须被定义。\n\n### Parameters and Arguments\n\n下面我们定义一个含有参数的函数：\n\n~~~julia\nfunction printtwice(bruce)\n    println(bruce)\n    println(bruce)\nend\n~~~\n\n传入的参数可以是值(value)、表达式和变量。\n\n### Variables and Parameters Are Local\n\n函数的变量和参数是局部的。\n\n### Fruitful Functions and Void Functions\n\n有返回值的函数称为Fruitful Functions，没有返回值的函数称为Void Functions。没有返回值的函数的返回值为`nothing`，我们只能使用`show`函数打印。\n\n~~~julia\njulia> result = printtwice(\"Bing\")\nBing\nBing\njulia> show(result)\nnothing\n~~~\n\n`nothing`的类型为`Nothing`：\n\n~~~julia\njulia> typeof(nothing)\nNothing\n~~~\n\n## Case Study: Interface Design\n\n### Turtles\n\n我们使用下列命令下载所需要的包：\n\n首先在`REPL`下按`]`键调出包管理：\n\n~~~julia\n(v1.0) pkg> add https://github.com/BenLauwens/ThinkJulia.jl\n~~~\n\n~~~julia\njulia> using ThinkJulia\n\njulia> 🐢 = Turtle()\nLuxor.Turtle(0.0, 0.0, true, 0.0, (0.0, 0.0, 0.0))\n~~~\n\n>  输入：`🐢` (**`\\:turtle: TAB`**)。\n\n一旦创建了一个乌龟，可以调用函数来让他移动。\n\n~~~julia\n@svg begin\n    forward(🐢, 100)\nend\n~~~\n\n`@svg`关键字运行一个绘制SVG图片的宏。宏是Julia的一个重要但高级的特性。\n\n为了绘制直角，修改宏\n\n~~~julia\n🐢 = Turtle()\n@svg begin\n    forward(🐢, 100)\n    turn(🐢, -90)\n    forward(🐢, 100)\nend\n~~~\n\n### Simple Repetition\n\n我们使用`for`循环来绘制一个正方形：\n\n~~~julia\n🐢 = Turtle()\n@svg begin\n    for i in 1:4\n        forward(🐢, 100)\n        turn(🐢, -90)\n    end\nend\n~~~\n\n## Conditionals and Recursion\n\n### Floor Division and Modulus\n\n`floor division`符号`÷` (**`\\div TAB`**)，两个数字相除后得到整数。取余符号`%`得到余数。\n\n~~~julia\njulia> minutes = 105            \n105                             \n                                \njulia> hours = minutes÷60       \n1                               \n                                \njulia> remainder = minutes % 60 \n45                              \n~~~\n\n### Boolean Expressions\n\n布尔表达式为结果为真或假的表达式。\n\n~~~julia\n      x == y               # x is equal to y\n      x != y               # x is not equal to y\n      x ≠ y                # (\\ne TAB)\n      x > y                # x is greater than y\n      x < y                # x is less than y\n      x >= y               # x is greater than or equal to y\n      x ≥ y                # (\\ge TAB)\n      x <= y               # x is less than or equal to y\n      x ≤ y                # (\\le TAB)\n~~~\n\n### Logical Operators\n\n与`&&`\n\n或`||`\n\n非`!`\n\n其中`&&`的优先级高于`||`。\n\n### Conditional Execution\n\n```julia\nif x > 0\n    println(\"x is positive\")\nend\n```\n\n### Alternative Execution\n\n```julia\nif x % 2 == 0\n    println(\"x is even\")\nelse\n    println(\"x is odd\")\nend\n```\n\n### Chained Conditionals\n\n~~~julia\nif x < y\n    println(\"x is less than y\")\nelseif x > y\n    println(\"x is greater than y\")\nelse\n    println(\"x and y are equal\")\nend\n~~~\n\n### Nested Conditionals\n\n~~~julia\nif x == y\n    println(\"x and y are equal\")\nelse\n    if x < y\n        println(\"x is less than y\")\n    else\n        println(\"x is greater than y\")\n    end\nend\n~~~\n\n~~~julia\nif 0 < x < 10\n    println(\"x is a positive single-digit number.\")\nend\n~~~\n\n### Recursion\n\n函数自己调用自己被称为递归。\n\n~~~julia\nfunction printn(s, n)\n    if n ≤ 0\n        return\n    end\n    println(s)\n    printn(s, n-1)\nend\n~~~\n\n### Keyboard Input\n\n`Julia`提供内建函数`readline`来停止程序来等待用户输入一些东西，当用户键入`RETURN`或`ENTERN`时程序继续运行，`readline`以字符串的形式返回用户输入的内容。\n\n~~~julia\njulia> text = readline()\nWhat are you waiting for?\n\"What are you waiting for?\"\n~~~\n\n## Fruitful Functions\n\n### Return Values\n\n函数具有返回值：\n\n~~~julia\nfunction area(radius)\n    a = π * radius^2\n    return a\nend\n~~~\n\n我们也可以省略`return`，默认最后一行为函数的返回值：\n\n~~~julia\nfunction area(radius)\n    π * radius^2\nend\n~~~\n\n### Checking Types\n\n~~~julia\nfunction fact(n)\n    if !(n isa Int64)\n        error(\"Factorial is only defined for integers.\")\n    elseif n < 0\n        error(\"Factorial is not defined for negative integers.\")\n    elseif n == 0\n        return 1\n    else\n        return n * fact(n-1)\n    end\nend\n~~~\n\n## Iteration\n\n### The `while` Statement\n\n~~~julia\nfunction countdown(n)\n    while n > 0\n        print(n, \" \")\n        n = n - 1\n    end\n    println(\"Blastoff!\")\nend\n~~~\n\n#### break\n\n~~~julia\nwhile true\n    print(\"> \")\n    line = readline()\n    if line == \"done\"\n        break\n    end\n    println(line)\nend\nprintln(\"Done!\")\n~~~\n\n#### continue\n\n~~~julia\nfor i in 1:10\n    if i % 3 == 0\n        continue\n    end\n    print(i, \" \")\nend\n~~~\n\n## Strings\n\n### Characters\n\n一个字符用单引号`''`包裹：\n\n~~~julia\njulia> 'x'\n'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)\njulia> '🍌'\n'🍌': Unicode U+01f34c (category So: Symbol, other)\njulia> typeof('x')\nChar\n~~~\n\n### A String Is a Sequence\n\n我们可以对字符串进行索引：\n\n~~~julia\njulia> fruit = \"banana\"\n\"banana\"\njulia> letter = fruit[1]\n'b': ASCII/Unicode U+0062 (category Ll: Letter, lowercase)\njulia> fruit[end]\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n~~~\n\n### `length`\n\n`length`返回字符串的长度：\n\n```julia\njulia> fruits = \"🍌 🍎 🍐\"\n\"🍌 🍎 🍐\"\njulia> len = length(fruits)\n5\n```\n\n字符串是使用`UTF-8`进行编码的。`UTF-8`是一个可变宽度的编码，这意味着并非所有字符均以相同数量的字节编码。因此我们索引可能会出错。\n\n函数`sizeof`可以给出字符串的字节数：\n\n~~~julia\njulia> sizeof(\"🍌\")\n4\n~~~\n\n这意味着`UTF-8`编码的字符串中的字节索引并不是并不总是一个字符的合理的索引：\n\n~~~julia\njulia> fruits[2]\nERROR: StringIndexError(\"🍌 🍎 🍐\", 2)\n~~~\n\n### Traversal\n\n~~~julia\nindex = firstindex(fruits)\nwhile index <= sizeof(fruits)\n    letter = fruits[index]\n    println(letter)\n    global index = nextind(fruits, index)\nend\n~~~\n\n`nextind`返回下一个合理的索引；`prevind`查找前一个合理的索引。\n\n### String Slices\n\n~~~julia\njulia> str = \"Julius Caesar\";\n\njulia> str[1:6]\n\"Julius\"\njulia> str[:]\n\"Julius Caesar\"\n~~~\n\n### Strings Are Immutable\n\n~~~julia\njulia> greeting = \"Hello, world!\"\n\"Hello, world!\"\njulia> greeting[1] = 'J'\nERROR: MethodError: no method matching setindex!(::String, ::Char, ::Int64)\n~~~\n\n### String Interpolation\n\n使用符号`$`可以将表达式的值插入到字符串中：\n\n~~~julia\njulia> greet = \"Hello\"  \n\"Hello\"                 \n                        \njulia> whom = \"World\"   \n\"World\"                 \n\njulia> \"$(greet), $(whom)!\"\n\"Hello, World!\"\n~~~\n\n### Searching\n\n~~~julia\nfunction find(word, letter)\n    index = firstindex(word)\n    while index <= sizeof(word)\n        if word[index] == letter\n            return index\n        end\n        index = nextind(word, index)\n    end\n    -1\nend\n~~~\n\n### Looping and Counting\n\n~~~julia\nword = \"banana\"\ncounter = 0\nfor letter in word\n    if letter == 'a'\n        global counter = counter + 1\n    end\nend\nprintln(counter)\n~~~\n\n### String Library\n\n~~~julia\njulia> uppercase(\"Hello, World!\")\n\"HELLO, WORLD!\"\n\njulia> findfirst(\"a\", \"banana\")\n2:2\n\njulia> findfirst(\"na\", \"banana\")\n3:4\n\njulia> findnext(\"na\", \"banana\", 4)\n5:6\n~~~\n\n### The `∈` Operator\n\n~~~julia\njulia> 'a' ∈ \"banana\"    # 'a' in \"banana\"\ntrue\n~~~\n\n### String Comparison\n\n~~~julia\nword = \"Pineapple\"\nif word < \"banana\"\n    println(\"Your word, $(word), comes before banana.\")\nelseif word > \"banana\"\n    println(\"Your word, $(word), comes after banana.\")\nelse\n    println(\"All right, bananas.\")\nend\n> Your word, Pineapple, comes before banana.\n~~~\n\n##  Arrays\n\n`Array`为`Julia`内置的数据结构。\n\n### An Array is a Sequence\n\n数组中元素不一定要是同一种类型，最简单的创建数组的方法是用中括号`[]`：\n\n~~~julia\n[\"spam\", 2.0, 5, [10, 20]]\n~~~\n\n~~~julia\njulia> cheeses = [\"Cheddar\", \"Edam\", \"Gouda\"];\n\njulia> numbers = [42, 123];\n\njulia> empty = [];\n\njulia> print(cheeses, \" \", numbers, \" \", empty)\n[\"Cheddar\", \"Edam\", \"Gouda\"] [42, 123] Any[]\n~~~\n\n我们可以使用`typeof`来查看类型：\n\n~~~julia\njulia> typeof(cheeses)\nArray{String,1}\njulia> typeof(numbers)\nArray{Int64,1}\njulia> typeof(empty)\nArray{Any,1}\n~~~\n\n数组类型包含数组中元素的类型和维度。\n\n### Arrays Are Mutable\n\n数组是可变的：\n\n~~~julia\njulia> numbers[2] = 5\n5\njulia> print(numbers)\n[42, 5]\n~~~\n\n### Traversing an Array\n\n~~~julia\nfor cheese in cheeses\n    println(cheese)\nend\n\nfor x in []\n    println(\"This can never happens.\")\nend\n~~~\n\n### Array Slices\n\n~~~julia\njulia> t = ['a', 'b', 'c', 'd', 'e', 'f'];\n\njulia> print(t[1:3])\n['a', 'b', 'c']\njulia> print(t[3:end])\n['c', 'd', 'e', 'f']\n~~~\n\n`[:]`拷贝数组：\n\n~~~julia\njulia> print(t[:])\n['a', 'b', 'c', 'd', 'e', 'f']\n~~~\n\n### Array Library\n\n`push!`向数组中添加元素：\n\n~~~julia\njulia> t = ['a', 'b', 'c'];\n\njulia> push!(t, 'd');\n\njulia> print(t)\n['a', 'b', 'c', 'd']\n~~~\n\n`append!`将第一个数组的元素放在第二个数组前面：\n\n~~~julia\njulia> t1 = ['a', 'b', 'c'];\n\njulia> t2 = ['d', 'e'];\n\njulia> append!(t1, t2);\n\njulia> print(t1)\n['a', 'b', 'c', 'd', 'e']\n~~~\n\n`sort!`排序，改变原数组，`sort`不改变原数组，带`!`的函数改变原来的数组。\n\n~~~julia\njulia> t = ['d', 'c', 'e', 'b', 'a'];\n\njulia> sort!(t);\n\njulia> print(t)\n['a', 'b', 'c', 'd', 'e']\n\njulia> t1 = ['d', 'c', 'e', 'b', 'a'];\n\njulia> t2 = sort(t1);\n\njulia> print(t1)\n['d', 'c', 'e', 'b', 'a']\njulia> print(t2)\n['a', 'b', 'c', 'd', 'e']\n~~~\n\n\n\n### Dot Syntax\n\n函数前添加`.`是逐元素操作：\n\n~~~julia\njulia> t = uppercase.([\"abc\", \"def\", \"ghi\"]);\n\njulia> print(t)\n[\"ABC\", \"DEF\", \"GHI\"]\n~~~\n\n### Deleting (Inserting) Elements\n\n`splice!`删除返回元素：\n\n~~~julia\njulia> t = ['a', 'b', 'c'];\n\njulia> splice!(t, 2)\n'b': ASCII/Unicode U+0062 (category Ll: Letter, lowercase)\njulia> print(t)\n['a', 'c']\n~~~\n\n`pop!`删除并返回最后一个元素：\n\n~~~julia\njulia> t = ['a', 'b', 'c'];\n\njulia> pop!(t)\n'c': ASCII/Unicode U+0063 (category Ll: Letter, lowercase)\njulia> print(t)\n['a', 'b']\n~~~\n\n`popfirst!`删除返回第一个元素：\n\n~~~julia\njulia> t = ['a', 'b', 'c'];\n\njulia> popfirst!(t)\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\njulia> print(t)\n['b', 'c']\n~~~\n\n`pushfirst!` and `push!`分别在第一位和最后一位插入数据。\n\n`deleteat!`删除但不返回元素：\n\n~~~julia\njulia> t = ['a', 'b', 'c'];\n\njulia> print(deleteat!(t, 2))\n['a', 'c']\n~~~\n\n `insert!`在指定位置插入元素：\n\n~~~julia\njulia> t = ['a', 'b', 'c'];\n\njulia> print(insert!(t, 2, 'x'))\n['a', 'x', 'b', 'c']\n~~~\n\n### Arrays and Strings\n\n`collect`可以将字符串转为数组：\n\n~~~julia\njulia> t = collect(\"spam\");\n\njulia> print(t)\n['s', 'p', 'a', 'm']\n~~~\n\n`split`可以将字符串按照分隔符分割为数组：\n\n~~~julia\njulia> t = split(\"spam-spam-spam\", '-');\n\njulia> print(t)\nSubString{String}[\"spam\", \"spam\", \"spam\"]\n~~~\n\n`join`是`split`的逆运算，将数组转为字符串：\n\n~~~julia\njulia> t = [\"pining\", \"for\", \"the\", \"fjords\"];\n\njulia> s = join(t, ' ')\n\"pining for the fjords\"\n~~~\n\n### Objects and Values\n\n一个对象是变量可以引用的东西。\n\n对于字符串：\n\n~~~julia\njulia> a = \"banana\"\n\"banana\"\njulia> b = \"banana\"\n\"banana\"\njulia> a ≡ b\ntrue\n~~~\n\n对于数组：\n\n~~~julia\njulia> a = [1, 2, 3];\n\njulia> b = [1, 2, 3];\n\njulia> a ≡ b\nfalse\n~~~\n\n### Aliasing\n\n~~~julia\njulia> a = [1, 2, 3];\n\njulia> b = a;\n\njulia> b ≡ a\ntrue\n~~~\n\n变量与对象的关联称为引用。在这个例子中，有两个对同一个对象的引用。\n\n### Array Arguments\n\n当把一个数组传给函数时，函数得到数组的引用，函数会改变数组：\n\n~~~julia\nfunction deletehead!(t)\n    popfirst!(t)\nend\n\njulia> letters = ['a', 'b', 'c'];\n\njulia> deletehead!(letters);\n\njulia> print(letters)\n['b', 'c']\n~~~\n\n函数`vcat`创建新的数组，不会改变原数组：\n\n~~~julia\njulia> t3 = vcat(t1, [4]);\n\njulia> print(t1)\n[1, 2, 3]\njulia> print(t3)\n[1, 2, 3, 4]\n~~~\n\n切片也会创建新数组，不会改变原数组：\n\n~~~julia\nfunction baddeletehead(t)\n    t = t[2:end]                # WRONG!\nend\n\njulia> t4 = baddeletehead(t3);\n\njulia> print(t3)\n[1, 2, 3, 4]\njulia> print(t4)\n[2, 3, 4]\n~~~\n\n","tags":["Julia","编程"],"categories":["书籍阅读"]},{"title":"B站课程Mathematica前三周","url":"/2022/07/01/math/","content":"\n<p align=\"center\">\n    <img src=\"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fi0.hdslb.com%2Fbfs%2Farticle%2F7d065302ef2984abddb60152758c13bd66f74fba.jpg&refer=http%3A%2F%2Fi0.hdslb.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1659263087&t=447b47f50cbb4d4d181ed18e4ac43cb5\" style=\"zoom: 100%;\" />\n</p>\n\n>  B站课程链接：https://www.bilibili.com/video/BV1av411N7Xi?spm_id_from=333.999.0.0&vd_source=6177c61c946280bb88c727585de76bc8\n\n<!--more-->\n\n## 第一周\n\n### 值、变量、类型\n\n以下三种对象成为原子(atom)：\n\n符号(Symbol)：由字母和数字(数字不能在起始位置)构成的有限序列\n\n数字(Number)：整数、有理数、实数、复数\n\n字符串(String)：由双引号`\"\"`括起来的任意字符构成的有限序列\n\n#### 命名\n\n我们在命名时应注意避开系统内建符号，系统内建符号的特点为：\n\n+ 由第一个字母大写的单词组成(Camel命名法)：True、False、FactorInteger、SetAttributes\n+ 用来做判断的函数末尾通常有\"Q\"：EvenQ、PrimeQ、MatchQ\n+ 用人名命名的符号=人名+符号名：EulerGamma、BesselJ、DiracDelta\n\n#### 类型检查\n\n一个编程语言的类型检查越严格，程序员受到的束缚越大。Mathematica程序通常来说都比较短小，靠程序员自觉检查类型基本上就足够了，所以不需要太严格的类型检查机制。一个较弱的类型检查可以让程序员写出更灵活的程序。\n\n~~~mathematica\nSin[\"I'm a string!\"]\n> Sin[\"I'm a string!\"]\nSin[\"I'm a string!\"] /. {\"I'm a string!\" -> Pi/3}\n> Sqrt[3]/2\n~~~\n\n### 条件、循环、子程序\n\n在Mathematica中，条件和循环结构其实用的并不多。这是因为条件结构的功能基本上可以通过核心语言中的模式匹配来完成；而循环结构的功能则可以通过表处理和泛函编程完成。\n\n#### 简单的条件判断\n\n~~~mathematica\nIf[True, Print[\"Then\"]]\n> Then\nIf[False, Print[\"Then\"], Print[\"Else\"]]\n> Else\nIf[a == b, Print[\"Then\"], Print[\"Else\"], Print[\"Unevaluated\"]]\n> Unevaluated\nIf[a === b, Print[\"Then\"], Print[\"Else\"], Print[\"Unevaluated\"]]\n> Else\n~~~\n\n#### 多重条件判断\n\n~~~mathematica\nx = 5; Which[x == 1, 1, x == 2, 2, x == 3, 3, True, Print[\"x!=1,2,3\"]]\n> x!=1,2,3\nPlot[Piecewise[{{1, x == 0}, {Sin[x]/x, x != 0}}], {x, -4 Pi, 4 Pi}]\n~~~\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/math1.jpg)\n\n~~~mathematica\nSwitch[b, True, 1, False, 0, _, Print[\"b is not a boolean value!\"]]\n> b is not a boolean value!\n~~~\n\n#### 简单循环\n\n~~~mathematica\nDo[Print[\"哟,\"], {3}]; Print[\"切克闹!\"]\nDo[Print[Prime[i]], {i, 2, PrimePi[100]}]\nDo[Print[i, \" is a prime number.\"], {i, {2, 3, 5, 7, 11}}]\n~~~\n\n#### 复杂循环\n\n~~~mathematica\nFor[i = 1; t = i, i <= 10, i++, Print[t *= i]]\nn = 1234567; While[Not[PrimeQ[++n]]]; n\n~~~\n\n### 函数\n\n函数定义方法一：模式匹配+延迟赋值\n\n~~~mathematica\nf[x_] := x^2;\nf[x_, y_] := x y;\n~~~\n\n函数定义方法二：纯函数($\\lambda-$表达式、匿名函数)\n\n~~~mathematica\nf1 = Function[x, x^2];\n(* 简写形式 *)\nf2 = #^2 &;\ng1 = Function[{x, y}, x y];\n(* 简写形式 *)\ng2 = #1 #2 &;\n~~~\n\n例子：求不大于给定正整数$n$的所有素数的和\n\n~~~mathematica\n(* 类C实现 *)\nmyPrimeQ = \n  Function[x, i = 2; max = Floor[Sqrt[x]] + 1; \n   While[Mod[x, i] != 0 && i < max, i++]; Not[i < max]];\nmyPrimeSum = \n  Function[n, sum = 0; Do[If[myPrimeQ[x], sum += x], {x, 2, n}]; sum];\n(*核心语言实现。Mathematica内部存储了前10亿个素数的素数表*)\nmyPrimesum2 = Plus @@ Prime /@ Range @ PrimePi[#] &;\nTiming[#[100000]] & /@ {myPrimeSum, myPrimesum2}\n> {{3.4375, 454396537}, {0., 454396537}}\n~~~\n\n## 第二周\n\n### 核心语言\n\n什么是Mathematica核心语言\n\n我们已经看到，虽然Mathematica提供了一些函数可以让我们像编写C程序一样编写Mathematica程序，但是这样编写出来的程序的效率很成问题，而且程序本身也不易懂。另一方面，我们还展示了如何用所谓Mathematica核心语言编制出更高效、更简明的程序。如：\n\n~~~mathematica\nmyPrimesum2 = Plus @@ Prime /@ Range @ PrimePi[#] &;\n~~~\n\n这里有很多符号(`@@`、`/@`、`#`、`&`)，它们其实只是一些Mathematica内建函数的简写形式，其完整形式为：\n\n~~~mathematica\nmyPrimesum2 = Function[n,\n  Apply[\n   Plus,\n   Map[\n    Prime,\n    Range[\n     PrimePi[n]\n     ]\n    ]\n   ]\n  ] \n~~~\n\n在Mathematica中，我们可以用TreeForm来获得一个表达式的语法树。\n\n~~~mathematica\nTreeForm[(a + b^n)/z == x]\n~~~\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/math2.jpg)\n\n我们也可以用FullForm来获得一个表达式在Mathematica内部的完整形式：\n\n~~~mathematica\nFullForm[(a + b^n)/z == x]\n> FullForm[(a + b^n)/z == x]\n~~~\n\n在Mathematica中，满足如下条件的对象就叫做表达式\n\n1. 原子对象是表达式\n2. 若$\\mathrm{F,X_1,X_2,\\cdots,X_n}$是表达式，则$\\mathrm{F[X_1,X_2,\\cdots,X_n]}$也是表达式。\n\nMathematica中的一切对象都是表达式，一个Mathematica程序就是一个表达式。\n\n> 这一事实如此地重要，以至于有人将其称为Mathematica的第一原理：万物皆表(达式)。\n\nMathematica的计算：\n\n1. 从待计算对象中识别一些可化简的模式\n2. 将识别出的模式用已知的规则进行化解\n\nMathematica是这样进行计算的，其中第一步叫做模式匹配，第二步叫做规则代入。基于模式和规则的计算模型在数理逻辑或计算机科学中叫做重写系统。\n\nMathematica第二原理：计算即重写。\n\n### 表达式与表\n\n根据定义，一个表达式或者是原子，或者是形如$\\mathrm{F[X_1,X_2,\\cdots,X_n]}$的函数。事实上，原子也可以看成后者的特殊情况，只要我们把函数的自变量个数取成零就行了。所以，以后我们讨论表达式的时候，总把它写成$\\mathrm{F[X_1,X_2,\\cdots,X_n]}$的样子。\n\n给定一个表达式$\\mathrm{F[X_1,X_2,\\cdots,X_n]}$，我们称$\\mathrm{F}$是它的\"头\"。\n\n~~~mathematica\nHead /@ {1, 1/2, True, \"number\", a + b, a - b, a*b, \n  a/b, (f + g)[x1, x2, x3]}\n> {Integer, Rational, Symbol, String, Plus, Plus, Times, Times, f + g}\n~~~\n\n我们发现对于原子表达式：符号的头总是Symbol；数字的头则依赖于它的类型，结果可以是Integer、Rational、Real和Complex；字符串的头总是String；图片的头是Image等等。\n\n利用这个性质，我们可以判断一个表达式是否是原子。\n\n~~~mathematica\nmyAtomQ = \n  Function[ex, \n   MemberQ[{Symbol, Integer, Rational, Reals, Complex, String, \n     Image}, Head[ex]]];\n~~~\n\n除了头以外，我们也常常需要将表达式的参数部分取出来。取出来的东西一些表达式构成的序列，是没有头的。但是在Mathematica里所有的表达式都必须有头，所以，为了处理这种无头表达式，Mathematica引入表(List)这个概念，然后规定所哟无头表达式的头都是List。\n\n~~~mathematica\nex = f[x1, x2, x3];\nList @@ ex\nApply[g, ex]\n(*可以将Apply函数理解为换头*)\n> {x1, x2, x3}\n> g[x1, x2, x3]\n~~~\n\n表这种表达式还有一种变体，叫做序列(Sequence)。序列可以认为是没有两边花括号(\"{}\")的表，或者说，表是用序列的元素做成了一个新的对象，而序列是某种更原始的东西。\n\n~~~mathematica\nex = h[1, 2, 3];\nseq = Sequence @@ ex\nlst = List @@ ex\n> Sequence[1, 2, 3]\n> {1, 2, 3}\n~~~\n\n~~~mathematica\nf[seq]\nf[lst]\nf @@ lst\nf[seq, lst, 4, 5, 6]\n> f[1, 2, 3]\n> f[{1, 2, 3}]\n> f[1, 2, 3]\n> f[1, 2, 3, {1, 2, 3}, 4, 5, 6]\n~~~\n\n上面的例子表明，当我们想把一个表达式的参数传递给另一个函数时，用List换头的结果可能不是我们想要的，因为多了一层花括号。如果不想要这层花括号，就要用Sequence换头。\n\n除了用Head和Apply以外，Mathematica还提供了另一种访问复合表达式内部表达式的方法，即系统内建函数Part，简写形式为`[[...]]`。\n\n~~~mathematica\nex = f[x1, x2, x3];\n{ex[[0]], ex[[1]], ex[[2]], ex[[3]]}\n> {f, x1, x2, x3}\n~~~\n\n对于嵌套的表达式，我们可以多次地取Part：\n\n~~~mathematica\nex = f[a, g[b, c], h[d, k[e, i], j]];\nex[[3]][[2]][[2]]\n> i\n~~~\n\n这个操作可以通过一个Part实现：\n\n~~~mathematica\nex[[3, 2, 2]]\n> i\n~~~\n\n另外Part还有更多的用法：\n\n~~~mathematica\nex[[-1, -2, -1]]\nex[[{2, 3}]]\nex[1 ;; 2]\nex[[1 ;; 3 ;; 2]]\n> i\n> f[g[b, c], h[d, k[e, i], j]]\n> f[a, g[b, c], h[d, k[e, i], j]][1 ;; 2]\n> f[a, h[d, k[e, i], j]]\n~~~\n\n最常用的Part都有属于它们自己的内建函数：\n\n~~~mathematica\nFunction[op, op[f[x1, x2, x3, x4]]] /@ {First, Last, Rest, Most}\n> {x1, x4, f[x2, x3, x4], f[x1, x2, x3]}\nTake[f[x1, x2, x3, x4], {2, 3}]\nDrop[f[x1, x2, x3, x4], {2, 3}]\n> f[x2, x3]\n> f[x1, x4]\n~~~\n\n对于Take函数，我们可以这样替代：\n\n~~~mathematica\nf[x1, x2, x3, x4][[{2, 3}]]\n> f[x2, x3]\n~~~\n\n对于给定的表达式，有两个值很重要，即它的长度和深度：\n\n~~~mathematica\nLength[f[g[x1, h[x2, x3]], x4]]\nDepth[f[g[x1, h[x2, x3]], x4]]\n> 2\n> 4\n~~~\n\n### 表的构造\n\n~~~mathematica\nRange[10]\nRange[2, 10]\nRange[2, 10, 3]\n> {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n> {2, 3, 4, 5, 6, 7, 8, 9, 10}\n> {2, 5, 8}\n~~~\n\n~~~mathematica\nTable[i^2 + i + 1, {i, 10}]\nTable[KroneckerDelta[i, j - 1] + t KroneckerDelta[i, j + 4], {i, \n   5}, {j, 5}] // MatrixForm\n> {3, 7, 13, 21, 31, 43, 57, 73, 91, 111}\n~~~\n\n$$\n\\left(\\begin{array}{lllll}\n0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1 \\\\\nt & 0 & 0 & 0 & 0\n\\end{array}\\right)\n$$\n\n~~~mathematica\nArray[#^2 + # + 1 &, 10]\n> {3, 7, 13, 21, 31, 43, 57, 73, 91, 111}\n#^2 + # + 1 & /@ Range[10]\n> {3, 7, 13, 21, 31, 43, 57, 73, 91, 111}\n\nArray[f, 5, 2, h](*5指的是长度，2指的是起始位置，h指的是头*)\n> h[f[2], f[3], f[4], f[5], f[6]]\n~~~\n\n~~~mathematica\nTuples[Range[3], 2]\n> {{1, 1}, {1, 2}, {1, 3}, {2, 1}, {2, 2}, {2, 3}, {3, 1}, {3, 2}, {3, \n  3}}\nOuter[f, Range[3], Range[2]]\n> {{f[1, 1], f[1, 2]}, {f[2, 1], f[2, 2]}, {f[3, 1], f[3, 2]}}\n~~~\n\n### 表的查询和搜索\n\n~~~mathematica\nex = f[x1, x2, x3, x4];\nFunction[i, MemberQ[ex, i]] /@ {f, x1, x2, x3, x4, x5, x6}\nFunction[i, FreeQ[ex, i]] /@ {f, x1, x2, x3, x4, x5, x6}\n> {False, True, True, True, True, False, False}\n> {False, False, False, False, False, True, True}\n~~~\n\n可以看出MemberQ和FreeQ结果并不是相反的。\n\nMemberQ函数还有参数：\n\n~~~mathematica\nMemberQ[ex, f, Heads -> True]\n> True\n~~~\n\nFreeQ函数可以指定深度（默认深度是所有深度都查找）：\n\n~~~mathematica\nFreeQ[{{1, 1, 3, 0}, {2, 1, 2, 2}}, 0]\nFreeQ[{{1, 1, 3, 0}, {2, 1, 2, 2}}, 0, 1](*在第一层搜索*)\n> False\n> True\n~~~\n\n还有Count函数(默认只看第一层)：\n\n~~~mathematica\neuler = (a + b^n)/n == x;\n{Count[euler, n], Count[euler, n, Infinity]}\n> {0, 2}\n~~~\n\nPosition可以找到位置：\n\n~~~mathematica\nPosition[euler, n]\nPosition[euler, n, 4]\nPosition[euler, n, {4}](*带{}表示只搜这一层，不带表示最深搜到这层*)\nFunction[level, Position[euler, n, level]] /@ {0, 1, 2, 3, 4}\nFunction[level, Position[euler, n, level]] /@ {3, 4}\nFunction[level, Position[euler, n, level]] /@ {{3}, {4}}\n> {{1, 1, 2, 2}, {1, 2, 1}}\n> {{1, 1, 2, 2}, {1, 2, 1}}\n> {{1, 1, 2, 2}}\n> {{}, {}, {}, {{1, 2, 1}}, {{1, 1, 2, 2}, {1, 2, 1}}}\n> {{{1, 2, 1}}, {{1, 1, 2, 2}, {1, 2, 1}}}\n> {{{1, 2, 1}}, {{1, 1, 2, 2}}}\n~~~\n\nSelect选取满足某个条件的：\n\n~~~mathematica\nSelect[Prime /@ Range[10], OddQ]\nSelect[Prime /@ Range[10], Mod[#, 4] == 1 &]\n> {3, 5, 7, 11, 13, 17, 19, 23, 29}\n> {5, 13, 17, 29}\n~~~\n\n### 表的添加、删除和修改\n\n下面的操作不改变表达式本身：\n\n~~~mathematica\nex = f[a, b, c];\n{Prepend[ex, z], Append[ex, d], Insert[ex, i, 2], Insert[ex, i, -2]}\n> {f[z, a, b, c], f[a, b, c, d], f[a, i, b, c], f[a, b, i, c]}\nex\n> f[a, b, c]\n~~~\n\n下面的操作会改变表达式：\n\n~~~mathematica\n{PrependTo[ex, z], AppendTo[ex, d]}\n> {f[z, a, b, c], f[z, a, b, c, d]}\n~~~\n\nDelete也不改变原表达式：\n\n~~~mathematica\nDelete[ex, 1]\nDelete[ex, {{1}, {-1}}]\n> f[a, b, c, d]\n> f[a, b, c]\n~~~\n\nReplacePart也不改变：\n\n~~~mathematica\n{ReplacePart[ex, 1 -> x], ex}\n> {f[x, a, b, c, d], f[z, a, b, c, d]}\n~~~\n\n但是下面会改变：\n\n~~~mathematica\nex[[1]] = y;\nex\n> f[y, a, b, c, d]\n~~~\n\n下面的是旋转的函数：\n\n~~~mathematica\nReverse[ex]\nRotateLeft[ex, 2]\nRotateRight[ex, -1]\n> f[d, c, b, a, y]\n> f[b, c, d, y, a]\n> f[a, b, c, d, y]\n~~~\n\n### 集合运算\n\n头部一样的表达式之间的集合运算：\n\n~~~mathematica\nJoin[f[x1, x2], f[x1, x3]]\n> f[x1, x2, x1, x3]\nUnion[f[x1, x2, x1, x3]]\n> f[x1, x2, x3]\nIntersection[f[x1, x2, x3], f[x1, x2, x4]]\n> f[x1, x2]\nComplement[f[x1, x2, x3], f[x1, x2, x4]]\n> f[x3]\n~~~\n\n### 排序\n\n~~~mathematica\nlist = Array[RandomInteger[10] &, {20, 2}]\nSort[list]\n> {{8, 0}, {6, 7}, {4, 3}, {2, 10}, {9, 6}, {1, 0}, {5, 10}, {8, \n  10}, {1, 1}, {8, 5}, {5, 8}, {9, 3}, {10, 7}, {4, 3}, {2, 9}, {4, \n  5}, {5, 1}, {1, 0}, {4, 3}, {5, 9}}\n> {{1, 0}, {1, 0}, {1, 1}, {2, 9}, {2, 10}, {4, 3}, {4, 3}, {4, 3}, {4, \n  5}, {5, 1}, {5, 8}, {5, 9}, {5, 10}, {6, 7}, {8, 0}, {8, 5}, {8, \n  10}, {9, 3}, {9, 6}, {10, 7}}\n\nSort[list, Function[{list1, list2}, list1[[1]] < list2[[1]]]]\n> {{1, 0}, {1, 1}, {1, 0}, {2, 9}, {2, 10}, {4, 3}, {4, 5}, {4, 3}, {4, \n  3}, {5, 9}, {5, 1}, {5, 8}, {5, 10}, {6, 7}, {8, 5}, {8, 10}, {8, \n  0}, {9, 3}, {9, 6}, {10, 7}}\nSort[list, (#1[[1]] < #2[[1]]) || (#1[[1]] == #2[[1]] && #1[[2]] > #2[[2]]) &]\n> {{1, 1}, {1, 0}, {1, 0}, {2, 10}, {2, 9}, {4, 5}, {4, 3}, {4, 3}, {4, \n  3}, {5, 10}, {5, 9}, {5, 8}, {5, 1}, {6, 7}, {8, 10}, {8, 5}, {8, \n  0}, {9, 6}, {9, 3}, {10, 7}}\n  \nlist = {2, 3, 5, 1, 4}\nSort[list]\nOrdering[list]\nlist[[Ordering[list]]]\n\n> {2, 3, 5, 1, 4}\n> {1, 2, 3, 4, 5}\n> {4, 1, 2, 5, 3}\n> {1, 2, 3, 4, 5}\n~~~\n\n## 第三周\n\n例：一种常用的提速技巧\n\n`Append`函数很慢，因为在表的最后插入数据，需要遍历整个表。\n\n问题：找到不大于$n$的所有无平方因子的自然数\n\n~~~mathematica\nsolution1 = \n  Function[n, L = {}; \n   Function[i, If[SquareFreeQ[i], AppendTo[L, i]]] /@ Range[n]; L];\nsolution2 = \n  Function[n, L = {}; \n   Function[i, If[SquareFreeQ[i], PrependTo[L, i]]] /@ Range[n]; \n   Reverse[L]];\n(*嵌套表:Flatten*)\nsolution3 = \n  Function[n, L = {}; \n   Function[i, If[SquareFreeQ[i], L = {L, i}]] /@ Range[n]; \n   Flatten[L]];\n(*收获与播种*)\nsolution4 = \n  Function[n, \n   Reap[Function[i, If[SquareFreeQ[i], Sow[i], 0]] /@ Range[n]][[2, \n     1]]];\n\nTiming[#[50000]][[1]] & /@ {solution1, solution2, solution3, \n  solution4}\n> {1.5625, 1.34375, 0.125, 0.109375}\n~~~\n\n但是Flatten函数也存在缺点，就是当我们搜索的结果中含有表时，会破坏我们搜索结果的结构，我们可以使用下面的方法解决：\n\n求解`Pell`方程$x^2-2y^2=1$的满足$1\\le y\\le n$的解。\n\n~~~mathematica\nsolution5 = \n  Function[n, L = {}; \n   Do[If[IntegerQ[x = Sqrt[1 + 2 y^2]], L = {L, list[x, y]}], {y , \n     n}]; Flatten[L] /. {list -> List}];\n~~~\n\n这里是用`list`代替`List`放置被压平，之后又还原。\n\n但收获与播种不存在此类问题：\n\n~~~mathematica\nsolution6 = \n Function[n, \n  Reap[Do[If[IntegerQ[x = Sqrt[1 + 2 y^2]], Sow[{x, y}]], {y, n}]][[2,\n     1]]]\n~~~\n\n收获与播种是很有用的一种构造表的方法，它们还有更高级的用法：播种的时候可以给每个种子加标签，收获时可以按照标签或模式匹配进行收获。\n\n~~~mathematica\nReap[\n Sow[张三, {披萨, 可乐, 鸡翅}];\n Sow[李四, {意面, 可乐, 鸡翅}];\n Sow[王五, {披萨, 雪碧, 薯条}];\n Sow[刘六, {意面, 红茶, 沙拉}];\n Sow[陈七, {披萨, 可乐, 薯条}];\n Sow[杨八, {意面, 橙汁, 沙拉}];,\n 红茶\n ]\n > Null, {{刘六}}}\n \n Reap[\n Sow[张三, {披萨, 可乐, 鸡翅}];\n Sow[李四, {意面, 可乐, 鸡翅}];\n Sow[王五, {披萨, 雪碧, 薯条}];\n Sow[刘六, {意面, 红茶, 沙拉}];\n Sow[陈七, {披萨, 可乐, 薯条}];\n Sow[杨八, {意面, 橙汁, 沙拉}];,\n _, #1 -> #2 &\n ]\n \n > {Null, {披萨 -> {张三, 王五, 陈七}, 可乐 -> {张三, 李四, 陈七}, 鸡翅 -> {张三, 李四}, \n  意面 -> {李四, 刘六, 杨八}, 雪碧 -> {王五}, 薯条 -> {王五, 陈七}, 红茶 -> {刘六}, \n  沙拉 -> {刘六, 杨八}, 橙汁 -> {杨八}}}\n~~~\n\n`,`后的表示模式匹配,`_`表示所有模式都可，而后面的为匿名函数。\n\n### 模式匹配\n\n我们已经提过Mathematica的第二原理：计算即重写。重写分两步、分别是模式匹配和规则代入。我们先讲模式匹配。\n\n所谓模式，是指满足一定条件的表达式构成的集合。而模式匹配，就是从给定的待计算表达式中搜索出符合某种模式（即输入这个集合）的子表达式。模式匹配完成之后，我们就可以对这些匹配出来的子表达式应用计算规则，从而达到计算或化简的目的。有些时候，我们的目标本身就是某种搜索结果，如果善用模式匹配，就可以写出非常高效的程序。\n\n根据定义，单个表达式也可以认为是一种模式，它只包含一个表达式作为其元素，这在模式匹配的时候也是很常见的。不过这种模式太简单了，我们称之为平凡模式，我们后面讨论模式时一般总假设是非平凡的。\n\n最简单的(非平凡)的模式是`_`，全名`Blank[]`，它代表一切表达式。\n\n~~~mathematica\nFullForm /@ {f[_], g[_, _], _[x, y], _[_, _, _]}\n> {f[Blank[]],g[Blank[],Blank[]],Blank[][x,y],Blank[][Blank[],Blank[],Blank[]]}\n\nFullForm /@ {_ + _, _ - _, _*_, _^_}\n> {Times[2,Blank[]],0,Power[Blank[],2],Power[Blank[],Blank[]]}\n~~~\n\n~~~mathematica\nMatchQ[a + b, _ + _]\nMatchQ[a + a, _ + _]\nMatchQ[a - b, _ - _]\nMatchQ[a - a, _ - _]\nMatchQ[a*b, _*_]\nMatchQ[a*a, _*_]\nMatchQ[a/b, _/_]\nMatchQ[a/a, _/_]\nMatchQ[g[a, b], _[_, _]]\n> False\n> True\n> False\n> True\n> False\n> True\n> False\n> True\n> True\n~~~\n\n`+,-,/,*`为具体的二元运算，而`g`为抽象的二元运算，所以结果可能有所不同。\n\n我们可以将匹配好的模式命名，其完整形式为Pattern[name, pattern]，简写形式有两种，分别对应于不同的优先级。\n\n~~~mathematica\nFullForm[x_]\nFullForm[x : _]\nFullForm[x_[_]]\nFullForm[x : _[_]]\n> Pattern[x,Blank[]]\n> Pattern[x,Blank[]]\n> Pattern[x,Blank[]][Blank[]]\n> Pattern[x,Blank[][Blank[]]]\n~~~\n\n如果在一个模式中，同一个命名模式出现了多次，它们会被认为是同样的。\n\n~~~mathematica\nMatchQ[f[a, a], f[x_, x_]]\nMatchQ[f[a, b], f[x_, x_]]\nMatchQ[f[a, b], f[x_, y_]]\n> True\n> False\n> True\n~~~\n\n注意模式匹配是按Mathematica内部的FullForm匹配的，它总是基于结构的，而非基于数学的。例如当我们匹配`x^_`这个模式时，`x`本身并不会匹配到，尽管在数学上$x=x^1$。\n\n~~~mathematica\n{1, x, x^2, x^3} /. {x^n_ :>  p[n]}\n> 1, x, p[2], p[3]}\n~~~\n\n为了解决这个问题，我们可以这样：\n\n~~~mathematica\n{1, x, x^2, x^3} /. {x^n_ :>  p[n], 1 -> p[0], x -> p[1]}\n> {p[0], p[1], p[2], p[3]}\n~~~\n\n但是如果有涉及到带有交换性、结合性的函数，Mathematica也会变得聪明一些。\n\n~~~mathematica\n{a + b, b + c, Plus[a, Plus[b, c]]} /. {b + x_  :> x}\n> {a, c, a + c}\n~~~\n\n这是因为Plus这个函数在Mathematica内部具有Flat和Orderless两种属性，分别对应于结合性和交换性。Mathematica在做模式匹配的时候会考虑这些属性导致的一些等价形式，如Plus[a,b] = Plus[b,a]，Plus[a,Plus[b,c]] = Plus[b, Plus[a,c]]等等。\n\n我们可以用Cases函数来列出所匹配的东西，不指定深度只搜第一层：\n\n~~~mathematica\nCases[1 + x + f[x^2, x^3], x^_]\nCases[1 + x + f[x^2, x^3], x^_, Infinity]\n> {}\n> {x^2, x^3}\n~~~\n\n~~~mathematica\nMax[Cases[a0 + a1 x + a2 x^2 + a3 x^3, x^n_ :> n, Infinity]]\n> 3\n~~~\n\n可以用模式匹配模式：\n\n~~~mathematica\nCases[{a -> b, c -> d}, HoldPattern[a -> _]]\n> {a -> b}\n~~~\n\n还可以用DeleteCases去掉被匹配到的东西。\n\n~~~mathematica\nDeleteCases[f[x] + g[y], f[_]]\n> g[y]\nDeleteCases[CoefficientList[(1 + x)^10 + (1 - x)^10, x], 0]\n> {2, 90, 420, 420, 90, 2}\n(*CoefficientList求多项式系数*)\n~~~\n\n比简单匹配稍微复杂一点的是类型匹配，完整形式为Blank[head]：\n\n~~~mathematica\nCases[{1, 2.5, x, y, f[x]}, _f]\nCases[{1, 2.5, x, y, f[x]}, _Symbol]\nCases[{1, 2.5, x, y, f[x]}, _Integer]\nCases[{1, 2.5, x, y, f[x]}, _Real]\n> {f[x]}\n> {x,y}\n> {1}\n> {2.5}\n~~~\n\n更复杂的是带条件的模式：\n\n~~~mathematica\nCases[{1, 2, 3, 4, 5, 6, x, y}, _?(EvenQ[(# + #^2)/2] &)]\nCases[{1, 2, 3, 4, 5, 6, x, y}, _?(Not@EvenQ[(# + #^2)/2] &)]\nCases[{1, 2, 3, 4, 5, 6, x, y}, Except[_?(EvenQ[(# + #^2)/2] &)]]\nCases[{1, 2, 3, 4, 5, 6, x, y}, \n Except[_?(EvenQ[(# + #^2)/2] &), _?NumberQ]]\n > {3, 4}\n > {1, 2, 5, 6, x, y}\n > {1, 2, 5, 6, x, y}\n > 1, 2, 5, 6}\n~~~\n\n`Except[c,p]`满足`p`但不满足`c`。\n\n与命名类似，条件也有更低优先级的一种简写形式：\n\n~~~mathematica\nCases[{{1, 2}, {2, 3}, {3, 1}}, _?(#[[1]] < #[[2]] &)]\nCases[{{1, 2}, {2, 3}, {3, 1}}, {x_, y_} /; x < y]\n> {{1, 2}, {2, 3}}\n> {{1, 2}, {2, 3}}\n~~~\n\n运算符`/;`经常被用来定义分情况的函数，如著名的$3x+1$问题：\n\n~~~mathematica\nf[n_] := n/2 /; EvenQ[n]\nf[n_] := 3 n + 1 /; OddQ[n]\n~~~\n\n如何定义双线性运算？\n\n~~~mathematica\ninner[x1_ + x2_, x3_] := inner[x1, x3] + inner[x2, x3]\ninner[x1_, x2_ + x3_] := inner[x1, x2] + inner[x1, x3]\ninner[a_?NumberQ x1_, x2_] := a inner[x1, x2]\ninner[x1_, a_?NumberQ x2_] := a inner[x1, x2]\n\ninner[3 x + 2 y, z/2]\n> 3/2 inner[x, z] + inner[y, z]\n~~~\n\n有时候我们需要对好几种情况做同一种规则代入，这时候就需要\"或然匹配\"，其形式为`p1|p2|p3`：\n\n~~~mathematica\n{1, 1/2, 0.25, 3 + 4 I} /. {_Rational -> 0, _Real -> 0}\n{1, 1/2, 0.25, 3 + 4 I} /. {_Rational | _Real -> 0}\nCases[Symbol /@ CharacterRange[\"a\", \"z\"], Except[a | e | i | o | u]]\n> {1, 0, 0, 3 + 4 I}\n> {1, 0, 0, 3 + 4 I}\n> {b, c, d, f, g, h, j, k, l, m, n, p, q, r, s, t, v, w, x, y, z}\n~~~\n\n之前模式匹配都是针对一个表达式的，模式匹配还可以对表达式序列进行。\n\n~~~mathematica\n{f[], f[x], f[x, y]} /. {f[a__] :> {a}}\n{f[], f[x], f[x, y]} /. {f[a___] :> {a}}\n> {f[], {x}, {x, y}}\n> {{}, {x}, {x, y}}\n~~~\n\n两个下划线对于空(0个表达式，对应于f[]无表达式)不匹配，三个下划线匹配空为空。\n\n例子：判断表中元素是否都是素数。\n\n~~~mathematica\nlistPrimeQ[list_] := \n Not@MatchQ[list, {___, _?(Not[PrimeQ[#]] &), ___}]\n (*前后两个___，表示前面有0个或多个表达式，中间的不能为素数*)\nlist = Array[#^2 + # + 41 &, 40, 0]\nlistPrimeQ[list]\n> True\n~~~\n\n用Longest和Shortest可以控制`__`和`___`的匹配长度：\n\n~~~mathematica\n{a, b, c, d, e, f, g} /. {x__, y__, z__} -> {{x}, {y}, {z}}\n{a, b, c, d, e, f, g} /. {x__, Longest[y__], z__} -> {{x}, {y}, {z}}\n> {{a}, {b}, {c, d, e, f, g}}\n> {{a}, {b, c, d, e, f}, {g}}\n~~~\n\n重复模式：\n\n~~~mathematica\nCases[{f[a], f[a, b], f[a, a], f[a, a, a]}, f[a ..]]\nCases[{f[a], f[a, b], f[a, a], f[a, a, a]}, f[Repeated[a]]]\nCases[{f[a], f[a, b], f[a, a], f[a, a, a]}, f[Repeated[a, 2]]]\nCases[{f[a], f[a, b], f[a, a], f[a, a, a]}, f[Repeated[a, {2, 3}]]]\n> {f[a], f[a, a], f[a, a, a]}\n> {f[a], f[a, a], f[a, a, a]}\n> {f[a], f[a, a]}\n> {f[a, a], f[a, a, a]}\n~~~\n\n模式序列：\n\n~~~mathematica\nf[x : PatternSequence[_, _], y___] := p[{x}, {y}]\n{f[1], f[1, 2], f[1, 2, 3, 4, 5]}\n> {f[1], p[{1, 2}, {}], p[{1, 2}, {3, 4, 5}]}\n{a, b, b, a, b, a, b, a, a, \n  b} /. {___, x : Longest[PatternSequence[a, b] ..], ___} :> {x}\n> {a, b, a, b}\n~~~\n\n模式的默认值：\n\n~~~mathematica\nplus[x_: 0, y_: 0] := x + y;\nplus[]\nplus[x]\nplus[x, y]\n> 0\n> x\n> x+y\n~~~\n\n~~~mathematica\n{1, x, x^2, x^3} /. {x^n_ :> n}\n{1, x, x^2, x^3} /. {x^n_. :>  n}(*相当于把Power函数的默认值也考虑进去了*)\n> {1, x, 2, 3}\n> {1, 1, 2, 3}\n~~~\n\n字面模式：\n\n~~~mathematica\n{f[2], f[a], f[x_], f[y_]} /. f[x_] :> x^2\n{f[2], f[a], f[x_], f[y_]} /. f[Verbatim[x_]] :> x^2\n> {4, a^2, x_^2, y_^2}\n> {f[2], f[a], x^2, f[y_]}\n~~~\n\n","tags":["Mathematica","编程"],"categories":["课程笔记"]},{"title":"Statistical Rethinking:Chapter3","url":"/2022/06/29/rt3/","content":"\n## Sampling the Imaginary\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt3_1.png)\n\n<!--more-->\n\n### Sampling from a grid-approximate\n\n我们先用第二章的例子生成后验分布：\n\n~~~R\np_grid <- seq(from=0, to=1, length.out=1000)\nprior <- rep(1, 1000)\nlikelihood <- dbinom(6, size = 9, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n~~~\n\n下面我们对后验进行抽样，抽取$10000$个样本：\n\n~~~R\n# sample\nsamples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\n# plot(samples)\ndens(samples)\n~~~\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt3_2.jpeg)\n\n### Sampling to summarize\n\n对样本进行总结主要包含以下几个方面：\n\n1. 定义边界的区间\n2. 定义概率质量区间的问题\n3. 点估计的问题\n\n#### Intervals of defined boundaries\n\n~~~R\n# add up posterior probability where p < 0.5\nsum(posterior[p_grid < 0.5])\n> 0.1718746\n\n# use samples\nsum(samples < 0.5) / 1e4\n> 0.1731\n\nsum(samples > 0.5 & samples < 0.75) / 1e4\n> 0.6037\n~~~\n\n#### Intervals of defined mass\n\n~~~R\nquantile(samples, 0.8)\n>       80% \n0.7597598 \n\nquantile(samples, c(0.1, 0.9))\n>       10%       90% \n0.4504505 0.8118118 \n~~~\n\n我们也可以通过`PI`和`HDPI`（highest posterior density interval ）函数计算给定概率质量的区间：\n\n~~~R\np_grid <- seq( from=0 , to=1 , length.out=1000 )\nprior <- rep(1,1000)\nlikelihood <- dbinom( 3 , size=3 , prob=p_grid ) \nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\nsamples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )\n# center\nPI(samples, prob = 0.5)\n>       25%       75% \n0.7067067 0.9321822 \n\nHPDI(samples, prob = 0.5)\n>   |0.5      0.5| \n0.8428428 0.9979980 \n~~~\n\n一般情况下`PI`和`HDPI`的结果相差不大，但是当概率密度函数高度倾斜时其值会大不相同。\n\n#### Point estimates\n\n最大后验估计：\n\n~~~R\np_grid[which.max(posterior)]\n> 1\n~~~\n\n也可以根据样本来计算众数：\n\n~~~R\nchainmode(samples, adj=0.01)\n> 0.9901787\n~~~\n\n或是均值和中位数\n\n~~~R\nmean(samples)\nmedian(samples)\n> 0.8015405\n> 0.8448448\n~~~\n\n那么描述后验估计用哪一个点呢？有时候我们采用损失函数还衡量点的好坏，但是损失函数的选择也会影响点的选择，如我们选择两个点之间距离的绝对值的差值作为损失函数，那么答案就是中位数。\n\n~~~R\nloss <- sapply(p_grid, function(d) sum(posterior*abs(d-p_grid)))\np_grid[which.min(loss)]\n> 0.8408408\n~~~\n\n可以看到与中位数非常接近。\n\n### Sampling to simulate prediction\n\n#### Dummy data\n\n似然函数也可以用来产产生数据，例如我们之间的例子，我们的似然函数为：\n$$\n\\Pr(w\\mid n,p) = \\frac{n!}{w!(n-w)!}p^w(1-p)^{n-w}\n$$\n例如计算投掷两次，分别有$0,1,2$次是水的概率，$p=0.7$。\n\n~~~R\ndbinom(0:2, size = 2, prob = 0.7)\n> 0.09 0.42 0.49\n~~~\n\n产生数据：\n\n~~~R\nrbinom(10, size = 2, prob = 0.7)\n> 0 2 2 0 1 2 1 2 1 1\n~~~\n\n让我们以$p=0.7$的概率投掷$9$次产生$100000$个数据：\n\n~~~R\ndummy_w <- rbinom(1e5, size = 9, prob = 0.7)\nsimplehist(dummy_w, xlab = \"dummy water count\")\n~~~\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt3_3.jpeg)\n\n\n\n#### Model checking\n\n现在我们的模型有两个不确定性，一个是$p$的不确定性，因为$p$存在一个后验分布，另一个是样本生成的不确定性，即使对于固定的$p$，样本的生成也是不确定的。\n\n~~~R\nw <- rbinom(1e4, size = 9, prob = samples)\nsimplehist(w)\n~~~\n\n相当于我们先从$p$的后验分布中采样$p$，之后根据采样得到的$p$生成数据，得到的就是$p$的**后验预测分布**。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt3_4.jpeg)\n\n","tags":["概率编程","贝叶斯统计","Statistical Rethinking"],"categories":["书籍阅读"]},{"title":"Statistical Rethinking:Chapter2","url":"/2022/06/29/rt2/","content":"\n## Small Worlds and Large Worlds\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_1.png)\n\n当初麦哲伦进行环球航行的时候，错误地认为地球比实际要小，他认为地球的周长只有$30000$km而不是$40000$km。麦哲伦的大小世界提供了模型与现实的对比。小世界是模型自成一体的逻辑世界，在这个小世界里我们根据自己的认知对模型做出一系列假设并且能够验证模型的逻辑。假设小世界是对现实世界的准确描述，没有替代模型可以更好地利用数据中的信息并支持更好的决策。\n\n大世界是现实世界，可能存在很多我们小世界中没有考虑的事件，模型是对现实世界的不完整表示。\n\n<!--more-->\n\n### The garden of forking data\n\n给定数据，能够用更多的方式产生数据的解释更可靠(概率更大)。\n\n#### Counting possibilities\n\n考虑下面的例子，假设有个袋子里有$4$个球，球的颜色为蓝色和白色，我们有放回地取三个球，得到的结果为**蓝白蓝**。袋子里的球和对应于产生该结果的方式如下表所示：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_2.jpg)\n\n所以我们推测袋子里的球为第四种的可能性较大。\n\n#### Using prior information\n\n我们也可以结合先验信息。假设我们又从袋子里抽出来一个球为蓝色，那么我们上面得到的结果就可以作为先验来进行推测，与现在的结果进行相乘，得到的结果如下图：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_3.jpg)\n\n> 第一列每中假设为产生新数据的方式，第二列为之前的结果作为先验。\n\n#### From counts to probability\n\n我们可以将之间的计算转为概率，还是之前的例子，变为：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_4.jpg)\n\n> $p$为蓝色的比例。\n\n计算方法为：\n\n~~~R\nways <- c(0, 3, 8, 9, 0)\nways/sum(ways)\n> 0.00 0.15 0.40 0.45 0.00\n~~~\n\n### Building a  model\n\n假设我们要估计地球上海洋所占的比例，假设我们在地球上随机抽样得到的结果为`WLWWWLWLW`。我们利用上面提到的方法对其进行推断：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_5.jpg)\n\n### Components of the model\n\n#### Likelihood\n\n首先是似然，似然指的是在给定参数情况下数据的合理性(发生的可能性)。\n\n#### Prior\n\n对于我们想要贝叶斯估计的每个参数，我们需要为其提供先验。先验也为一个概率分布，可以是之前数据得到的参数的概率分布或是我们自己根据经验的概率分布。\n\n#### Posterior\n\n再有了先验和似然后我们就可以计算后验：\n$$\n\\text { Posterior }=\\frac{\\text { Likelihood } \\times \\text { Prior }}{\\text { Average Likelihood }}\n$$\n\n### Making the model go\n\n由于后验分布存在积分，我们有时无法直接对其进行计算，这时候就需要数值方法，我们主要介绍三种方法：\n\n1. 网格近似\n2. 二次逼近\n3. MCMC\n\n#### Grid approximation\n\n最简单的调节技术之一是网格近似。虽然大多数参数是连续的，能够取无限数量的值，但事实证明，我们可以通过仅考虑参数值的有限网格来实现对连续后验分布的极好近似。\n\n但是在大多数真实建模中，网格近似是不切实际的。原因是随着参数数量的增加，它的扩展性很差。所以在后面的章节中，网格近似将逐渐消失，取而代之的是其他更有效的技术。\n\n~~~R\n# define grid\np_grid <- seq(from=0, to=1, length.out=20)\n\n# define prior\nprior = rep(1, 20)\n\n# compute likelihood at each value in grid\nlikelihood <- dbinom(6, size = 9, prob = p_grid)\n\n\n# compute product of likelihood and prior\nunstd.posterior <- likelihood * prior\n\n# standardize the posterior, so it sums to 1\nposterior <- unstd.posterior / sum(unstd.posterior)\n~~~\n\n~~~R\nplot(p_grid, posterior, type = \"b\", xlab = \"probability of water\", ylab = \"posterior probability\")\nmtext(\"20 points\")\n~~~\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_6.jpeg)\n\n#### Quadratic approximation\n\n在一般的条件下，后验分布峰值附近的区域在形状上将接近高斯或正态分布。这意味着后验分布可以有用地近似为高斯分布。高斯分布很方便，因为它可以完全用两个数字来描述：中心的位置（均值）和分布（方差）。该方法分为两个步骤：\n\n1. 找到后验分布的众数\n2. 一旦找到后验的峰值，就必须估计峰值附近的曲率。该曲率足以计算整个后验分布的二次近似\n\n~~~R\nlibrary(rethinking)\nglobe.qa <- map(\n  alist(\n    w ~ dbinom(9, p), #likelihood\n    p ~ dunif(0,1)\n  ),\n  data = list(w=6)\n)\n# display summary of quadratic approximation\nprecis(globe.qa)\n>  mean   sd 5.5% 94.5%\np 0.67 0.16 0.42  0.92\n~~~\n\n我们与真实的后验进行比较：\n\n~~~R\n# analytical calculation\nw <- 6\nn <- 9\ncurve(dbeta(x, w+1, n-w+1), from = 0, to=1)\n# quadratic approximation\ncurve(dnorm(x, 0.67, 0.16), lty=2, add = TRUE)\n~~~\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt2_7.jpeg)\n\n","tags":["概率编程","贝叶斯统计","Statistical Rethinking"],"categories":["书籍阅读"]},{"title":"Statistical Rethinking:Chapter1","url":"/2022/06/28/rt1/","content":"\n## The Golem of Prague\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt1_1.png)\n\n`golem`为魔像，为一个非常强大的机器人，但是它只会听从人的命令，没有自主思考的能力。因此人类必须给他设置非常具体的命令，否则可能会对人类造成伤害。\n\n<!--more-->\n\n### Statistical golems\n\n统计家也制造魔像。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt1_2.jpg)\n\n> 统计家制造的魔像，非常强大，但也同样需要人类的指导。缺乏灵活性，在需要创造性的区域无法应用。\n\n### Statistical rethinking\n\n很多人认为统计推断的目标是检验无效假设。但这是不正确的，我们有以下两个理由：\n\n1. 假设不是模型。假设和不同种类的模型之间的关系是复杂的。许多模型对应同一个假设，许多假设对应一个模型。这使得严格的证伪变得不可能。\n2. 测量很重要。即使我们认为数据证伪了模型，另一位观察者也会争论我们的方法和措施。他们不相信数据。有时他们是对的。\n\n#### Hypotheses are not models\n\n当我们试图证伪一个假设时，我们必须使用某种模型，但是我们不能仅仅通过一个模型来证明假设是错误的。\n\n我们看一个关于进化的例子，有人认为进化是中性的，而有人不这么认为，所有存在两个假设。同一个假设可能导致不同的过程的模型，而同一个过程模型会引出不同的统计模型，同一个统计模型也可能对应于不同的过程模型和假设，因此证伪非常复杂。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/rt1_3.jpg)\n\n\n\n#### Measurement matters\n\n首先观测是存在误差的，而且有的测量非常复杂容易出现误差。\n\n其次假设并不一定是离散的，现实生活中的很多假设都是连续的，例如$80\\%$的天鹅都是白色的，对我们证伪来说非常困难。\n\n### Three tools for golem engineering\n\n#### Bayesian data analysis\n\n贝叶斯统计用随机型来描述不确定性，更详细的将在第二章讲述。\n\n#### Multilevel models\n\n使用多级模型有四个典型且互补的原因：\n\n1. 调整重复抽样的估计值。当不止一个观察来自同一个人、地点或时间时，传统的单级模型可能会误导我们。\n2. 调整抽样不平衡的估计值。当某些个体、地点或时间的采样次数多于其他人时，我们也可能会被单级模型误导。\n3. 研究变异。如果我们的研究问题包括数据中个人或其他群体之间的变化，那么多层次模型将有很大帮助，因为它们明确地模拟了变化。\n4. 避免平均。学者们经常对一些数据进行预平均，以构建用于回归分析的变量。这可能很危险，因为平均会消除变化。因此，它制造了虚假的信念。多级模型允许我们保留原始预平均值中的不确定性，同时仍使用平均值进行预测。\n\n#### Model comparison and information criteria\n\n最著名的信息准则是 AIC，即 Akaike (ah-kah-ee-kay) 信息准则。AIC 及其同类被称为“信息”标准，因为它们从信息论中发展出对模型准确性的度量。我们可以用起来比较模型的好坏。\n\n","tags":["概率编程","贝叶斯统计","Statistical Rethinking"],"categories":["书籍阅读"]},{"title":"Turing:a language for flexible probabilistic inference","url":"/2022/06/28/Turing/","content":"\n## Turing: a language for flexible probabilistic inference\n\n> 文章链接：http://proceedings.mlr.press/v84/ge18b.html?ref=https://githubhelp.com\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/Tur1.png)\n\n<!--more-->\n\n### Background\n\n在概率模型中，我们关注的一般是$p(\\theta\\mid y,\\gamma)$，其中$\\theta$为参数，$y$为观测数据，$\\gamma$为一些确定了的超参数。\n\n#### Models as computer programs\n\n最早的概率编程语言为BUGS，可以追溯到20世纪90年代。下面展示了概率程序的一般结构。\n\n输入：数据$y$和超参数$\\gamma$\n\n步骤1：定义全局参数：\n$$\n\\theta^{\\text{global}}\\sim p(\\cdot\\mid \\gamma)\n$$\n步骤2：对于每一个观测$y_n$，定义(局部)隐变量并计算似然：\n$$\n\\begin{aligned}\n\\theta_n^{\\text{local}}&\\sim p\\left(\\cdot\\mid\\theta_{1:n-1}^{\\text{local}},\\theta^{\\text{global}},\\gamma\\right)\\\\\ny_n&\\sim p\\left(\\cdot\\mid \\theta_{1:n}^{\\text{local}},\\theta^{\\text{global}},\\gamma\\right)\n\\end{aligned}\n$$\n其中$n=1,2,\\cdots,N$。\n\n参数分为两类：$\\theta_n^{\\text{local}}$表示对于观测$y_n$的模型参数，如混合高斯模型中$y_n$属于哪个高斯分布的参数，而$\\theta^{\\text{global}}$表示全局变量。\n\n#### Inference for probabilistic programs\n\n概率程序只有在与高效的推理引擎相结合时才能发挥其灵活性潜力。为了解释概率编程中推理如何工作，我们考虑以下具有$K$个状态的HMM例子：\n$$\n\\begin{aligned}\n\\pi_k&\\sim \\text{Dir}(\\theta)\\\\\n\\phi_k&\\sim p(\\gamma)\\\\\nz_t\\mid z_{t-1}&\\sim \\text{Cat}(\\cdot\\mid \\pi_{z_{t-1}})\\\\\ny_t\\mid z_t&\\sim h(\\cdot\\mid \\phi_{z_t})\n\\end{aligned}\n$$\n其中$k = 1,2,\\cdots,K$，$t = 1,\\cdots,N$。\n\n具有以下三个步骤的高效 Gibbs 采样器通常用于贝叶斯推理：\n\n+ Step 1: Sample $z_{1: T} \\sim z_{1: T} \\mid \\phi_{1: K}, \\pi_{1: K}, y_{1: T} ;$\n+ Step 2: Sample $\\phi_{k} \\sim \\phi_{k} \\mid z_{1: T}, y_{1: T}, \\gamma$;\n+ Step 3: Sample $\\pi_{k} \\sim \\pi_{k} \\mid z_{1: T}, \\theta(k=1, \\ldots, K)$.\n\n\n\n#### Computation graph based inference\n\n对概率程序进行建模的一大挑战是构建模型变量之间的计算图。对于一些编程语言，在推理之前概率图模型就已经生成，但是当程序中存在随机分支时就会出现问题，在这种情况下，我们不得不求助于其他推理方法。\n\n### Composable MCMC inference\n\n我们提出的可组合推理方法利用了HMC算法和粒子吉布斯(PG)算法。为了描述所提出的概率程序方法，我们利用潜在狄利克雷分配(LDA)的例子。\n\n~~~julia\n@model lda(K ,M, N, w, d, beta, alpha) = begin\n    theta = Vector{Vector{Real}}(M)\n    for m = 1:M\n        theta[m] ~ Dirichlet(alpha)\n    end\n    phi = Vector{Vector{Real}}(K)\n    for k = 1:K\n        phi[k] ~ Dirichlet(beta)\n    end\n    \n    z = tzeros(Int, N)\n    for n = 1:N\n        z[n] ~ Categorical(theta[d[n]])\n        w[n] ~ Categorical(phi[z[n]])\n    end\nend\n~~~\n\n其中变量$\\phi,\\theta,z$表示模型参数，变量$K,M,N,d,\\beta,\\alpha$表示超参数，$w$表示观测数据。\n\n一旦定义了模型，提供数据和执行推理就很直观了。\n\n~~~julia\nmodel = lda(K, V, M, N, w, d, beta, alpha)\nsample(model, engine)\n~~~\n\n`engine`是我们想要使用的MCMC引擎。例如，如果要应用例子吉布斯采样，我们可以：\n\n~~~julia\nspl = PG(n, m)\nsample(model, spl)\n~~~\n\n这将会用含有$m$个粒子的PG进行$n$次迭代。\n\n我们也可以对不同的参数采用不同的采样器：\n\n~~~julia\nspl2 = Gibbs(1000, PG(10,2,:z), HMC(2, 0.1, 1, 5, :phi,:theta))\n~~~\n\n上述采样引擎`spl2`将参数分割为两部分，每个部分采用不同的采样方法，值得注意的是，分布的两个部分不需要是互斥的。\n\n#### A family of MCMC operators\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/tur2.jpg)\n\n> Supported Monte Carlo algorithms in Turing\n\n### Implementation and Experiments\n\n#### The Turing library\n\nTuring为Julia的一个包。因为Turing为一般的Julia程序，因此它可以利用Julia中丰富的数值和统计库。\n\n##### Efficient particle Gibbs implementation\n\n我们使用协程来实现粒子 Gibbs。协程可以看作是函数的泛化，具有可以在多个点暂停和恢复的特性。\n\n##### Automatic differentiation\n\nHMC在采样的过程需要梯度，当给定定义$\\log p(\\theta\\mid z_{1:N},\\gamma)$的计算程序时，这些梯度可以通过自动微分(AD)自动获得。为了简便和高效，我们率先使用了一种称为向量模式的前向微分技术。向量模式前向微分背后的主要概念是多维对偶数，其在标量函数上的行为定义为：\n$$\nf\\left(\\theta+\\sum_{i=1}^D y_i\\epsilon_i\\right) = f(\\theta) + f^{\\prime}(\\theta)\\sum_{i=1}^Dy_i\\epsilon_i\n$$\n其中$\\epsilon_i\\epsilon_j=0,\\text{for }i\\neq j$。\n\n对于小模型，向量前向AD非常高效。但是对于大模型逆向模式的AD较为高效，因此Turing两种模式都存在。\n\n##### Vectorized random variables\n\nTuring支持利用以下语法对独立同分布的变量进行矢量化采样：\n\n~~~julia\nrv = Vector(10)\nrv ~ [Normal(0, 1)]\n~~~\n\n##### Constrained random variables\n\nTuring支持约束的变量。主要由三种类型的约束：\n\n1. 有界的单变量。\n2. 有简单约束的多维变量，如相加和为$1$。\n3. 矩阵约束：例如协方差矩阵为半正定矩阵。\n\n##### MCMC output analysis\n\n在Turing中我们可以使用`describe`函数计算：\n\n1. 均值\n2. 标准差\n3. naive standard error\n4. 蒙特卡洛标准误差\n5. 有效样本数\n6. 分位数\n\n也可以使用`hpd`函数计算高后验概率区间，互相关`cor`，自相关`autocor`，状态空间变化率`changerate`和偏差信息准则`dic`等等。\n\n#### Finding the right inference engine\n\n下面我们将比较`NUTS`和`Gibbs(PG,HMC)`在不同的概率模型上。\n\n##### Models and inference engine setup\n\n**Stochastic Volatility Model**：参数的集合为$\\{\\phi,\\sigma,\\mu,h_{1:N}\\}$。所有这些参数对于目标分布来说都是可导的，因此NUTS算法是可用的：\n$$\n\\begin{aligned}\n\\mu &\\sim \\mathcal{C} \\mathrm{a}(0,10)), \\phi \\sim \\mathcal{U} \\mathrm{n}(-1,1), \\sigma \\sim \\mathcal{C} \\mathrm{a}(0,5), \\quad(\\sigma>0) \\\\\nh_{1} & \\sim \\mathcal{N}\\left(\\mu, \\sigma / \\sqrt{1-\\phi^{2}}\\right), h_{n} \\sim \\mathcal{N}\\left(\\mu+\\phi\\left(h_{n-1}-\\mu\\right), \\sigma\\right) \\\\\ny_{n} & \\sim \\mathcal{N}\\left(0, \\exp \\left(h_{n} / 2\\right)\\right) \\quad(n=2,3, \\ldots, N) .\n\\end{aligned}\n$$\n其中$\\mathcal{C}\\mathrm{a}$表示柯西分布。\n\n~~~julia\nspl1 = NUTS(1e4, 1e3, 0.65)\nspl2 = Gibbs(1e4, PG(5, 1, :h), NUTS(1, 1e3, 0.65, :mu, :phi, :sigma))\n~~~\n\n**Gaussian Mixture Model**：参数的集合为$\\{z,\\theta\\}$，其中参数$\\theta$是可导的，参数$z$不可以。为了运行NUTS算法，我们积分积掉$z$只对$\\theta$采样：\n$$\n\\begin{array}{r}\n\\mu=\\left(\\mu_{1: K}\\right), \\quad \\sigma=\\left(\\sigma_{1: K}\\right), \\quad \\pi=\\left(p_{1: K}\\right) \\\\\nz \\sim \\operatorname{Cat}(\\pi), \\quad \\theta \\sim \\mathcal{N}\\left(\\mu_{z}, \\sigma_{z}\\right)\n\\end{array}\n$$\n\n~~~julia\nspl3 = NUTS(5e4, 1000, 0.65)\nspl4 = Gibbs(5e4, PG(5, 1, :z), NUTS(5e2, 1e3, 0.65, :theta))\n~~~\n\n##### Results\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/tur3.jpg)\n\n> 上图为在GMM模型上trace plot，下图为联合分布的概率的对数的图，可以看到两个算法都达到了收敛，但是NUTS算法在某些对方被\"困住了\"。在下图更明显。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/tur4.jpg)\n\n> 对具有$5$个混合的GMM采样的结果，可以更明显地看到NUTS算法被困住了，在图的上半部分只探索到了两个混合成分。\n\n\n\n","tags":["概率编程","Julia"],"categories":["文献阅读"]},{"title":"文章A Conceptual Introduction to Hamiltonian Monte Carlo阅读笔记","url":"/2022/06/22/HMC/","content":"\n## A Conceptual Introduction to Hamiltonian Monte Carlo\n\n> 文章链接：https://arxiv.org/abs/1701.02434\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/HMC1.png)\n\n<!--more-->\n\n### 期望的计算\n\n对于给定函数$f(q)$，我们在给定的$q$的分布$\\pi (q)$上计算其期望：\n$$\n\\mathbb{E}_{\\pi}[f] = \\int_{\\mathcal{Q}}\\pi(q)f(q)dq\n$$\n一般情况下此积分的原函数得不到，因此我们采用蒙特卡洛的方法，在$\\pi(q)$上对$q$进行采样，用下式计算期望：\n$$\n\\mathbb{E}_{\\pi}[f]\\approx \\frac{1}{n}\\sum_{i=1}^n f(q_i)\\quad q_i\\sim \\pi(q)\n$$\n但是我们如何在$\\pi(q)$上进行采样呢？为了节省时间，我们一般选择在概率密度较高的位置进行采样，即在概率密度最高的邻域内进行采样。但是在高维情况下存在问题，假设我们在概率密度最高的$1/3$邻域内进行采样，当维度为$n$时，积分区域的体积为$(1/3)^n$，当$n$很大时趋近于$0$，因此对积分的贡献很小。而概率密度较小的地方由于概率密度趋近于$0$，对积分的贡献也不大。我们着重关注的应该是介于两者之间的区域，其对积分的贡献较大，成为典型集(typical set)。我们研究的重点在于如何在**典型集上采样**。\n\n### 马尔可夫链蒙特卡洛方法\n\n#### 理想状态\n\n利用马尔可夫链蒙特卡洛(MCMC)方法可以在典型集上进行采样。在理想状态下，MCMC的采样过程可以分为三个阶段：\n\n1. 从初始位置到典型集，此时偏差(bias)较大。\n2. 进入典型集后，在典型集上进行探索，准确度迅速上升。\n3. 继续在典型集上进行探索，准确度上升缓慢。\n\n如下图所示：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/HMC2.jpg)\n\n> 图(a)表示阶段1，图(b)表示阶段2，图(c)表示阶段3。\n\n当达到阶段3时，估计的结果符合大数定律：\n$$\n\\hat{f}^{\\text{MCMC}}_N\\sim \\mathcal{N}(\\mathbb{E}_{\\pi}[f],\\text{MCMC-SE})\n$$\n其中蒙特卡洛误差为：\n$$\n\\text{MCMC-SE}\\equiv \\sqrt{\\frac{\\text{Var}_{\\pi}[f]}{\\text{ESS}}}\n$$\n其中ESS为有效样本量，定义为：\n$$\n\\text{ESS} = \\frac{N}{1+2\\sum_{l=1}^\\infty \\rho_l}\n$$\n其中$\\rho_l$为之后$l$的自相关系数。\n\n#### 病态情况\n\n当典型集内存在高曲率区域时，会导致此区域无法被探索，造成偏差。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/HMC3.jpg)\n\n> 病态情况：其中绿色区域表示高曲率区域。存在三种情况：\n>\n> 1. 无法跨过此高曲率区域，仅在一侧进行采样。\n> 2. 在高曲率区域周围震荡。\n> 3. 可以跨过高区域区域，在整个典型集上进行采样。\n\n#### Metropolis-Hastings采样\n\n一个较为简单的MCMC方法为M-H采样(Metropolis-Hastings采样)，在局部利用建议分布对目标分布进行近似，其分为两个步骤：\n\n1. 在提议分布$\\mathbb{Q}(q^\\prime\\mid q)$进行采样\n2. 计算接受率$$a(q^\\prime\\mid q) = \\min\\left(1,\\frac{\\mathbb{Q}(q\\mid q^\\prime)\\pi(q^\\prime)}{\\mathbb{Q}(q^\\prime\\mid q)\\pi(q)}\\right)$$，如果$a$大于生成的$0\\sim1$之间的随机数，接受样本$q^\\prime$，否则继续接受样本$q$。\n但是M-H采样在高维情况下存在接受率过低的问题。\n\n### Hamiltonian Monte Carlo\n\n汉密尔顿蒙特卡洛(HMC)方法：我们可以利用典型集的形状的特征来进行采样。我们不再在典型集上随机移动，而是通过向量场的形式来指示移动的方向，使其高效地在典型集上移动。\n\n我们将概率系统类比于物理系统，典型集类似于行星绕地球旋转地轨道。对于行星，我们需要添加动量来抵消重力使行星正常围绕地球运动；类比于概率空间，我们需要添加动量来抵消梯度使马尔可夫链在典型集上采样。\n\n#### 相空间和汉密尔顿方程\n\n我们需要引入动量参数来补充目标参数空间的每个维度：\n$$\nq_n \\rightarrow (q_n,p_n)\n$$\n这样将$D$维空间拓展为了$2D$维的空间，我们就将目标参数空间拓展为了相空间。相空间上的联合分布成为典型分布(canonical distribution)：\n$$\n\\pi(q,p) = \\pi(p\\mid q)\\pi(q)\n$$\n这样我们对动量参数进行积分后很容易得到我们要采样的目标参数。\n\n我们将典型分布写为不变的汉密尔顿函数的形式：\n$$\n\\pi(q,p) = \\exp^{-H(q,p)}\n$$\n所以：\n$$\n\\begin{aligned}\nH(q,p) &= -\\log\\pi(p\\mid q) - \\log\\pi(q)\\\\\n&\\equiv K(p,q) + V(q)\n\\end{aligned}\n$$\n其中$K(p,q)$被称为动能，$V(q)$被称为势能。\n\n我们利用汉密尔顿方程来生成向量场：\n$$\n\\begin{aligned}\n\\frac{dq}{dt} &= + \\frac{\\partial H}{\\partial p} = \\frac{\\partial K}{\\partial p}\\\\\n\\frac{dp}{dt} &= -\\frac{\\partial H}{\\partial q} = -\\frac{\\partial K}{\\partial q} - \\frac{\\partial V}{\\partial q}\n\\end{aligned}\n$$\n所以汉密尔顿方程是不随时间发生改变的，因为：\n$$\n\\begin{aligned}\n\\frac{dH}{dt} &= \\frac{\\partial H}{\\partial p}\\frac{d p}{dt} + \\frac{\\partial H}{\\partial q}\\frac{d q}{dt}\\\\\n&= -\\frac{\\partial H}{\\partial p}\\frac{\\partial H}{\\partial q} + \\frac{\\partial H}{\\partial q}\\frac{\\partial H}{\\partial p}\\\\\n&=0\n\\end{aligned}\n$$\n\n#### 理想条件下的汉密尔顿转移\n\n理想条件下的HMC可以分为3个步骤：\n\n1. 从初始位置产生初始动量\n2. 以此类推产生轨迹\n3. 从相空间投影到参数空间\n\n\n\n### 高效的HMC\n\n#### 相空间的几何形状\n\n汉密尔顿公式的性质使汉密尔顿方程的值始终保持不变。话句话说，每一个汉密尔顿轨迹都使一个能级：\n$$\nH^{-1}(E) = \\{q,p\\mid H(q,p)=E\\}\n$$\n如下图所示，相空间可以被分解维汉密尔顿能级。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/HMC4.jpg)\n\n所以我们的采样过程可以分解为两个步骤，一个是在相同的能级上进行采样，一个是在不同的能级上进行跃迁，如下图：\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/HMC5.jpg)\n\n> 深红色表示在相同的能级上进行采样，浅红色的表示在不同能级上进行跃迁。\n\n#### 对动能的优化\n\n欧几里得-高斯动能：\n$$\n\\begin{aligned}\n\\Delta(q,q^\\prime) &= (q-q^\\prime)^\\top\\cdot M\\cdot(q-q^\\prime)\\\\\n\\Delta(p,p^\\prime) &= (p-p^\\prime)^\\top\\cdot M^{-1}\\cdot(p-p^\\prime)\n\\end{aligned}\n$$\n我们一般定义条件分布为：\n$$\n\\pi(p\\mid q) = \\mathcal{N}(p\\mid 0,M)\n$$\n\n\n这种特殊选择定义了欧几里得-高斯动能：\n$$\nK(q,p) = \\frac{1}{2}P^\\top \\cdot M^{-1}\\cdot p + \\frac{1}{2}\\log|M|+\\text{const}\n$$\n\n\n黎曼-高斯动能函数：与欧几里得-高斯动能函数不同之处为协方差与位置有关：\n$$\n\\pi(p\\mid q) = \\mathcal{N}(p\\mid 0,\\Sigma(q))\n$$\n定义了黎曼-高斯动能：\n$$\nK(q,p) = \\frac{1}{2}p^\\top\\cdot\\Sigma^{-1}(q)\\cdot p+\\frac{1}{2}\\log|\\Sigma(q)| + \\text{const}\n$$\n\n\n#### 对积分时间的优化\n\n这里的积分时间指的是在某个特定能级上的探索时间(步数)。随着积分时间的增加，时间期望会收敛到空间期望。\n\n![](https://raw.githubusercontent.com/HFC666/image/master/img/hmc6.jpg)\n\n> 图(a)：时间期望与空间期望的差值的绝对值随着积分时间的变化，可以看到到积分时间到达一定的程度后，增加积分时间对结果产生的影响并不大；图(b)：有效样本数随着积分时间的变化，与图(a)变化类似；图(c)：有效样本数/积分时间随着积分时间的变化，先增加后减小，存在最大值。\n\n当目标概率密度为：\n$$\n\\pi_\\beta(q)\\propto \\exp(-|q|^\\beta)\n$$\n动能函数为欧几里得动能：\n$$\n\\pi(p\\mid q) = \\mathcal{N}(0,1)\n$$\n最优积分时间与包含轨迹的能级的能量成比例：\n$$\nT_{\\text{optimal}}(q,p)\\propto (H(q,p))^{\\frac{2-\\beta}{2\\beta}}\n$$\n\n### 在实践中实现HMC\n\n由于在绝大数情况下我们不能准确地求解哈密顿方程，必须采用数值求解的方法，但是数值求解的过程会累积误差，对我们的结果产生影响。\n\n#### Symplectic Integrators\n\nSymplectic Integrators(辛积分器)是一个强大的积分器，它产生的数值轨迹不会偏离精确的能级，而是在其附近震荡，即使在很长的积分时间内也是如此。\n$$\n\\begin{aligned}\n&q_{0} \\leftarrow q, p_{0} \\leftarrow p \\\\\n&\\text {for } 0 \\leq n<\\llcorner T / \\epsilon\\lrcorner \\text { do } \\\\\n&\\quad p_{n+\\frac{1}{2}}  \\leftarrow p_{n}-\\frac{\\epsilon}{2} \\frac{\\partial V}{\\partial q}\\left(q_{n}\\right) \\\\\n&\\quad q_{n+1}  \\leftarrow q_{n}+\\epsilon p_{n+\\frac{1}{2}} \\\\\n&\\quad p_{n+1} \\leftarrow p_{n+\\frac{1}{2}}-\\frac{\\epsilon}{2} \\frac{\\partial V}{\\partial q}\\left(q_{n+1}\\right)\\\\\n&\\text {end for. }\n\\end{aligned}\n$$\n\n#### 纠正辛积分器\n\n我们在每个能级上运行$L$步，取最后一个样本$(q_L,p_L)$，之后进行能级跃迁。因为我们是使用数值的方法，因此在同一个能级上采样上可能不能保持能量不变。因此我们借用M-H采样的思想来对样本进行进行接受-拒绝，因为在同一个能级上采样当确定初始点时采到的样本是固定的，所以：\n$$\n\\mathbb{Q}(q_0,p_0\\mid q_L,p_L) = \\mathbb{Q}(q_L,p_L\\mid q_0,p_0)=1\n$$\n其接受概率为：\n$$\n\\begin{aligned}\na\\left(q_{L},p_{L} \\mid q_{0}, p_{0}\\right) &=\\min \\left(1, \\frac{\\mathbb{Q}\\left(q_{0}, p_{0} \\mid q_{L},p_{L}\\right) \\pi\\left(q_{L},p_{L}\\right)}{\\mathbb{Q}\\left(q_{L},p_{L} \\mid q_{0}, p_{0}\\right) \\pi\\left(q_{0}, p_{0}\\right)}\\right) \\\\\n\n&=\\min \\left(1, \\frac{\\pi\\left(q_{L},p_{L}\\right)}{\\pi\\left(q_{0}, p_{0}\\right)}\\right) \\\\\n&=\\min \\left(1, \\frac{\\exp \\left(-H\\left(q_{L},p_{L}\\right)\\right)}{\\exp \\left(-H\\left(q_{0}, p_{0}\\right)\\right)}\\right) \\\\\n&=\\min \\left(1, \\exp \\left(-H\\left(q_{L},p_{L}\\right)+H\\left(q_{0}, p_{0}\\right)\\right)\\right)\n\\end{aligned}\n$$\n\n\n\n\n","tags":["算法"],"categories":["文献阅读"]},{"title":"只争朝夕，不负韶华","url":"/2021/07/13/index/","content":"\n<h1 align=\"center\">\n    凡是过往皆为序章，所有将来皆可盼。\n</h1>\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/HFC666/image/master/img/head.jpg\" style=\"zoom: 100%;\" />\n</p>\n\n\n\n\n\n\n"}]